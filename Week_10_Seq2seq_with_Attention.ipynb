{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Week 10 - Seq2seq with Attention.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "OE7fXh-OSJYF",
        "colab_type": "code",
        "outputId": "c56ac019-a0e3-4e44-9480-9022c07fccb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 776
        }
      },
      "cell_type": "code",
      "source": [
        "!pip3 -qq install torch==0.4.1\n",
        "!pip -qq install torchtext==0.3.1\n",
        "!pip install msgpack==0.5.6\n",
        "!pip -qq install spacy==2.0.18\n",
        "!pip -qq install torchvision==0.2.1\n",
        "!python -m spacy download en\n",
        "!pip install sacremoses==0.0.5\n",
        "!pip install subword_nmt==0.3.5\n",
        "!wget -qq http://www.manythings.org/anki/rus-eng.zip \n",
        "!unzip rus-eng.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tcmalloc: large alloc 1073750016 bytes == 0x58f9e000 @  0x7f1f90b832a4 0x591a07 0x5b5d56 0x502e9a 0x506859 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x502540 0x502f3d 0x507641\n",
            "Collecting msgpack==0.5.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/4e/dcf124fd97e5f5611123d6ad9f40ffd6eb979d1efdc1049e28a795672fcd/msgpack-0.5.6-cp36-cp36m-manylinux1_x86_64.whl (315kB)\n",
            "\u001b[K    100% |████████████████████████████████| 317kB 19.7MB/s \n",
            "\u001b[31mspacy 2.0.18 has requirement numpy>=1.15.0, but you'll have numpy 1.14.6 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: msgpack\n",
            "  Found existing installation: msgpack 0.6.0\n",
            "    Uninstalling msgpack-0.6.0:\n",
            "      Successfully uninstalled msgpack-0.6.0\n",
            "Successfully installed msgpack-0.5.6\n",
            "\u001b[31mfeaturetools 0.4.1 has requirement pandas>=0.23.0, but you'll have pandas 0.22.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mcufflinks 0.14.6 has requirement plotly>=3.0.0, but you'll have plotly 1.12.12 which is incompatible.\u001b[0m\n",
            "Collecting en_core_web_sm==2.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz#egg=en_core_web_sm==2.0.0\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz (37.4MB)\n",
            "\u001b[K    100% |████████████████████████████████| 37.4MB 48.0MB/s \n",
            "\u001b[?25hInstalling collected packages: en-core-web-sm\n",
            "  Running setup.py install for en-core-web-sm ... \u001b[?25l-\b \b\\\b \b|\b \bdone\n",
            "\u001b[?25hSuccessfully installed en-core-web-sm-2.0.0\n",
            "\n",
            "\u001b[93m    Linking successful\u001b[0m\n",
            "    /usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "    /usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "\n",
            "    You can now load the model via spacy.load('en')\n",
            "\n",
            "Collecting sacremoses==0.0.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c5/c4/9d4cdd0e3e02d3328bb4e6764da25b147ce72d87d3d627e4f90611755411/sacremoses-0.0.5.tar.gz (102kB)\n",
            "\u001b[K    100% |████████████████████████████████| 112kB 6.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses==0.0.5) (1.11.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Running setup.py bdist_wheel for sacremoses ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/fb/b4/f5/8ca724b21fc983eee2c9b99a7db69f85480c330a5bf6d8d546\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses\n",
            "Successfully installed sacremoses-0.0.5\n",
            "Collecting subword_nmt==0.3.5\n",
            "  Downloading https://files.pythonhosted.org/packages/e1/14/f870780204476815af1aa11a20bfde91fbe588712a1e900b32c079beb7ea/subword_nmt-0.3.5-py2.py3-none-any.whl\n",
            "Installing collected packages: subword-nmt\n",
            "Successfully installed subword-nmt-0.3.5\n",
            "Archive:  rus-eng.zip\n",
            "  inflating: rus.txt                 \n",
            "  inflating: _about.txt              \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uhvfH55PUJ8K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    from torch.cuda import FloatTensor, LongTensor\n",
        "    DEVICE = torch.device('cuda')\n",
        "else:\n",
        "    from torch import FloatTensor, LongTensor\n",
        "    DEVICE = torch.device('cpu')\n",
        "\n",
        "np.random.seed(42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "txWqIO_74A4s",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Attention"
      ]
    },
    {
      "metadata": {
        "id": "dr_Kn_7GialL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "В прошлый раз мы реализовали простую Seq2seq модель:\n",
        "\n",
        "![](https://raw.githubusercontent.com/tensorflow/nmt/master/nmt/g3doc/img/seq2seq.jpg =x400)  \n",
        "*From [tensorflow/nmt](https://github.com/tensorflow/nmt)*\n",
        "\n",
        "Основной её недостаток - вся информация об исходном тексте кодируется в единственный вектор фиксированного размера. Но очевидно же, что идея эта так себе.\n",
        "\n",
        "Давайте запоминать все скрытые состояния энкодера, а не только последнее.\n",
        "\n",
        "Дальше, для вычисления нового слова при генерации найдем сначала представление уже сгенерированного контекста (по которому обычно и генерируется следующее слово).  \n",
        "По этому представлению посчитаем оценки полезности состояний энкодера: `attention weights` на картинке ниже. Чем выше вес - тем более полезно состояние. (Можно, кстати, представлять, что в предыдущем варианте мы просто давали всем состояниям кроме последнего вес 0, а последнему - 1).\n",
        "\n",
        "С этими весами состояния энкодера суммируются, и мы получаем взвешенный вектор-представление контекста. Опять вектор?! Но теперь этот вектор получен для конкретного генерируемого слова - это же гораздо лучше, чем пытаться сделать один вектор сразу для всех генерируемых слов.\n",
        "\n",
        "![attention](https://www.tensorflow.org/images/seq2seq/attention_mechanism.jpg =x400)  \n",
        "From [Neural Machine Translation (seq2seq) Tutorial](https://www.tensorflow.org/tutorials/seq2seq).\n",
        "\n",
        "Более наглядно это может быть в [динамике](https://raw.githubusercontent.com/yandexdataschool/nlp_course/master/resources/attention_mechanism.gif) (из cs224n + shad nlp course).\n",
        "\n",
        "В результате получаются такие красивые картинки с визуализацией аттеншена:   \n",
        "![att-vis](https://www.tensorflow.org/images/seq2seq/attention_vis.jpg =x500)\n",
        "\n",
        "Яркость ячейки показывает насколько много внимания уделяла модель данному слову на исходном языке при генерации соответствующего ему слова.\n",
        "\n",
        "Очень красивая статья с демонстрацией attention'а: [Attention and Augmented Recurrent Neural Networks](https://distill.pub/2016/augmented-rnns/)."
      ]
    },
    {
      "metadata": {
        "id": "JyNkst1XkYN6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Подготовка"
      ]
    },
    {
      "metadata": {
        "id": "tRLNIzJkkqkM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Возьмем те же данные, что и в прошлый раз:"
      ]
    },
    {
      "metadata": {
        "id": "U2vjzBVqZF0b",
        "colab_type": "code",
        "outputId": "33c8ccae-15f4-46c9-d061-a2ae0ecde744",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "cell_type": "code",
      "source": [
        "!shuf -n 10 rus.txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "You need a joystick.\tТебе нужен джойстик.\n",
            "Tom may leave anytime he wants to.\tТом может уходить когда хочет.\n",
            "You have to take care of Tom.\tТы должна позаботиться о Томе.\n",
            "Don't you have any money?\tУ тебя нет денег?\n",
            "I'm glad you didn't get injured.\tЯ рад, что ты не пострадал.\n",
            "I'd tell you the same thing.\tЯ бы вам то же самое сказал.\n",
            "Tom is busy right now.\tПрямо сейчас Том занят.\n",
            "Tom, can you hear me?\tТом, тебе меня слышно?\n",
            "Tom didn't call 911.\tТом не звонил в 911.\n",
            "She thinks of nothing but making money.\tОна думает только о зарабатывании денег.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QOVlO5_Qlg5y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Токенизируем их:"
      ]
    },
    {
      "metadata": {
        "id": "fsOvtO0fpCHa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torchtext.data import Field, Example, Dataset, BucketIterator\n",
        "\n",
        "BOS_TOKEN = '<s>'\n",
        "EOS_TOKEN = '</s>'\n",
        "\n",
        "source_field = Field(tokenize='spacy', init_token=None, eos_token=EOS_TOKEN, lower=True)\n",
        "target_field = Field(tokenize='moses', init_token=BOS_TOKEN, eos_token=EOS_TOKEN, lower=True)\n",
        "fields = [('source', source_field), ('target', target_field)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VO-gix7yoBjg",
        "colab_type": "code",
        "outputId": "033d5127-a6d5-4b98-d70b-2026787851aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "MAX_TOKENS_COUNT = 16\n",
        "SUBSET_SIZE = .3\n",
        "\n",
        "examples = []\n",
        "with open('rus.txt') as f:\n",
        "    for line in tqdm(f, total=328190):\n",
        "        source_text, target_text = line.split('\\t')\n",
        "        source_text = source_field.preprocess(source_text)\n",
        "        target_text = target_field.preprocess(target_text)\n",
        "        if len(source_text) <= MAX_TOKENS_COUNT and len(target_text) <= MAX_TOKENS_COUNT:\n",
        "            if np.random.rand() < SUBSET_SIZE:\n",
        "                examples.append(Example.fromlist([source_text, target_text], fields))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 328190/328190 [00:56<00:00, 5859.43it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "A8uCsMEglm6V",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Построим датасеты:"
      ]
    },
    {
      "metadata": {
        "id": "ZOBgLAgVTrk1",
        "colab_type": "code",
        "outputId": "8949e3d9-69d0-4860-890b-9bf08b607592",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "cell_type": "code",
      "source": [
        "dataset = Dataset(examples, fields)\n",
        "\n",
        "train_dataset, test_dataset = dataset.split(split_ratio=0.85)\n",
        "\n",
        "print('Train size =', len(train_dataset))\n",
        "print('Test size =', len(test_dataset))\n",
        "\n",
        "source_field.build_vocab(train_dataset, min_freq=2)\n",
        "print('Source vocab size =', len(source_field.vocab))\n",
        "\n",
        "target_field.build_vocab(train_dataset, min_freq=2)\n",
        "print('Target vocab size =', len(target_field.vocab))\n",
        "\n",
        "train_iter, test_iter = BucketIterator.splits(\n",
        "    datasets=(train_dataset, test_dataset), batch_sizes=(32, 512), shuffle=True, device=DEVICE, sort=False\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train size = 83261\n",
            "Test size = 14693\n",
            "Source vocab size = 6296\n",
            "Target vocab size = 14073\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8FYJe2CA8GcY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Seq2seq модель\n",
        "\n",
        "Старая модель выглядела так:"
      ]
    },
    {
      "metadata": {
        "id": "x8ndCRZLl4ZZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim=128, rnn_hidden_dim=256, num_layers=1, bidirectional=False):\n",
        "        super().__init__()\n",
        "\n",
        "        self._emb = nn.Embedding(vocab_size, emb_dim)\n",
        "        self._rnn = nn.GRU(input_size=emb_dim, hidden_size=rnn_hidden_dim, \n",
        "                           num_layers=num_layers, bidirectional=bidirectional)\n",
        "\n",
        "    def forward(self, inputs, hidden=None):\n",
        "        encoder_output, encoder_hidden = self._rnn(self._emb(inputs), hidden)\n",
        "        return encoder_output, encoder_hidden"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Un0AOmdqLPp_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim=128, rnn_hidden_dim=256, attn_dim=128, num_layers=1):\n",
        "        super().__init__()\n",
        "\n",
        "        self._emb = nn.Embedding(vocab_size, emb_dim)\n",
        "        self._attention = MultiplicativeAttention(rnn_hidden_dim, rnn_hidden_dim, attn_dim)\n",
        "        self._rnn = nn.GRU(input_size=emb_dim + rnn_hidden_dim, \n",
        "                           hidden_size=rnn_hidden_dim, num_layers=num_layers)\n",
        "        self._out = nn.Linear(rnn_hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, inputs, encoder_output, encoder_mask, hidden=None):\n",
        "        embs = self._emb(inputs)\n",
        "        outputs, attentions = [], []\n",
        "        key_proj = self._attention._key_layer(encoder_output)\n",
        "        for i in range(embs.shape[0]):\n",
        "            # encoder_output (seq_len, batch_size, rnn_hidden_dim)\n",
        "            # hidden (1, batch_size, rnn_hidden_dim)\n",
        "            context, f_att = self._attention(query=hidden, key_proj=key_proj, \n",
        "                                             value=encoder_output, mask=encoder_mask)\n",
        "            context = context.unsqueeze(0)\n",
        "            rnn_input = torch.cat((embs[i: i+1], context), -1)\n",
        "            output, hidden = self._rnn(rnn_input, hidden)\n",
        "            \n",
        "            outputs.append(output)\n",
        "            attentions.append(f_att)\n",
        "            \n",
        "        output = torch.cat(outputs)\n",
        "        attentions = torch.cat(attentions)\n",
        "        return self._out(output), hidden, attentions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VfeVlIqTm4Ss",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Реализация attention'а\n",
        "\n",
        "В общем случае, attention работает так: пусть у нас есть набор скрытых состояний $\\mathbf{s}_1, \\ldots, \\mathbf{s}_m$ - представлений слов из исходного языка, полученных с помощью энкодера. И есть некоторое текущее скрытое состояние $\\mathbf{h}_i$ - скажем, представление, используемое для предсказания слова на нужном нам языке.\n",
        "\n",
        "Тогда с помощью аттеншена мы можем получить взвешенное представление контекста $\\mathbf{s}_1, \\ldots, \\mathbf{s}_m$ - вектор $\\mathbf{c}_i$:\n",
        "$$\n",
        "\\begin{align}\\begin{split}\n",
        "\\mathbf{c}_i &= \\sum\\limits_j a_{ij}\\mathbf{s}_j\\\\\n",
        "\\mathbf{a}_{ij} &= \\text{softmax}(f_{att}(\\mathbf{h}_i, \\mathbf{s}_j))\n",
        "\\end{split}\\end{align}\n",
        "$$\n",
        "\n",
        "$f_{att}$ - функция, которая говорит, насколько хорошо $\\mathbf{h}_i$ и $\\mathbf{s}_j$ подходят друг другу.\n",
        "\n",
        "Самые популярные её варианты:\n",
        "- Additive attention:\n",
        "$$f_{att}(\\mathbf{h}_i, \\mathbf{s}_j) = \\mathbf{v}_a{}^\\top \\text{tanh}(\\mathbf{W}_a\\mathbf{h}_i + \\mathbf{W}_b\\mathbf{s}_j)$$\n",
        "- Dot attention:\n",
        "$$f_{att}(\\mathbf{h}_i, \\mathbf{s}_j) = \\mathbf{h}_i^\\top \\mathbf{s}_j$$\n",
        "- Multiplicative attention:\n",
        "$$f_{att}(\\mathbf{h}_i, \\mathbf{s}_j) = \\mathbf{h}_i^\\top \\mathbf{W}_a \\mathbf{s}_j$$\n",
        "\n",
        "**Задание** Реализуйте Additive attention."
      ]
    },
    {
      "metadata": {
        "id": "Q-LQGNWWw0kh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class AdditiveAttention(nn.Module):\n",
        "    def __init__(self, query_size, key_size, hidden_dim):\n",
        "        super().__init__()\n",
        "        \n",
        "        self._query_layer = nn.Linear(query_size, hidden_dim)\n",
        "        self._key_layer = nn.Linear(key_size, hidden_dim)\n",
        "        self._energy_layer = nn.Linear(hidden_dim, 1)\n",
        "        \n",
        "    def forward(self, query, key_proj, value, mask):\n",
        "        # key (seq_len, batch_size, rnn_hidden_dim)\n",
        "        # query (1, batch_size, rnn_hidden_dim)\n",
        "        query = self._query_layer(query)\n",
        "        f_att = self._energy_layer(torch.tanh(query + key_proj))\n",
        "        f_att.data.masked_fill_(mask.unsqueeze(2), -float('inf'))\n",
        "        \n",
        "        # f_att (seq_len, batch_size, 1)\n",
        "        \n",
        "        f_att = F.softmax(f_att, 0)\n",
        "        \n",
        "        scores = f_att * value\n",
        "        \n",
        "        return scores.sum(0), f_att"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Im_cU6aD78F_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class DotAttention(nn.Module):\n",
        "    def __init__(self, query_size, key_size, hidden_dim):  # query_size == hidden_dim, \n",
        "        # но пусть будет как отдельная переменная, чтобы не переписывать декодер\n",
        "        super().__init__()\n",
        "        \n",
        "        self._key_layer = nn.Linear(key_size, hidden_dim)\n",
        "        \n",
        "    def forward(self, query, key_proj, value, mask):\n",
        "        # key (seq_len, batch_size, rnn_hidden_dim)\n",
        "        # query (1, batch_size, rnn_hidden_dim)\n",
        "        \n",
        "        query = query.permute(1, 2, 0)\n",
        "        key_proj = key_proj.permute(1, 0, 2)\n",
        "        f_att = query.new_zeros([key_proj.shape[0], key_proj.shape[1], query.shape[1]])  # (batch_size, seq_len, 1)\n",
        "        for i in range(key_proj.shape[0]):\n",
        "            f_att[i] = torch.matmul(key_proj[i], query[i])\n",
        "        f_att = f_att.permute(1, 0, 2)\n",
        "        \n",
        "        f_att.data.masked_fill_(mask.unsqueeze(2), -float('inf'))\n",
        "        \n",
        "        # f_att (seq_len, batch_size, 1)\n",
        "        \n",
        "        f_att = F.softmax(f_att, 0)\n",
        "        \n",
        "        scores = f_att * value\n",
        "        \n",
        "        return scores.sum(0), f_att"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sB7NIaBrdYY8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class MultiplicativeAttention(nn.Module):\n",
        "    def __init__(self, query_size, key_size, hidden_dim):\n",
        "        super().__init__()\n",
        "        \n",
        "        self._query_layer = nn.Linear(query_size, hidden_dim)\n",
        "        self._key_layer = nn.Linear(key_size, hidden_dim)\n",
        "        \n",
        "    def forward(self, query, key_proj, value, mask):\n",
        "        # key (seq_len, batch_size, rnn_hidden_dim)\n",
        "        # query (1, batch_size, rnn_hidden_dim)\n",
        "        query = self._query_layer(query)\n",
        "        \n",
        "        query = query.permute(1, 2, 0)\n",
        "        key_proj = key_proj.permute(1, 0, 2)\n",
        "        f_att = query.new_zeros([key_proj.shape[0], key_proj.shape[1], query.shape[1]])  # (batch_size, seq_len, 1)\n",
        "        for i in range(key_proj.shape[0]):\n",
        "            f_att[i] = torch.matmul(key_proj[i], query[i])\n",
        "        f_att = f_att.permute(1, 0, 2)\n",
        "        \n",
        "        f_att.data.masked_fill_(mask.unsqueeze(2), -float('inf'))\n",
        "        \n",
        "        # f_att (seq_len, batch_size, 1)\n",
        "        \n",
        "        f_att = F.softmax(f_att, 0)\n",
        "        \n",
        "        scores = f_att * value\n",
        "        \n",
        "        return scores.sum(0), f_att"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dRoRQ0-IncKq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Нужно обновить `Decoder`, чтобы он работал с attention'ом:  \n",
        "![](https://image.ibb.co/fB12nq/2018-11-12-23-34-06.png =x500)  \n",
        "*From [Attention and Augmented Recurrent Neural Networks](https://distill.pub/2016/augmented-rnns/#attentional-interfaces)*\n",
        "\n",
        "На каждом шаге rnn'ки будем использовать текущее скрытое состояние декодера, чтобы определить, какие из состояний энкодера самые интересные.\n",
        "\n",
        "Выход attention'а (текущий контекст) будем конкатенировать к эмбеддингу слова.\n",
        "\n",
        "**Задание** Обновите `Decoder`."
      ]
    },
    {
      "metadata": {
        "id": "ySJ4tUAqvFvB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch = next(iter(train_iter))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n9nsO1HCmgn3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Модель перевода будет просто сперва вызывать Encoder, а потом передавать его скрытое состояние декодеру в качестве начального."
      ]
    },
    {
      "metadata": {
        "id": "vLIGjPOiO7X9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class TranslationModel(nn.Module):\n",
        "    def __init__(self, source_vocab_size, target_vocab_size, emb_dim=64, rnn_hidden_dim=128, \n",
        "                 attn_dim=128, num_layers=1, bidirectional_encoder=False):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = Encoder(source_vocab_size, emb_dim, rnn_hidden_dim, num_layers, bidirectional_encoder)\n",
        "        self.decoder = Decoder(target_vocab_size, emb_dim, rnn_hidden_dim, attn_dim, num_layers)\n",
        "        \n",
        "    def forward(self, source_inputs, target_inputs):\n",
        "        encoder_mask = source_inputs == 1\n",
        "        encoder_output, encoder_hidden = self.encoder(source_inputs)\n",
        "        \n",
        "        return self.decoder(target_inputs, encoder_output, encoder_mask, encoder_hidden)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5_qVuSL8QJg4",
        "colab_type": "code",
        "outputId": "5446413f-02ae-4994-9e9d-f064a5d3b9f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "model = TranslationModel(source_vocab_size=len(source_field.vocab), target_vocab_size=len(target_field.vocab)).to(DEVICE)\n",
        "\n",
        "model(batch.source, batch.target)[0].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([17, 32, 14120])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "W71i85Q4pdOS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Тренировка модели"
      ]
    },
    {
      "metadata": {
        "id": "YjYA3eohGlOA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "\n",
        "def evaluate_model(model, iterator):\n",
        "    model.eval()\n",
        "    refs, hyps = [], []\n",
        "    bos_index = iterator.dataset.fields['target'].vocab.stoi[BOS_TOKEN]\n",
        "    eos_index = iterator.dataset.fields['target'].vocab.stoi[EOS_TOKEN]\n",
        "    with torch.no_grad():\n",
        "        for i, batch in enumerate(iterator):\n",
        "            encoder_output, encoder_hidden = model.encoder(batch.source)\n",
        "            mask = batch.source == 1.\n",
        "            \n",
        "            hidden = encoder_hidden\n",
        "            result = [LongTensor([bos_index]).expand(1, batch.target.shape[1])]\n",
        "            \n",
        "            for _ in range(30):\n",
        "                step, hidden, _ = model.decoder(result[-1], encoder_output, mask, hidden)\n",
        "                step = step.argmax(-1)\n",
        "                result.append(step)\n",
        "            \n",
        "            targets = batch.target.data.cpu().numpy().T\n",
        "            eos_indices = (targets == eos_index).argmax(-1)\n",
        "            eos_indices[eos_indices == 0] = targets.shape[1]\n",
        "\n",
        "            targets = [target[:eos_ind] for eos_ind, target in zip(eos_indices, targets)]\n",
        "            refs.extend(targets)\n",
        "            \n",
        "            result = torch.cat(result)\n",
        "            result = result.data.cpu().numpy().T\n",
        "            eos_indices = (result == eos_index).argmax(-1)\n",
        "            eos_indices[eos_indices == 0] = result.shape[1]\n",
        "\n",
        "            result = [res[:eos_ind] for eos_ind, res in zip(eos_indices, result)]\n",
        "            hyps.extend(result)\n",
        "            \n",
        "    return corpus_bleu([[ref] for ref in refs], hyps) * 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mhVPgFNsousF",
        "colab_type": "code",
        "outputId": "d9f0858d-32c8-49f5-cca6-bf55a24e1cc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "cell_type": "code",
      "source": [
        "evaluate_model(model, test_iter)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "42.467682589111234"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "_E2JxfRuphch",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import math\n",
        "from tqdm import tqdm\n",
        "tqdm.get_lock().locks = []\n",
        "\n",
        "\n",
        "def do_epoch(model, criterion, data_iter, optimizer=None, name=None):\n",
        "    epoch_loss = 0\n",
        "    \n",
        "    is_train = not optimizer is None\n",
        "    name = name or ''\n",
        "    model.train(is_train)\n",
        "    \n",
        "    batches_count = len(data_iter)\n",
        "    \n",
        "    with torch.autograd.set_grad_enabled(is_train):\n",
        "        with tqdm(total=batches_count) as progress_bar:\n",
        "            for i, batch in enumerate(data_iter):                \n",
        "                logits, _, _ = model(batch.source, batch.target)\n",
        "                \n",
        "                target = torch.cat((batch.target[1:], batch.target.new_ones((1, batch.target.shape[1]))))\n",
        "                loss = criterion(logits.view(-1, logits.shape[-1]), target.view(-1))\n",
        "\n",
        "                epoch_loss += loss.item()\n",
        "\n",
        "                if optimizer:\n",
        "                    optimizer.zero_grad()\n",
        "                    loss.backward()\n",
        "                    nn.utils.clip_grad_norm_(model.parameters(), 1.)\n",
        "                    optimizer.step()\n",
        "\n",
        "                progress_bar.update()\n",
        "                progress_bar.set_description('{:>5s} Loss = {:.5f}, PPX = {:.2f}'.format(name, loss.item(), \n",
        "                                                                                         math.exp(loss.item())))\n",
        "                \n",
        "            progress_bar.set_description('{:>5s} Loss = {:.5f}, PPX = {:.2f}'.format(\n",
        "                name, epoch_loss / batches_count, math.exp(epoch_loss / batches_count))\n",
        "            )\n",
        "            progress_bar.refresh()\n",
        "\n",
        "    return epoch_loss / batches_count\n",
        "\n",
        "\n",
        "def fit(model, criterion, optimizer, train_iter, epochs_count=1, val_iter=None):\n",
        "    best_val_loss = None\n",
        "    for epoch in range(epochs_count):\n",
        "        name_prefix = '[{} / {}] '.format(epoch + 1, epochs_count)\n",
        "        train_loss = do_epoch(model, criterion, train_iter, optimizer, name_prefix + 'Train:')\n",
        "        \n",
        "        if not val_iter is None:\n",
        "            val_loss = do_epoch(model, criterion, val_iter, None, name_prefix + '  Val:')\n",
        "            print('\\nVal BLEU = {:.2f}'.format(evaluate_model(model, val_iter)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5X2kYDU_rCjP",
        "colab_type": "code",
        "outputId": "337998e9-93f7-4e36-c299-3887204dedb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1276
        }
      },
      "cell_type": "code",
      "source": [
        "model = TranslationModel(source_vocab_size=len(source_field.vocab), target_vocab_size=len(target_field.vocab)).to(DEVICE)\n",
        "\n",
        "pad_idx = target_field.vocab.stoi['<pad>']\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx).to(DEVICE)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "fit(model, criterion, optimizer, train_iter, epochs_count=11, val_iter=test_iter)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 / 30] Train: Loss = 3.68497, PPX = 39.84: 100%|██████████| 2602/2602 [03:39<00:00, 11.85it/s]\n",
            "[1 / 30]   Val: Loss = 2.80175, PPX = 16.47: 100%|██████████| 29/29 [00:02<00:00, 12.51it/s]\n",
            "  0%|          | 0/2602 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 20.02\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[2 / 30] Train: Loss = 2.48598, PPX = 12.01: 100%|██████████| 2602/2602 [03:39<00:00, 11.87it/s]\n",
            "[2 / 30]   Val: Loss = 2.25788, PPX = 9.56: 100%|██████████| 29/29 [00:02<00:00, 11.91it/s]\n",
            "[3 / 30] Train: Loss = 1.88807, PPX = 6.61:   0%|          | 1/2602 [00:00<08:01,  5.40it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 26.27\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[3 / 30] Train: Loss = 1.95232, PPX = 7.05: 100%|██████████| 2602/2602 [03:41<00:00, 11.74it/s]\n",
            "[3 / 30]   Val: Loss = 1.99299, PPX = 7.34: 100%|██████████| 29/29 [00:02<00:00, 11.92it/s]\n",
            "  0%|          | 0/2602 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 29.76\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[4 / 30] Train: Loss = 1.61115, PPX = 5.01: 100%|██████████| 2602/2602 [03:43<00:00, 11.65it/s]\n",
            "[4 / 30]   Val: Loss = 1.85210, PPX = 6.37: 100%|██████████| 29/29 [00:02<00:00, 12.40it/s]\n",
            "  0%|          | 0/2602 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 31.81\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[5 / 30] Train: Loss = 1.37641, PPX = 3.96: 100%|██████████| 2602/2602 [03:46<00:00, 11.48it/s]\n",
            "[5 / 30]   Val: Loss = 1.75779, PPX = 5.80: 100%|██████████| 29/29 [00:02<00:00, 12.53it/s]\n",
            "  0%|          | 0/2602 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 33.45\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[6 / 30] Train: Loss = 1.20307, PPX = 3.33: 100%|██████████| 2602/2602 [03:46<00:00, 11.35it/s]\n",
            "[6 / 30]   Val: Loss = 1.71565, PPX = 5.56: 100%|██████████| 29/29 [00:02<00:00, 12.44it/s]\n",
            "  0%|          | 0/2602 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 34.14\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[7 / 30] Train: Loss = 1.07328, PPX = 2.92: 100%|██████████| 2602/2602 [03:37<00:00, 11.96it/s]\n",
            "[7 / 30]   Val: Loss = 1.68648, PPX = 5.40: 100%|██████████| 29/29 [00:02<00:00, 12.56it/s]\n",
            "  0%|          | 0/2602 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 34.73\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[8 / 30]   Val: Loss = 1.67635, PPX = 5.35: 100%|██████████| 29/29 [00:02<00:00, 12.17it/s]\n",
            "  0%|          | 0/2602 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 34.83\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[9 / 30] Train: Loss = 0.88609, PPX = 2.43: 100%|██████████| 2602/2602 [03:41<00:00, 11.72it/s]\n",
            "[9 / 30]   Val: Loss = 1.67105, PPX = 5.32: 100%|██████████| 29/29 [00:02<00:00, 11.97it/s]\n",
            "  0%|          | 0/2602 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 35.32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[10 / 30] Train: Loss = 0.81763, PPX = 2.27: 100%|██████████| 2602/2602 [03:43<00:00, 11.65it/s]\n",
            "[10 / 30]   Val: Loss = 1.67648, PPX = 5.35: 100%|██████████| 29/29 [00:02<00:00, 11.69it/s]\n",
            "  0%|          | 1/2602 [00:00<08:30,  5.09it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 35.37\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[11 / 30] Train: Loss = 0.64765, PPX = 1.91:   6%|▋         | 163/2602 [00:14<03:31, 11.53it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-a255522ba2f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-17-73fed5214515>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, criterion, optimizer, train_iter, epochs_count, val_iter)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mname_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'[{} / {}] '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdo_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_prefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'Train:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mval_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-73fed5214515>\u001b[0m in \u001b[0;36mdo_epoch\u001b[0;34m(model, criterion, data_iter, optimizer, name)\u001b[0m\n\u001b[1;32m     27\u001b[0m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                     \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0mprogress_bar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m                 \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "KW2dh6Ntcy70",
        "colab_type": "code",
        "outputId": "9e173086-1075-45dd-b4c3-a06212bde0ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1646
        }
      },
      "cell_type": "code",
      "source": [
        "# dot attention\n",
        "model = TranslationModel(source_vocab_size=len(source_field.vocab), target_vocab_size=len(target_field.vocab)).to(DEVICE)\n",
        "\n",
        "pad_idx = target_field.vocab.stoi['<pad>']\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx).to(DEVICE)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "fit(model, criterion, optimizer, train_iter, epochs_count=11, val_iter=test_iter)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 / 11] Train: Loss = 3.85116, PPX = 47.05: 100%|██████████| 2602/2602 [17:49<00:00,  2.44it/s]\n",
            "[1 / 11]   Val: Loss = 3.02249, PPX = 20.54: 100%|██████████| 29/29 [00:38<00:00,  1.31s/it]\n",
            "  0%|          | 0/2602 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 16.30\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[2 / 11] Train: Loss = 2.72619, PPX = 15.27: 100%|██████████| 2602/2602 [17:58<00:00,  2.49it/s]\n",
            "[2 / 11]   Val: Loss = 2.47815, PPX = 11.92: 100%|██████████| 29/29 [00:39<00:00,  1.34s/it]\n",
            "  0%|          | 0/2602 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 22.32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[3 / 11] Train: Loss = 2.19067, PPX = 8.94: 100%|██████████| 2602/2602 [17:56<00:00,  2.51it/s]\n",
            "[3 / 11]   Val: Loss = 2.18227, PPX = 8.87: 100%|██████████| 29/29 [00:38<00:00,  1.37s/it]\n",
            "  0%|          | 0/2602 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 25.71\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[4 / 11] Train: Loss = 1.84095, PPX = 6.30: 100%|██████████| 2602/2602 [17:48<00:00,  2.49it/s]\n",
            "[4 / 11]   Val: Loss = 2.02281, PPX = 7.56: 100%|██████████| 29/29 [00:38<00:00,  1.30s/it]\n",
            "  0%|          | 0/2602 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 27.59\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[5 / 11] Train: Loss = 1.59005, PPX = 4.90: 100%|██████████| 2602/2602 [17:31<00:00,  2.63it/s]\n",
            "[5 / 11]   Val: Loss = 1.91361, PPX = 6.78: 100%|██████████| 29/29 [00:37<00:00,  1.23s/it]\n",
            "  0%|          | 0/2602 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 29.02\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[6 / 11] Train: Loss = 1.40119, PPX = 4.06: 100%|██████████| 2602/2602 [17:25<00:00,  2.77it/s]\n",
            "[6 / 11]   Val: Loss = 1.84258, PPX = 6.31: 100%|██████████| 29/29 [00:37<00:00,  1.27s/it]\n",
            "  0%|          | 0/2602 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 30.26\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[7 / 11] Train: Loss = 1.25440, PPX = 3.51: 100%|██████████| 2602/2602 [17:25<00:00,  2.48it/s]\n",
            "[7 / 11]   Val: Loss = 1.79938, PPX = 6.05: 100%|██████████| 29/29 [00:38<00:00,  1.34s/it]\n",
            "  0%|          | 0/2602 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 31.48\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[8 / 11] Train: Loss = 1.13781, PPX = 3.12: 100%|██████████| 2602/2602 [17:32<00:00,  2.54it/s]\n",
            "[8 / 11]   Val: Loss = 1.77347, PPX = 5.89: 100%|██████████| 29/29 [00:38<00:00,  1.27s/it]\n",
            "  0%|          | 0/2602 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 31.66\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[9 / 11] Train: Loss = 1.04226, PPX = 2.84: 100%|██████████| 2602/2602 [17:46<00:00,  2.63it/s]\n",
            "[9 / 11]   Val: Loss = 1.76640, PPX = 5.85: 100%|██████████| 29/29 [00:38<00:00,  1.35s/it]\n",
            "  0%|          | 0/2602 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 31.83\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[10 / 11] Train: Loss = 0.96338, PPX = 2.62: 100%|██████████| 2602/2602 [17:51<00:00,  2.44it/s]\n",
            "[10 / 11]   Val: Loss = 1.75827, PPX = 5.80: 100%|██████████| 29/29 [00:38<00:00,  1.37s/it]\n",
            "  0%|          | 0/2602 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 32.38\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[11 / 11] Train: Loss = 0.89784, PPX = 2.45: 100%|██████████| 2602/2602 [17:52<00:00,  2.43it/s]\n",
            "[11 / 11]   Val: Loss = 1.75908, PPX = 5.81: 100%|██████████| 29/29 [00:38<00:00,  1.32s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-e75a066cf3ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-15-73fed5214515>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, criterion, optimizer, train_iter, epochs_count, val_iter)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mval_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdo_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_prefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'  Val:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nVal BLEU = {:.2f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-5c933a382c44>\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                 \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m                 \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-fd4b3b13e89f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, encoder_output, encoder_mask, hidden)\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;31m# hidden (1, batch_size, rnn_hidden_dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             context, f_att = self._attention(query=hidden, key_proj=key_proj, \n\u001b[0;32m---> 19\u001b[0;31m                                              value=encoder_output, mask=encoder_mask)\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mrnn_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-799357993bc1>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query, key_proj, value, mask)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mf_att\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_zeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey_proj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_proj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (batch_size, seq_len, 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey_proj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mf_att\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey_proj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mf_att\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf_att\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "DQpyc0mSl0e6",
        "colab_type": "code",
        "outputId": "e9a753c4-7c14-48ce-f488-7bbcf94102a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 791
        }
      },
      "cell_type": "code",
      "source": [
        "#multiplicative attention\n",
        "model = TranslationModel(source_vocab_size=len(source_field.vocab), target_vocab_size=len(target_field.vocab)).to(DEVICE)\n",
        "\n",
        "pad_idx = target_field.vocab.stoi['<pad>']\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx).to(DEVICE)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "fit(model, criterion, optimizer, train_iter, epochs_count=11, val_iter=test_iter)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 / 11] Train: Loss = 3.82332, PPX = 45.76: 100%|██████████| 2602/2602 [18:21<00:00,  2.43it/s]\n",
            "[1 / 11]   Val: Loss = 3.01535, PPX = 20.40: 100%|██████████| 29/29 [00:38<00:00,  1.28s/it]\n",
            "  0%|          | 0/2602 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 15.85\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[2 / 11] Train: Loss = 2.73592, PPX = 15.42: 100%|██████████| 2602/2602 [18:26<00:00,  2.47it/s]\n",
            "[2 / 11]   Val: Loss = 2.50979, PPX = 12.30: 100%|██████████| 29/29 [00:38<00:00,  1.37s/it]\n",
            "  0%|          | 0/2602 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 21.07\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[3 / 11] Train: Loss = 2.22440, PPX = 9.25: 100%|██████████| 2602/2602 [18:21<00:00,  2.30it/s]\n",
            "[3 / 11]   Val: Loss = 2.24420, PPX = 9.43: 100%|██████████| 29/29 [00:39<00:00,  1.40s/it]\n",
            "  0%|          | 0/2602 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 23.71\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[4 / 11] Train: Loss = 1.88182, PPX = 6.57: 100%|██████████| 2602/2602 [18:30<00:00,  2.46it/s]\n",
            "[4 / 11]   Val: Loss = 2.08018, PPX = 8.01: 100%|██████████| 29/29 [00:39<00:00,  1.36s/it]\n",
            "  0%|          | 0/2602 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 25.71\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[5 / 11] Train: Loss = 1.63063, PPX = 5.11: 100%|██████████| 2602/2602 [18:24<00:00,  2.26it/s]\n",
            "[5 / 11]   Val: Loss = 1.98563, PPX = 7.28: 100%|██████████| 29/29 [00:38<00:00,  1.36s/it]\n",
            "  0%|          | 0/2602 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 27.20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[6 / 11] Train: Loss = 1.43786, PPX = 4.21: 100%|██████████| 2602/2602 [18:21<00:00,  2.53it/s]\n",
            "[6 / 11]   Val: Loss = 1.92170, PPX = 6.83: 100%|██████████| 29/29 [00:38<00:00,  1.33s/it]\n",
            "  0%|          | 0/2602 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 27.82\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[7 / 11] Train: Loss = 1.28593, PPX = 3.62: 100%|██████████| 2602/2602 [18:21<00:00,  2.39it/s]\n",
            "[7 / 11]   Val: Loss = 1.88094, PPX = 6.56: 100%|██████████| 29/29 [00:38<00:00,  1.37s/it]\n",
            "  0%|          | 0/2602 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 28.66\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[8 / 11] Train: Loss = 1.16263, PPX = 3.20: 100%|██████████| 2602/2602 [18:29<00:00,  2.44it/s]\n",
            "[8 / 11]   Val: Loss = 1.86132, PPX = 6.43: 100%|██████████| 29/29 [00:38<00:00,  1.37s/it]\n",
            "  0%|          | 0/2602 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 29.11\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[9 / 11] Train: Loss = 1.06060, PPX = 2.89: 100%|██████████| 2602/2602 [18:32<00:00,  2.39it/s]\n",
            "[9 / 11]   Val: Loss = 1.85333, PPX = 6.38: 100%|██████████| 29/29 [00:38<00:00,  1.26s/it]\n",
            "  0%|          | 0/2602 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 29.39\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[10 / 11] Train: Loss = 0.97707, PPX = 2.66: 100%|██████████| 2602/2602 [18:27<00:00,  2.65it/s]\n",
            "[10 / 11]   Val: Loss = 1.85169, PPX = 6.37: 100%|██████████| 29/29 [00:38<00:00,  1.33s/it]\n",
            "  0%|          | 0/2602 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 29.89\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[11 / 11] Train: Loss = 0.90639, PPX = 2.48: 100%|██████████| 2602/2602 [18:33<00:00,  2.21it/s]\n",
            "[11 / 11]   Val: Loss = 1.85992, PPX = 6.42: 100%|██████████| 29/29 [00:38<00:00,  1.31s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 29.81\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "H0_U9etCpf17",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Визуализация результатов"
      ]
    },
    {
      "metadata": {
        "id": "h9gmcOC9DwiS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def greedy_decode(model, source_text, source_field, target_field):\n",
        "    bos_index = target_field.vocab.stoi[BOS_TOKEN]\n",
        "    eos_index = target_field.vocab.stoi[EOS_TOKEN]\n",
        "    \n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        result, attentions = [], []\n",
        "        source = source_field.preprocess(source_text)\n",
        "        inputs = source_field.process([source]).to(DEVICE)\n",
        "        \n",
        "        encoder_output, encoder_hidden = model.encoder(inputs)\n",
        "        encoder_mask = torch.zeros_like(inputs).byte()\n",
        "        \n",
        "        hidden = encoder_hidden\n",
        "        step = LongTensor([[bos_index]])\n",
        "        \n",
        "        for _ in range(50):\n",
        "            step, hidden, attention = model.decoder(step, encoder_output, encoder_mask, hidden)\n",
        "            step = step.argmax(-1)\n",
        "            attentions.append(attention.squeeze(1))\n",
        "          \n",
        "            if step.squeeze().item() == eos_index:\n",
        "                break\n",
        "            \n",
        "            result.append(step.item())   \n",
        "        result = [target_field.vocab.itos[ind] for ind in result]\n",
        "        return source, result, torch.cat(attentions, -1).data.cpu().numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "02c9efn3UmAX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "def plot_heatmap(src, trg, scores):\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    heatmap = ax.pcolor(scores, cmap='viridis')\n",
        "\n",
        "    ax.set_xticklabels(trg, minor=False, rotation=45)\n",
        "    ax.set_yticklabels(src, minor=False)\n",
        "\n",
        "    ax.xaxis.tick_top()\n",
        "    ax.set_xticks(np.arange(scores.shape[1]) + 0.5, minor=False)\n",
        "    ax.set_yticks(np.arange(scores.shape[0]) + 0.5, minor=False)\n",
        "    ax.invert_yaxis()\n",
        "\n",
        "    plt.colorbar(heatmap)\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mM58pAd6FBml",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "source, result, attentions = greedy_decode(model, \"He lied to me.\", source_field, target_field)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y1rAgHXFlY7h",
        "colab_type": "code",
        "outputId": "6d8ec22a-0dac-407a-ba6e-b26af82b5be9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "result"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['он', 'мне', 'соврал', '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "metadata": {
        "id": "CTc7DiogUYTI",
        "colab_type": "code",
        "outputId": "8c962ba2-a178-4772-a89c-91d73a575d2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "cell_type": "code",
      "source": [
        "plot_heatmap(source + ['</s>'], ['<s>'] + result + ['</s>'], attentions)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWUAAAETCAYAAADu/hdnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fe6d75e79e8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "jWX_Z8r18XRs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Улучшение модели\n",
        "\n",
        "**Задание** Попробуйте другие варианты attention'а (из приведенных выше).\n",
        "\n",
        "**Задание** Попробуйте приемы из тех, что были в предыдущем ноутбуке: bpe, dropout, bidirectional or multi-layer encoder."
      ]
    },
    {
      "metadata": {
        "id": "gu7GPqbcu59v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from subword_nmt.learn_bpe import learn_bpe\n",
        "from subword_nmt.apply_bpe import BPE\n",
        "\n",
        "with open('data.en', 'w') as f_src, open('data.ru', 'w') as f_dst:\n",
        "    for example in examples:\n",
        "        f_src.write(' '.join(example.source) + '\\n')\n",
        "        f_dst.write(' '.join(example.target) + '\\n')\n",
        "\n",
        "bpe = {}\n",
        "for lang in ['en', 'ru']:\n",
        "    with open('./data.' + lang) as f_data, open('bpe_rules.' + lang, 'w') as f_rules:\n",
        "        learn_bpe(f_data, f_rules, num_symbols=3000)\n",
        "    with open('bpe_rules.' + lang) as f_rules:\n",
        "        bpe[lang] = BPE(f_rules)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o-9y3iP0u-55",
        "colab_type": "code",
        "outputId": "df38b0ec-86da-40cd-c38a-250fa92a313f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        }
      },
      "cell_type": "code",
      "source": [
        "from torchtext.data import Field, Example, Dataset, BucketIterator\n",
        "\n",
        "BOS_TOKEN = '<s>'\n",
        "EOS_TOKEN = '</s>'\n",
        "\n",
        "source_field = Field(tokenize='spacy', init_token=None, eos_token=EOS_TOKEN)\n",
        "target_field = Field(tokenize='moses', init_token=BOS_TOKEN, eos_token=EOS_TOKEN)\n",
        "fields = [('source', source_field), ('target', target_field)]\n",
        "source_field.preprocess(bpe['en'].process_line(\"It's surprising that you haven't heard anything about her wedding.\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I@@',\n",
              " 't@@',\n",
              " \"'s\",\n",
              " 'surpri@@',\n",
              " 'sing',\n",
              " 'that',\n",
              " 'you',\n",
              " 'ha@@',\n",
              " 've@@',\n",
              " \"n't\",\n",
              " 'heard',\n",
              " 'anything',\n",
              " 'about',\n",
              " 'her',\n",
              " 'we@@',\n",
              " 'd@@',\n",
              " 'din@@',\n",
              " 'g@@',\n",
              " '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "yhrapkawvCP2",
        "colab_type": "code",
        "outputId": "19b4bb7f-93a3-4330-84e8-fcbab3ff8ccc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "MAX_TOKENS_COUNT = 16\n",
        "SUBSET_SIZE = .3\n",
        "\n",
        "examples = []\n",
        "with open('rus.txt') as f:\n",
        "    for line in tqdm(f, total=328190):\n",
        "        source_text, target_text = line.split('\\t')\n",
        "        source_text = bpe['en'].process_line(source_text)\n",
        "        target_text = bpe['ru'].process_line(target_text)\n",
        "        source_text = source_field.preprocess(source_text)\n",
        "        target_text = target_field.preprocess(target_text)\n",
        "        if len(source_text) <= MAX_TOKENS_COUNT and len(target_text) <= MAX_TOKENS_COUNT:\n",
        "            if np.random.rand() < SUBSET_SIZE:\n",
        "                examples.append(Example.fromlist([source_text, target_text], fields))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 328190/328190 [03:15<00:00, 1680.12it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "unekhj1lvE9I",
        "colab_type": "code",
        "outputId": "d98d178e-e9ce-470f-f535-e4aeaab86fd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "cell_type": "code",
      "source": [
        "dataset = Dataset(examples, fields)\n",
        "\n",
        "train_dataset, test_dataset = dataset.split(split_ratio=0.85)\n",
        "\n",
        "print('Train size =', len(train_dataset))\n",
        "print('Test size =', len(test_dataset))\n",
        "\n",
        "source_field.build_vocab(train_dataset, min_freq=3)\n",
        "print('Source vocab size =', len(source_field.vocab))\n",
        "\n",
        "target_field.build_vocab(train_dataset, min_freq=3)\n",
        "print('Target vocab size =', len(target_field.vocab))\n",
        "\n",
        "train_iter, test_iter = BucketIterator.splits(\n",
        "    datasets=(train_dataset, test_dataset), batch_sizes=(32, 256), shuffle=True, device=DEVICE, sort=False\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train size = 22393\n",
            "Test size = 3952\n",
            "Source vocab size = 1881\n",
            "Target vocab size = 2249\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "z_cJVCM9fX5N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim=128, rnn_hidden_dim=256, num_layers=1, bidirectional=False):\n",
        "        super().__init__()\n",
        "        self.bidirectional = bidirectional\n",
        "        self._emb = nn.Sequential(\n",
        "            nn.Embedding(vocab_size, emb_dim),\n",
        "            nn.Dropout(0.3)\n",
        "        )\n",
        "        self._rnn = nn.GRU(input_size=emb_dim, hidden_size=rnn_hidden_dim, \n",
        "                  num_layers=num_layers, bidirectional=bidirectional)\n",
        "\n",
        "    def forward(self, inputs, hidden=None):\n",
        "        encoder_output, encoder_hidden = self._rnn(self._emb(inputs), hidden)\n",
        "        if self.bidirectional:\n",
        "            encoder_hidden = torch.cat((encoder_hidden[0], encoder_hidden[1]), dim=-1).unsqueeze(0)\n",
        "        return encoder_output, encoder_hidden\n",
        "    \n",
        "class AdditiveAttention(nn.Module):\n",
        "    def __init__(self, query_size, key_size, hidden_dim):\n",
        "        super().__init__()\n",
        "        \n",
        "        self._query_layer = nn.Linear(query_size, hidden_dim)\n",
        "        self._key_layer = nn.Linear(key_size, hidden_dim)\n",
        "        self._energy_layer = nn.Linear(hidden_dim, 1)\n",
        "        \n",
        "    def forward(self, query, key_proj, value, mask):\n",
        "        # key (seq_len, batch_size, rnn_hidden_dim)\n",
        "        # query (1, batch_size, rnn_hidden_dim)\n",
        "        query = self._query_layer(query)\n",
        "        f_att = self._energy_layer(torch.tanh(query + key_proj))\n",
        "        f_att.data.masked_fill_(mask.unsqueeze(2), -float('inf'))\n",
        "        \n",
        "        # f_att (seq_len, batch_size, 1)\n",
        "        f_att = F.softmax(f_att, 0)\n",
        "        scores = f_att * value\n",
        "        \n",
        "        return scores.sum(0), f_att\n",
        "    \n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim=128, rnn_hidden_dim=256, attn_dim=128, num_layers=1):\n",
        "        super().__init__()\n",
        "\n",
        "        self._emb = nn.Sequential(\n",
        "            nn.Embedding(vocab_size, emb_dim),\n",
        "            nn.Dropout(0.3)\n",
        "        )\n",
        "        self._attention = AdditiveAttention(rnn_hidden_dim, rnn_hidden_dim, attn_dim)\n",
        "        self._rnn = nn.GRU(input_size=emb_dim + rnn_hidden_dim, \n",
        "                           hidden_size=rnn_hidden_dim, num_layers=num_layers)\n",
        "        self._out = nn.Sequential(\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(rnn_hidden_dim, vocab_size)\n",
        "        )\n",
        "\n",
        "    def forward(self, inputs, encoder_output, encoder_mask, hidden=None):\n",
        "        embs = self._emb(inputs)\n",
        "        outputs, attentions = [], []\n",
        "        key_proj = self._attention._key_layer(encoder_output)\n",
        "        for i in range(embs.shape[0]):\n",
        "            # encoder_output (seq_len, batch_size, rnn_hidden_dim)\n",
        "            # hidden (1, batch_size, rnn_hidden_dim)\n",
        "            context, f_att = self._attention(query=hidden, key_proj=key_proj, \n",
        "                                             value=encoder_output, mask=encoder_mask)\n",
        "            context = context.unsqueeze(0)\n",
        "            rnn_input = torch.cat((embs[i: i+1], context), -1)\n",
        "            output, hidden = self._rnn(rnn_input, hidden)\n",
        "            \n",
        "            outputs.append(output)\n",
        "            attentions.append(f_att)\n",
        "            \n",
        "        output = torch.cat(outputs)\n",
        "        attentions = torch.cat(attentions)\n",
        "        return self._out(output), hidden, attentions\n",
        "    \n",
        "class ImprovedTranslationModel(nn.Module):\n",
        "    def __init__(self, source_vocab_size, target_vocab_size, emb_dim=64, rnn_hidden_dim=128, \n",
        "                 attn_dim=128, num_layers=1, bidirectional_encoder=False):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = Encoder(source_vocab_size, emb_dim, rnn_hidden_dim, num_layers, bidirectional_encoder)\n",
        "        self.decoder = Decoder(target_vocab_size, emb_dim, rnn_hidden_dim * (2 if bidirectional_encoder else 1), attn_dim, num_layers)\n",
        "        \n",
        "    def forward(self, source_inputs, target_inputs):\n",
        "        encoder_mask = source_inputs == 1\n",
        "        encoder_output, encoder_hidden = self.encoder(source_inputs)\n",
        "        \n",
        "        return self.decoder(target_inputs, encoder_output, encoder_mask, encoder_hidden)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GsaXn_KZfs3C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch = next(iter(train_iter))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wdC3hzv2fuzV",
        "colab_type": "code",
        "outputId": "8be6ae5e-5085-458a-f3ae-c719893f4233",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "model = ImprovedTranslationModel(source_vocab_size=len(source_field.vocab), target_vocab_size=len(target_field.vocab)).to(DEVICE)\n",
        "\n",
        "model(batch.source, batch.target)[0].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([18, 32, 2243])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "metadata": {
        "id": "3bW_szm4vQfa",
        "colab_type": "code",
        "outputId": "f8e798eb-7bc1-41b9-9bc8-25c478cba444",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "cell_type": "code",
      "source": [
        "dataset = Dataset(examples, fields)\n",
        "\n",
        "train_dataset, test_dataset = dataset.split(split_ratio=0.85)\n",
        "\n",
        "print('Train size =', len(train_dataset))\n",
        "print('Test size =', len(test_dataset))\n",
        "\n",
        "source_field.build_vocab(train_dataset, min_freq=3)\n",
        "print('Source vocab size =', len(source_field.vocab))\n",
        "\n",
        "target_field.build_vocab(train_dataset, min_freq=3)\n",
        "print('Target vocab size =', len(target_field.vocab))\n",
        "\n",
        "train_iter, test_iter = BucketIterator.splits(\n",
        "    datasets=(train_dataset, test_dataset), batch_sizes=(32, 256), shuffle=True, device=DEVICE, sort=False\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train size = 22393\n",
            "Test size = 3952\n",
            "Source vocab size = 1881\n",
            "Target vocab size = 2249\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ztLEbmZsMuTT",
        "colab_type": "code",
        "outputId": "23ec9e69-0d95-49a9-ee44-e2400ff6837e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2129
        }
      },
      "cell_type": "code",
      "source": [
        "model = ImprovedTranslationModel(source_vocab_size=len(source_field.vocab), target_vocab_size=len(target_field.vocab)).to(DEVICE)\n",
        "\n",
        "pad_idx = target_field.vocab.stoi['<pad>']\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx).to(DEVICE)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "fit(model, criterion, optimizer, train_iter, epochs_count=30, val_iter=test_iter)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 / 30] Train: Loss = 2.58673, PPX = 13.29: 100%|██████████| 700/700 [01:07<00:00, 10.32it/s]\n",
            "[1 / 30]   Val: Loss = 2.06250, PPX = 7.87: 100%|██████████| 16/16 [00:00<00:00, 22.12it/s]\n",
            "[2 / 30] Train: Loss = 1.97302, PPX = 7.19:   0%|          | 1/700 [00:00<01:33,  7.46it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 24.32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[2 / 30] Train: Loss = 2.00575, PPX = 7.43: 100%|██████████| 700/700 [01:07<00:00, 10.32it/s]\n",
            "[2 / 30]   Val: Loss = 1.83152, PPX = 6.24: 100%|██████████| 16/16 [00:00<00:00, 22.22it/s]\n",
            "[3 / 30] Train: Loss = 1.84665, PPX = 6.34:   0%|          | 1/700 [00:00<01:29,  7.79it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 27.92\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[3 / 30] Train: Loss = 1.82611, PPX = 6.21: 100%|██████████| 700/700 [01:07<00:00, 10.42it/s]\n",
            "[3 / 30]   Val: Loss = 1.68210, PPX = 5.38: 100%|██████████| 16/16 [00:00<00:00, 21.92it/s]\n",
            "[4 / 30] Train: Loss = 1.76239, PPX = 5.83:   0%|          | 1/700 [00:00<01:29,  7.80it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 29.54\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[4 / 30] Train: Loss = 1.69643, PPX = 5.45: 100%|██████████| 700/700 [01:07<00:00, 10.33it/s]\n",
            "[4 / 30]   Val: Loss = 1.57422, PPX = 4.83: 100%|██████████| 16/16 [00:00<00:00, 22.16it/s]\n",
            "[5 / 30] Train: Loss = 1.49824, PPX = 4.47:   0%|          | 1/700 [00:00<01:30,  7.75it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 30.83\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[5 / 30] Train: Loss = 1.59077, PPX = 4.91: 100%|██████████| 700/700 [01:07<00:00, 10.32it/s]\n",
            "[5 / 30]   Val: Loss = 1.47289, PPX = 4.36: 100%|██████████| 16/16 [00:00<00:00, 22.06it/s]\n",
            "[6 / 30] Train: Loss = 1.66239, PPX = 5.27:   0%|          | 1/700 [00:00<01:29,  7.80it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 32.15\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[6 / 30] Train: Loss = 1.50209, PPX = 4.49: 100%|██████████| 700/700 [01:08<00:00, 10.28it/s]\n",
            "[6 / 30]   Val: Loss = 1.39168, PPX = 4.02: 100%|██████████| 16/16 [00:00<00:00, 22.03it/s]\n",
            "[7 / 30] Train: Loss = 1.45288, PPX = 4.28:   0%|          | 1/700 [00:00<01:36,  7.28it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 33.92\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[7 / 30] Train: Loss = 1.42639, PPX = 4.16: 100%|██████████| 700/700 [01:07<00:00, 10.30it/s]\n",
            "[7 / 30]   Val: Loss = 1.32610, PPX = 3.77: 100%|██████████| 16/16 [00:00<00:00, 22.41it/s]\n",
            "[8 / 30] Train: Loss = 1.55078, PPX = 4.72:   0%|          | 1/700 [00:00<01:30,  7.74it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 35.31\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[8 / 30] Train: Loss = 1.36077, PPX = 3.90: 100%|██████████| 700/700 [01:07<00:00, 10.31it/s]\n",
            "[8 / 30]   Val: Loss = 1.27129, PPX = 3.57: 100%|██████████| 16/16 [00:00<00:00, 22.48it/s]\n",
            "[9 / 30] Train: Loss = 1.42361, PPX = 4.15:   0%|          | 1/700 [00:00<01:31,  7.62it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 36.51\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[9 / 30] Train: Loss = 1.30374, PPX = 3.68: 100%|██████████| 700/700 [01:08<00:00, 10.35it/s]\n",
            "[9 / 30]   Val: Loss = 1.21722, PPX = 3.38: 100%|██████████| 16/16 [00:00<00:00, 22.08it/s]\n",
            "[10 / 30] Train: Loss = 1.38594, PPX = 4.00:   0%|          | 1/700 [00:00<01:29,  7.82it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 37.75\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[10 / 30] Train: Loss = 1.25487, PPX = 3.51: 100%|██████████| 700/700 [01:08<00:00, 10.37it/s]\n",
            "[10 / 30]   Val: Loss = 1.17422, PPX = 3.24: 100%|██████████| 16/16 [00:00<00:00, 22.20it/s]\n",
            "[11 / 30] Train: Loss = 1.36017, PPX = 3.90:   0%|          | 1/700 [00:00<01:29,  7.82it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 38.47\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[11 / 30] Train: Loss = 1.21106, PPX = 3.36: 100%|██████████| 700/700 [01:08<00:00, 10.39it/s]\n",
            "[11 / 30]   Val: Loss = 1.14626, PPX = 3.15: 100%|██████████| 16/16 [00:00<00:00, 22.16it/s]\n",
            "[12 / 30] Train: Loss = 1.31684, PPX = 3.73:   0%|          | 1/700 [00:00<01:28,  7.86it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 39.83\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[12 / 30] Train: Loss = 1.17360, PPX = 3.23: 100%|██████████| 700/700 [01:08<00:00, 10.22it/s]\n",
            "[12 / 30]   Val: Loss = 1.10931, PPX = 3.03: 100%|██████████| 16/16 [00:00<00:00, 21.88it/s]\n",
            "[13 / 30] Train: Loss = 1.15997, PPX = 3.19:   0%|          | 1/700 [00:00<01:30,  7.70it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 40.89\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[13 / 30] Train: Loss = 1.13725, PPX = 3.12: 100%|██████████| 700/700 [01:08<00:00, 10.32it/s]\n",
            "[13 / 30]   Val: Loss = 1.08301, PPX = 2.95: 100%|██████████| 16/16 [00:00<00:00, 21.75it/s]\n",
            "[14 / 30] Train: Loss = 1.18573, PPX = 3.27:   0%|          | 1/700 [00:00<01:33,  7.49it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 41.97\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[14 / 30] Train: Loss = 1.10545, PPX = 3.02: 100%|██████████| 700/700 [01:08<00:00, 10.18it/s]\n",
            "[14 / 30]   Val: Loss = 1.05655, PPX = 2.88: 100%|██████████| 16/16 [00:00<00:00, 22.05it/s]\n",
            "[15 / 30] Train: Loss = 0.98134, PPX = 2.67:   0%|          | 1/700 [00:00<01:32,  7.56it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 42.51\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[15 / 30] Train: Loss = 1.07727, PPX = 2.94: 100%|██████████| 700/700 [01:09<00:00, 10.12it/s]\n",
            "[15 / 30]   Val: Loss = 1.04109, PPX = 2.83: 100%|██████████| 16/16 [00:00<00:00, 21.75it/s]\n",
            "[16 / 30] Train: Loss = 1.26041, PPX = 3.53:   0%|          | 1/700 [00:00<01:29,  7.77it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 42.87\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[16 / 30] Train: Loss = 1.05345, PPX = 2.87: 100%|██████████| 700/700 [01:08<00:00, 10.15it/s]\n",
            "[16 / 30]   Val: Loss = 1.01892, PPX = 2.77: 100%|██████████| 16/16 [00:00<00:00, 21.75it/s]\n",
            "[17 / 30] Train: Loss = 0.93016, PPX = 2.53:   0%|          | 1/700 [00:00<01:32,  7.59it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 43.61\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[17 / 30] Train: Loss = 1.02880, PPX = 2.80: 100%|██████████| 700/700 [01:09<00:00, 10.15it/s]\n",
            "[17 / 30]   Val: Loss = 0.99668, PPX = 2.71: 100%|██████████| 16/16 [00:00<00:00, 21.82it/s]\n",
            "[18 / 30] Train: Loss = 0.96843, PPX = 2.63:   0%|          | 1/700 [00:00<01:32,  7.55it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 44.41\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[18 / 30] Train: Loss = 1.00464, PPX = 2.73: 100%|██████████| 700/700 [01:08<00:00, 10.15it/s]\n",
            "[18 / 30]   Val: Loss = 0.98642, PPX = 2.68: 100%|██████████| 16/16 [00:00<00:00, 21.17it/s]\n",
            "[19 / 30] Train: Loss = 0.85537, PPX = 2.35:   0%|          | 1/700 [00:00<01:33,  7.45it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 44.90\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[19 / 30] Train: Loss = 0.98623, PPX = 2.68: 100%|██████████| 700/700 [01:09<00:00, 10.08it/s]\n",
            "[19 / 30]   Val: Loss = 0.96777, PPX = 2.63: 100%|██████████| 16/16 [00:00<00:00, 21.71it/s]\n",
            "[20 / 30] Train: Loss = 0.93419, PPX = 2.55:   0%|          | 1/700 [00:00<01:32,  7.54it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 45.54\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[20 / 30] Train: Loss = 0.96469, PPX = 2.62: 100%|██████████| 700/700 [01:08<00:00, 10.17it/s]\n",
            "[20 / 30]   Val: Loss = 0.96222, PPX = 2.62: 100%|██████████| 16/16 [00:00<00:00, 21.47it/s]\n",
            "[21 / 30] Train: Loss = 0.86999, PPX = 2.39:   0%|          | 1/700 [00:00<01:30,  7.71it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 46.11\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[21 / 30] Train: Loss = 0.94845, PPX = 2.58: 100%|██████████| 700/700 [01:09<00:00, 10.13it/s]\n",
            "[21 / 30]   Val: Loss = 0.94587, PPX = 2.58: 100%|██████████| 16/16 [00:00<00:00, 21.98it/s]\n",
            "[22 / 30] Train: Loss = 0.76365, PPX = 2.15:   0%|          | 1/700 [00:00<01:33,  7.51it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 46.53\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[22 / 30] Train: Loss = 0.93308, PPX = 2.54: 100%|██████████| 700/700 [01:08<00:00, 10.20it/s]\n",
            "[22 / 30]   Val: Loss = 0.94284, PPX = 2.57: 100%|██████████| 16/16 [00:00<00:00, 21.64it/s]\n",
            "[23 / 30] Train: Loss = 0.91104, PPX = 2.49:   0%|          | 1/700 [00:00<01:31,  7.64it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 46.41\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[23 / 30] Train: Loss = 0.91750, PPX = 2.50: 100%|██████████| 700/700 [01:09<00:00, 10.13it/s]\n",
            "[23 / 30]   Val: Loss = 0.92672, PPX = 2.53: 100%|██████████| 16/16 [00:00<00:00, 21.44it/s]\n",
            "[24 / 30] Train: Loss = 0.84393, PPX = 2.33:   0%|          | 1/700 [00:00<01:30,  7.69it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 46.99\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[24 / 30] Train: Loss = 0.90557, PPX = 2.47: 100%|██████████| 700/700 [01:08<00:00, 10.16it/s]\n",
            "[24 / 30]   Val: Loss = 0.91394, PPX = 2.49: 100%|██████████| 16/16 [00:00<00:00, 22.12it/s]\n",
            "[25 / 30] Train: Loss = 0.84708, PPX = 2.33:   0%|          | 1/700 [00:00<01:33,  7.45it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 47.50\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[25 / 30] Train: Loss = 0.88915, PPX = 2.43: 100%|██████████| 700/700 [01:09<00:00, 10.21it/s]\n",
            "[25 / 30]   Val: Loss = 0.90138, PPX = 2.46: 100%|██████████| 16/16 [00:00<00:00, 21.08it/s]\n",
            "[26 / 30] Train: Loss = 0.86970, PPX = 2.39:   0%|          | 1/700 [00:00<01:32,  7.59it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 47.40\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[26 / 30] Train: Loss = 0.87449, PPX = 2.40: 100%|██████████| 700/700 [01:09<00:00, 10.08it/s]\n",
            "[26 / 30]   Val: Loss = 0.89974, PPX = 2.46: 100%|██████████| 16/16 [00:00<00:00, 21.80it/s]\n",
            "[27 / 30] Train: Loss = 0.76895, PPX = 2.16:   0%|          | 1/700 [00:00<01:32,  7.55it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 47.68\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[27 / 30] Train: Loss = 0.86356, PPX = 2.37: 100%|██████████| 700/700 [01:09<00:00, 10.23it/s]\n",
            "[27 / 30]   Val: Loss = 0.89008, PPX = 2.44: 100%|██████████| 16/16 [00:00<00:00, 21.86it/s]\n",
            "[28 / 30] Train: Loss = 0.83511, PPX = 2.31:   0%|          | 1/700 [00:00<01:32,  7.56it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 48.11\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[28 / 30] Train: Loss = 0.85268, PPX = 2.35: 100%|██████████| 700/700 [01:09<00:00, 10.14it/s]\n",
            "[28 / 30]   Val: Loss = 0.88304, PPX = 2.42: 100%|██████████| 16/16 [00:00<00:00, 21.88it/s]\n",
            "[29 / 30] Train: Loss = 0.87564, PPX = 2.40:   0%|          | 1/700 [00:00<01:30,  7.72it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 48.50\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[29 / 30] Train: Loss = 0.84028, PPX = 2.32: 100%|██████████| 700/700 [01:09<00:00, 10.24it/s]\n",
            "[29 / 30]   Val: Loss = 0.87960, PPX = 2.41: 100%|██████████| 16/16 [00:00<00:00, 22.14it/s]\n",
            "[30 / 30] Train: Loss = 0.84436, PPX = 2.33:   0%|          | 1/700 [00:00<01:30,  7.72it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 48.53\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[30 / 30] Train: Loss = 0.83041, PPX = 2.29: 100%|██████████| 700/700 [01:08<00:00, 10.15it/s]\n",
            "[30 / 30]   Val: Loss = 0.86404, PPX = 2.37: 100%|██████████| 16/16 [00:00<00:00, 21.85it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 49.14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sWHie5bCvXpc",
        "colab_type": "code",
        "outputId": "7826d1ac-ca41-4876-bb58-b74e27f0804a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "cell_type": "code",
      "source": [
        "source, result, attentions = greedy_decode(model, \"He lied to me.\", source_field, target_field)\n",
        "print(result)\n",
        "plot_heatmap(source + ['</s>'], result + ['</s>'], attentions)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['В', '@', '@', 'се', '@', '@', 'слуша', '@', '@', 'й', 'мне', '@', '@', '.']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWUAAAEKCAYAAADKJ0Q0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMMYmAVHAMwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fc340544780>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "Bzgvc-qrqjIo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Image Captioning with Attention\n",
        "\n",
        "Attention может работать не только для текстов. Мы вполне можем аттентиться и на картинки:\n",
        "\n",
        "![](https://cdn-images-1.medium.com/max/2000/0*YCeQbqU6CVxzpave.)  \n",
        "*From [Show, Attend and Tell: Neural Image Caption Generation with Visual Attention](https://arxiv.org/abs/1502.03044)*\n",
        "\n",
        "В качестве энкодера будет выступать сверточная сеть. Модель теперь должна научиться генерировать маску внимания на каждом шаге:\n",
        "\n",
        "![](http://kelvinxu.github.io/projects/diags/model_diag.png =x300)  \n",
        "*From [http://kelvinxu.github.io/projects/capgen.html](http://kelvinxu.github.io/projects/capgen.html)*"
      ]
    },
    {
      "metadata": {
        "id": "aJcQknT28mqb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Скачаем данные:"
      ]
    },
    {
      "metadata": {
        "id": "RLFU7loM8ewE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Install the PyDrive wrapper & import libraries.\n",
        "# This only needs to be done once per notebook.\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "downloaded = drive.CreateFile({'id': '1qM6fJuaOqhTES17kU_rz9Ydxz540bSJ6'})\n",
        "downloaded.GetContentFile('image_codes_for_attn.npy')\n",
        "\n",
        "downloaded = drive.CreateFile({'id': '1O7_3lyTyBMXsBBIt1PwUXwLdkyRQzZML'})\n",
        "downloaded.GetContentFile('sources.txt')\n",
        "\n",
        "downloaded = drive.CreateFile({'id': '1t-Dy8TzoRuTMoM7N9NJZKgWXfaw3b6KF'})\n",
        "downloaded.GetContentFile('texts.txt')\n",
        "\n",
        "!wget http://nlp.cs.illinois.edu/HockenmaierGroup/Framing_Image_Description/Flickr8k_Dataset.zip\n",
        "!unzip Flickr8k_Dataset.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vO5M--X18oJ1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Скачаем модель сверточной сети (чтобы было)"
      ]
    },
    {
      "metadata": {
        "id": "2XM_A_Xn8feC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torchvision.models.inception import Inception3\n",
        "from torch.utils.model_zoo import load_url\n",
        "\n",
        "\n",
        "class BeheadedInception3(Inception3):\n",
        "    \"\"\" Like torchvision.models.inception.Inception3 but the head goes separately \"\"\"\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = x.clone()\n",
        "        x[:, 0] = x[:, 0] * (0.229 / 0.5) + (0.485 - 0.5) / 0.5\n",
        "        x[:, 1] = x[:, 1] * (0.224 / 0.5) + (0.456 - 0.5) / 0.5\n",
        "        x[:, 2] = x[:, 2] * (0.225 / 0.5) + (0.406 - 0.5) / 0.5\n",
        "        x = self.Conv2d_1a_3x3(x)\n",
        "        x = self.Conv2d_2a_3x3(x)\n",
        "        x = self.Conv2d_2b_3x3(x)\n",
        "        x = F.max_pool2d(x, kernel_size=3, stride=2)\n",
        "        x = self.Conv2d_3b_1x1(x)\n",
        "        x = self.Conv2d_4a_3x3(x)\n",
        "        x = F.max_pool2d(x, kernel_size=3, stride=2)\n",
        "        x = self.Mixed_5b(x)\n",
        "        x = self.Mixed_5c(x)\n",
        "        x = self.Mixed_5d(x)\n",
        "        x = self.Mixed_6a(x)\n",
        "        x = self.Mixed_6b(x)\n",
        "        x = self.Mixed_6c(x)\n",
        "        x = self.Mixed_6d(x)\n",
        "        x = self.Mixed_6e(x)\n",
        "        x = self.Mixed_7a(x)\n",
        "        x = self.Mixed_7b(x)\n",
        "        x_for_attn = x = self.Mixed_7c(x)\n",
        "        # 8 x 8 x 2048\n",
        "        x = F.avg_pool2d(x, kernel_size=8)\n",
        "        # 1 x 1 x 2048\n",
        "        x_for_capt = x = x.view(x.size(0), -1)\n",
        "        # 2048\n",
        "        x = self.fc(x)\n",
        "        # 1000 (num_classes)\n",
        "        return x_for_attn, x_for_capt, x\n",
        "    \n",
        "\n",
        "inception_model = BeheadedInception3()\n",
        "\n",
        "inception_url = 'https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth'\n",
        "inception_model.load_state_dict(load_url(inception_url))\n",
        "\n",
        "inception_model.eval()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O4ZKVE8O8tqR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Загрузим данные:"
      ]
    },
    {
      "metadata": {
        "id": "CJ0OSYF28hfV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "target_field = Field(init_token=BOS_TOKEN, eos_token=EOS_TOKEN)\n",
        "image_indices_field = Field(sequential=False, use_vocab=False)\n",
        "\n",
        "fields = [('target', target_field), ('image_index', image_indices_field)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HcNFi0Gt8yRs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Чтобы не уткнуться в лимит по памяти - используем memmap формат:"
      ]
    },
    {
      "metadata": {
        "id": "qrLcBNek8wD-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open('sources.txt') as f_sources:\n",
        "    image_paths = [line.strip() for line in f_sources]\n",
        "    \n",
        "image_tensors = np.memmap('image_codes_for_attn.npy', shape=(8091, 2048, 8, 8), dtype=np.float32)\n",
        "\n",
        "examples = []\n",
        "with open('texts.txt') as f_texts:\n",
        "    for image_ind, texts in enumerate(f_texts):\n",
        "        for text in texts.split('\\t'):\n",
        "            examples.append(Example.fromlist([target_field.preprocess(text), image_ind], fields))`"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ioWDbal781Gy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataset = Dataset(examples, fields)\n",
        "\n",
        "train_dataset, test_dataset = dataset.split(split_ratio=0.85)\n",
        "\n",
        "print('Train size =', len(train_dataset))\n",
        "print('Test size =', len(test_dataset))\n",
        "\n",
        "target_field.build_vocab(train_dataset, min_freq=2)\n",
        "print('Target vocab size =', len(target_field.vocab))\n",
        "\n",
        "train_iter, test_iter = BucketIterator.splits(\n",
        "    datasets=(train_dataset, test_dataset), batch_sizes=(16, 64), shuffle=True, device=DEVICE, sort=False\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uOE8rm7c86KP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Задание** Реализуйте почти такие же модели как для перевода, чтобы научиться подписывать картинки:"
      ]
    },
    {
      "metadata": {
        "id": "XrZiXbvE87b_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class AdditiveAttention(nn.Module):\n",
        "    def __init__(self, query_size, key_size, hidden_dim):\n",
        "        super().__init__()\n",
        "        \n",
        "        self._query_layer = nn.Linear(query_size, hidden_dim)\n",
        "        self._key_layer = nn.Linear(key_size, hidden_dim)\n",
        "        self._energy_layer = nn.Linear(hidden_dim, 1)\n",
        "        \n",
        "    def forward(self, query, key_proj, value):\n",
        "        ..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zjYmhTeE8_J-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, vocab_size, cnn_feature_size, emb_dim=128, rnn_hidden_dim=256, attn_dim=128, num_layers=1):\n",
        "        super().__init__()\n",
        "\n",
        "        self._emb = nn.Embedding(vocab_size, emb_dim)\n",
        "        self._attention = AdditiveAttention(query_size=rnn_hidden_dim, key_size=cnn_feature_size, hidden_dim=attn_dim)\n",
        "        \n",
        "        self._cnn_to_h0 = nn.Linear(cnn_feature_size, rnn_hidden_dim)\n",
        "        self._cnn_to_c0 = nn.Linear(cnn_feature_size, rnn_hidden_dim)\n",
        "        self._rnn = nn.LSTM(input_size=emb_dim + cnn_feature_size, hidden_size=rnn_hidden_dim, num_layers=num_layers)\n",
        "        self._out = nn.Linear(rnn_hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, encoder_output, inputs, hidden=None):\n",
        "        embs = self._emb(inputs)\n",
        "        \n",
        "        seq_len, batch_size = inputs.shape[:2]\n",
        "        \n",
        "        encoder_output = encoder_output.view(batch_size, encoder_output.shape[1], -1).permute(0, 2, 1)\n",
        "        \n",
        "        if hidden is None:\n",
        "            hidden = self.init_hidden(encoder_output)\n",
        "        \n",
        "        outputs, attentions = [], []\n",
        "        <make forward pass with attention>\n",
        "    \n",
        "        return self._out(output), hidden, attentions\n",
        "    \n",
        "    def init_hidden(self, encoder_output):\n",
        "        encoder_output = encoder_output.mean(dim=1)\n",
        "        h0 = self._cnn_to_h0(encoder_output)\n",
        "        c0 = self._cnn_to_c0(encoder_output)\n",
        "        \n",
        "        return h0.unsqueeze(0), c0.unsqueeze(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CVtZrmDo9BIp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def do_epoch(model, criterion, data_iter, optimizer=None, name=None):\n",
        "    epoch_loss = 0\n",
        "    \n",
        "    is_train = not optimizer is None\n",
        "    name = name or ''\n",
        "    model.train(is_train)\n",
        "    \n",
        "    batches_count = len(data_iter)\n",
        "    \n",
        "    with torch.autograd.set_grad_enabled(is_train):\n",
        "        with tqdm(total=batches_count) as progress_bar:\n",
        "            for i, batch in enumerate(data_iter):  \n",
        "                encoder_output = FloatTensor(image_tensors[batch.image_index])\n",
        "                logits, _, _ = model(encoder_output, batch.target)\n",
        "                \n",
        "                target = torch.cat((batch.target[1:], batch.target.new_ones((1, batch.target.shape[1]))))\n",
        "                loss = criterion(logits.view(-1, logits.shape[-1]), target.view(-1))\n",
        "\n",
        "                epoch_loss += loss.item()\n",
        "\n",
        "                if optimizer:\n",
        "                    optimizer.zero_grad()\n",
        "                    loss.backward()\n",
        "                    nn.utils.clip_grad_norm_(model.parameters(), 1.)\n",
        "                    optimizer.step()\n",
        "\n",
        "                progress_bar.update()\n",
        "                progress_bar.set_description('{:>5s} Loss = {:.5f}, PPX = {:.2f}'.format(name, loss.item(), \n",
        "                                                                                         math.exp(loss.item())))\n",
        "                \n",
        "            progress_bar.set_description('{:>5s} Loss = {:.5f}, PPX = {:.2f}'.format(\n",
        "                name, epoch_loss / batches_count, math.exp(epoch_loss / batches_count))\n",
        "            )\n",
        "            progress_bar.refresh()\n",
        "\n",
        "    return epoch_loss / batches_count\n",
        "\n",
        "\n",
        "def fit(model, criterion, optimizer, train_iter, epochs_count=1, val_iter=None):\n",
        "    best_val_loss = None\n",
        "    for epoch in range(epochs_count):\n",
        "        name_prefix = '[{} / {}] '.format(epoch + 1, epochs_count)\n",
        "        train_loss = do_epoch(model, criterion, train_iter, optimizer, name_prefix + 'Train:')\n",
        "        \n",
        "        if not val_iter is None:\n",
        "            val_loss = do_epoch(model, criterion, val_iter, None, name_prefix + '  Val:')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iPpoTIVn9Ddh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Decoder(vocab_size=len(target_field.vocab), cnn_feature_size=image_tensors.shape[1]).to(DEVICE)\n",
        "\n",
        "pad_idx = target_field.vocab.stoi['<pad>']\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx).to(DEVICE)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "fit(model, criterion, optimizer, train_iter, epochs_count=30, val_iter=test_iter)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J-NBlUW49KX7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Задание** Напишите цикл генерации по картинке:"
      ]
    },
    {
      "metadata": {
        "id": "J35wKjlQ9HsW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generate(image_tensor):\n",
        "    bos_index = target_field.vocab.stoi[BOS_TOKEN]\n",
        "    eos_index = target_field.vocab.stoi[EOS_TOKEN]\n",
        "\n",
        "    words, attentions = [], []\n",
        "    \n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        ...\n",
        "        \n",
        "    return words, attentions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ou96FMJs9MdB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def visualize(image_tensors, image_paths, image_index):\n",
        "    words, attentions = generate(image_tensors[image_index])\n",
        "\n",
        "    figure = plt.figure(figsize=(15, 20))\n",
        "\n",
        "    image_path = image_paths[image_index]\n",
        "    image = plt.imread('Flicker8k_Dataset/' + image_path)\n",
        "    image = imresize(image, (299, 299)).astype('float32') / 255.\n",
        "\n",
        "    for ind, (word, attention) in enumerate(zip(words, attentions)):\n",
        "        ax = figure.add_subplot(np.ceil(len(words) / 3.), 3, ind + 1)\n",
        "\n",
        "        ax.text(0, 1, word, color='black', backgroundcolor='white', fontsize=12)\n",
        "        ax.imshow(image)\n",
        "\n",
        "        alpha = imresize(1 - attention, (192, 192))\n",
        "\n",
        "        ax.imshow(alpha, alpha=0.7)\n",
        "\n",
        "        ax.axis('off')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GbI2UepR9PH2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Визуализируем это!"
      ]
    },
    {
      "metadata": {
        "id": "K69xx2XK9QCO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "visualize(test_dataset.examples[0].image_index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "N4-3pYqVJIKA"
      },
      "cell_type": "markdown",
      "source": [
        "# Дополнительные материалы\n",
        "\n",
        "## Статьи\n",
        "Neural Machine Translation by Jointly Learning to Align and Translate, Bahdanau, 2014 [[pdf]](https://arxiv.org/pdf/1409.0473.pdf)  \n",
        "Effective Approaches to Attention-based Neural Machine Translation, Luong, 2015 [[arxiv]](http://arxiv.org/abs/1508.04025)  \n",
        "Show, Attend and Tell: Neural Image Caption Generation with Visual Attention, Xu, 2015 [[arxiv]](https://arxiv.org/abs/1502.03044)\n",
        "\n",
        "## Блоги\n",
        "[Attention and Augmented Recurrent Neural Networks](https://distill.pub/2016/augmented-rnns/)  \n",
        "[Deep Learning for NLP Best Practices, Attention](http://ruder.io/deep-learning-nlp-best-practices/index.html#attention)  \n",
        "[Attention? Attention!](https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html)  \n",
        "[Multi-Modal Methods: Image Captioning (From Translation to Attention)](https://medium.com/mlreview/multi-modal-methods-image-captioning-from-translation-to-attention-895b6444256e)  \n",
        "\n",
        "## Видео\n",
        "[Attention в Deep Learning и машинный перевод в очень широком смысле](https://www.youtube.com/watch?v=k63pDjKV3Ew)"
      ]
    },
    {
      "metadata": {
        "id": "Vwb5e5hPQebd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Сдача\n",
        "\n",
        "[Форма для сдачи](https://goo.gl/forms/RnQN6UrGKdxPxPBG3)  \n",
        "[Feedback](https://goo.gl/forms/9aizSzOUrx7EvGlG3)"
      ]
    }
  ]
}