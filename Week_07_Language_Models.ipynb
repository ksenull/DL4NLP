{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Week 07 - Language Models.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "OE7fXh-OSJYF",
        "colab_type": "code",
        "outputId": "7e104b1f-adaf-40ab-87eb-ced2b2bded1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "cell_type": "code",
      "source": [
        "!pip3 -qq install torch==0.4.1\n",
        "!pip -qq install torchtext==0.3.1\n",
        "!wget -qq --no-check-certificate 'https://drive.google.com/uc?export=download&id=1Pq4aklVdj-sOnQw68e1ZZ_ImMiC8IR1V' -O tweets.csv.zip\n",
        "!wget -qq --no-check-certificate \"https://drive.google.com/uc?export=download&id=1ji7dhr9FojPeV51dDlKRERIqr3vdZfhu\" -O surnames.txt\n",
        "!unzip tweets.csv.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tcmalloc: large alloc 1073750016 bytes == 0x5919a000 @  0x7f3bcb05b2a4 0x594e17 0x626104 0x51190a 0x4f5277 0x510c78 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f6070 0x510c78 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f6070 0x4f3338 0x510fb0 0x5119bd 0x4f6070\n",
            "Archive:  tweets.csv.zip\n",
            "  inflating: tweets.csv              \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uhvfH55PUJ8K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    from torch.cuda import FloatTensor, LongTensor\n",
        "    DEVICE = torch.device('cuda')\n",
        "else:\n",
        "    from torch import FloatTensor, LongTensor\n",
        "    DEVICE = torch.device('cpu')\n",
        "\n",
        "np.random.seed(42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jVcnkGDgxfNx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# –Ø–∑—ã–∫–æ–≤—ã–µ –º–æ–¥–µ–ª–∏"
      ]
    },
    {
      "metadata": {
        "id": "8Kjg1Z3xxmEP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*–Ø–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å* - —ç—Ç–æ —à—Ç—É–∫–∞, –∫–æ—Ç–æ—Ä–∞—è —É–º–µ–µ—Ç –æ—Ü–µ–Ω–∏–≤–∞—Ç—å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –≤—Å—Ç—Ä–µ—Ç–∏—Ç—å –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–ª–æ–≤ $w_1, \\ldots, w_n$:   \n",
        "$$\\mathbf{P}(w_1, \\ldots, w_n) = \\prod_k \\mathbf{P}(w_k|w_{k-1}, \\ldots, w_{1}).$$\n",
        "\n",
        "–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º—ã –∏ –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã —Ç—É—Ç –∏–º–µ–Ω–Ω–æ —É—Å–ª–æ–≤–Ω—ã–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ - –∫–∞–∫–æ–µ —Å–ª–æ–≤–æ —è–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å –æ–∂–∏–¥–∞–µ—Ç –≤—Å–ª–µ–¥ –∑–∞ –¥–∞–Ω–Ω—ã–º–∏. –£ –Ω–∞—Å —É –≤—Å–µ—Ö —Ç–∞–∫–∞—è —è–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å –µ—Å—Ç—å, —Ç–∞–∫-—Ç–æ. –ù–∞–ø—Ä–∏–º–µ—Ä, –≤ —Ç–∞–∫–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ\n",
        "\n",
        "![](https://hsto.org/web/956/239/601/95623960157b4e15a1b3f599aed62ed2.png =x170)\n",
        "\n",
        "–º–æ—è —è–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å –≥–æ–≤–æ—Ä–∏—Ç - –ø–æ—Å–ª–µ *—á–µ—Å—Ç–Ω—ã—Ö* –Ω–∞–≤—Ä—è–¥ –ª–∏ –ø–æ–π–¥—ë—Ç *–º–æ–π*. –ê –≤–æ—Ç *–∏* –∏–ª–∏, –∫–æ–Ω–µ—á–Ω–æ, *–ø—Ä–∞–≤–∏–ª* - –æ—á–µ–Ω—å –¥–∞–∂–µ.\n",
        "\n",
        "–ê –∑–∞–¥–∞—á–∞ —Ç–∞–∫–∞—è: –Ω–∞—É—á–∏—Ç—å—Å—è –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –ø–æ–ª–∏—Ç–∏—á–µ—Å–∫–∏–µ —Ç–≤–∏—Ç—ã –ø–æ –æ–±—Ä–∞–∑—É –∏ –ø–æ–¥–æ–±–∏—é `Russian Troll Tweets`. –î–∞—Ç–∞—Å–µ—Ç –≤–∑—è—Ç –æ—Ç—Å—é–¥–∞: https://www.kaggle.com/vikasg/russian-troll-tweets"
      ]
    },
    {
      "metadata": {
        "id": "JpjfUoN4_WY7",
        "colab_type": "code",
        "outputId": "67444f44-69db-47ff-bf46-a38e818b475d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv('tweets.csv')\n",
        "\n",
        "data.text.sample(15).tolist()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['RT @RivalThoughts: @CNN This lack of forethought is what ran the country into the ground.',\n",
              " \"#TopNews Icahn on CNBC:'Archie Bunker of the world' will vote for Trump\",\n",
              " 'RT @mclark1951: Just 5.7 Percent Of #Clinton Foundation Budget Actually Went To Charitable Grants https://t.co/c2EIYW4w9H #uniteblue2016 #p‚Ä¶',\n",
              " \"RT @JamilSmith: Read @jelani9 on Rudy Giuliani's flailing effort to gain relevance in this Trump moment. https://t.co/48p9d31pgi\",\n",
              " 'RT @Laura_A_Diaz: #StandUpWithEvan #MakeHistoryWithEvan  Unite and #Vote3rdParty #Deny270 https://t.co/quB1FdZZAo',\n",
              " 'RT @MommyExchangeGa: Camouflage Wedding Rings Made From Titanium! High Quality. Choose from Promise, Wedding, Friendship and Couples https:‚Ä¶',\n",
              " 'RT @NewssTrump: BREAKING: Trump‚Äôs UN Ambassador Just Put The Fear Of God In Our Enemies! She Just Gave The UN Teeth For The First‚Ä¶ https://‚Ä¶',\n",
              " '@Nero March for Trump at Trump tower NY happening now:\\n#Trump #MAGA https://t.co/SWvbWxOEjO',\n",
              " \"Why don't Portuguese Muslims speak out and condemn this guy? If he doesn't represent Islam hasn't he offended them?‚Ä¶ https://t.co/3hWEBCNgyg\",\n",
              " 'RT @theclobra: People either live in anonymity and then attack people for putting themselves out there or they are hypocrites and do the sa‚Ä¶',\n",
              " 'RT @GoldStarMomTX55: ChristiChat: RT ChristiChat: Dem IRONY!\\r\\nbillclinton address in 1995 ‚ÄúWe are a nation of immigrants, but we are als‚Ä¶ ht‚Ä¶',\n",
              " 'RT @pollygolightly: Boundaries. #GiftIdeasForPoliticians https://t.co/N0EN6hvVaD',\n",
              " 'RT @TheYoungTurks: .@HillaryClinton was caught on tape discussing rigging an election. https://t.co/a3WTZ0fIXz',\n",
              " 'RT @FeministaJones: Old Bay Macaroni and Cheese https://t.co/8yyIOxMmUh',\n",
              " 'RT @mansplainer123: Iran said it only takes 7min to hit Tel-Aviv.We need to point out that it will take 45min after that to turn them and t‚Ä¶']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "WAQ4d__2_sAz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "–î–∞, —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –±—É–¥—É—Ç —É–ø–æ—Ä–æ—Ç—ã, —Å—Ä–∞–∑—É –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–∞—é."
      ]
    },
    {
      "metadata": {
        "id": "7Qvqidof7Fsi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## –ß—Ç–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö"
      ]
    },
    {
      "metadata": {
        "id": "OSu56oDX-KY5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "–ö–æ–≥–æ-–Ω–∏–±—É–¥—å —É–∂–µ –¥–æ—Å—Ç–∞–ª–æ –ø–∏—Å–∞—Ç—å –≤—Å–µ —ç—Ç–∏ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –±–∞—Ç—á–µ–π, —Å–ª–æ–≤–∞—Ä–∏ - –≤–æ—Ç —ç—Ç–æ –≤—Å—ë? –õ–∏—á–Ω–æ –º–µ–Ω—è - –¥–∞!\n",
        "\n",
        "–í pytorch –µ—Å—Ç—å —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π –∫–ª–∞—Å—Å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –±–∞—Ç—á–µ–π - `Dataset`. –í–º–µ—Å—Ç–æ —Ç–æ–≥–æ, —á—Ç–æ–±—ã –ø–∏—Å–∞—Ç—å —Ñ—É–Ω–∫—Ü–∏—é —Ç–∏–ø–∞ `iterate_batches`, –º–æ–∂–Ω–æ –æ—Ç–Ω–∞—Å–ª–µ–¥–æ–≤–∞—Ç—å –æ—Ç –Ω–µ–≥–æ –∏ –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –º–µ—Ç–æ–¥—ã `__len__` –∏ `__getitem__`... –∏ —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –≤ –Ω–∏—Ö –ø–æ—á—Ç–∏ –≤—Å—ë —Ç–æ, —á—Ç–æ –±—ã–ª–æ –≤ `iterate_batches`. –ü–æ–∫–∞ –Ω–µ –≤–ø–µ—á–∞—Ç–ª—è–µ—Ç, –¥–∞?\n",
        "\n",
        "–ï—â—ë —Ç–∞–º –µ—Å—Ç—å `DataLoader`, —É–º–µ—é—â–∏–π —Ä–∞–±–æ—Ç–∞—Ç—å —Å –¥–∞—Ç–∞—Å–µ—Ç–æ–º. –û–Ω –ø–æ–∑–≤–æ–ª—è–µ—Ç –¥–µ–ª–∞—Ç—å shuffle –±–∞—Ç—á–µ–π –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –∏—Ö –≤ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –ø—Ä–æ—Ü–µ—Å—Å–∞—Ö - —ç—Ç–æ –æ—Å–æ–±–µ–Ω–Ω–æ –≤–∞–∂–Ω–æ, –∫–æ–≥–¥–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –±–∞—Ç—á–∞ - –¥–æ–ª–≥–∞—è –æ–ø–µ—Ä–∞—Ü–∏—è. –ù–∞–ø—Ä–∏–º–µ—Ä, –≤ –∫–∞—Ä—Ç–∏–Ω–∫–∞—Ö. –ü–æ—á–∏—Ç–∞—Ç—å –ø—Ä–æ —ç—Ç–æ –≤—Å—ë –º–æ–∂–Ω–æ –∑–¥–µ—Å—å: [Data Loading and Processing Tutorial](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html).\n",
        "\n",
        "–ù–æ –ø–æ–∫–∞ —á—Ç–æ –≤—Å—ë —Ä–∞–≤–Ω–æ –Ω–µ –æ—Å–æ–±–æ –∫—Ä—É—Ç–æ, –º–Ω–µ –∫–∞–∂–µ—Ç—Å—è. –ò–Ω—Ç–µ—Ä–µ—Å–Ω–æ –¥—Ä—É–≥–æ–µ - —É pytorch –≤ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ –∂–∏–≤–µ—Ç –æ—Ç–¥–µ–ª—å–Ω–∞—è –±–∏–±–ª–∏–æ—Ç–µ—á–∫–∞ - [torchtext](https://github.com/pytorch/text). –í–æ—Ç –æ–Ω–∞ —É–∂–µ –¥–∞—Å—Ç –Ω–∞–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ `Dataset` –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ç–µ–∫—Å—Ç–æ–º –∏ –≤—Å—è–∫–∏–µ —Ç—É–ª–∑—ã, –¥–µ–ª–∞—é—â–∏–µ –∂–∏–∑–Ω—å —á—É—Ç–æ—á–∫—É –ø—Ä–æ—â–µ.\n",
        "\n",
        "–ë–∏–±–ª–∏–æ—Ç–µ–∫–µ, –Ω–∞ –º–æ–π –≤–∑–≥–ª—è–¥, –Ω–µ–¥–æ—Å—Ç–∞–µ—Ç —Ç—É—Ç–æ—Ä–∏–∞–ª–æ–≤, –≤ –∫–æ—Ç–æ—Ä—ã—Ö –±—ã –ø–æ–∫–∞–∑—ã–≤–∞–ª–æ—Å—å, –∫–∞–∫ —Å –Ω–µ–π —Ä–∞–±–æ—Ç–∞—Ç—å - –Ω–æ –º–æ–∂–Ω–æ —á–∏—Ç–∞—Ç—å –∏—Å—Ö–æ–¥–Ω—ã–π –∫–æ–¥, –æ–Ω –ø—Ä–∏—è—Ç–Ω—ã–π.\n",
        "\n",
        "–ü–ª–∞–Ω —Ç–∞–∫–æ–π: –ø–æ—Å—Ç—Ä–æ–∏—Ç—å –∫–ª–∞—Å—Å `torchtext.data.Dataset`, –¥–ª—è –Ω–µ–≥–æ —Å–æ–∑–¥–∞—Ç—å –∏—Ç–µ—Ä–∞—Ç–æ—Ä, –∏ —É—á–∏—Ç—å –º–æ–¥–µ–ª—å.\n",
        "\n",
        "–î–∞–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç—Å—è –¥–≤—É–º—è –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏:\n",
        "```\n",
        "            examples: List of Examples.\n",
        "            fields (List(tuple(str, Field))): The Fields to use in this tuple. The\n",
        "                string is a field name, and the Field is the associated field.\n",
        "```\n",
        "–†–∞–∑–±–µ—Ä–µ–º—Å—è —Å–Ω–∞—á–∞–ª–∞ —Å–æ –≤—Ç–æ—Ä—ã–º.\n",
        "\n",
        "`Field` - —ç—Ç–æ —Ç–∞–∫–∞—è –º–µ—Ç–∞-–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –¥–ª—è –¥–∞—Ç–∞—Å–µ—Ç–∞ + –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ —Å—ç–º–ø–ª–æ–≤.  \n",
        "\n",
        "–û–Ω –∏–º–µ–µ—Ç –∫—É—á—É –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, –Ω–∞ –∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–æ—â–µ –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å [–∑–¥–µ—Å—å](https://github.com/pytorch/text/blob/master/torchtext/data/field.py). –ï—Å–ª–∏ –∫–æ—Ä–æ—Ç–∫–æ, —Ç–æ –æ–Ω –º–æ–∂–µ—Ç –ø—Ä–µ–¥–æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å (–Ω–∞–ø—Ä–∏–º–µ—Ä, —Ç–æ–∫–µ–Ω–∏–∑–∏—Ä–æ–≤–∞—Ç—å) –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è, —Å—Ç—Ä–æ–∏—Ç—å —Å–ª–æ–≤–∞—Ä—å (–æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–∑ —Å–ª–æ–≤–∞ –≤ –∏–Ω–¥–µ–∫—Å), —Å—Ç—Ä–æ–∏—Ç—å –±–∞—Ç—á–∏ - –¥–æ–±–∞–≤–ª—è—Ç—å –ø–∞–¥–¥–∏–Ω–≥–∏ –∏ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –≤ —Ç–µ–Ω–∑–æ—Ä—ã. –ß—Ç–æ –µ—â—ë –Ω—É–∂–Ω–æ –≤ –∂–∏–∑–Ω–∏?\n",
        "\n",
        "–ú—ã –±—É–¥–µ–º –¥–µ–ª–∞—Ç—å character-level —è–∑—ã–∫–æ–≤—É—é –º–æ–¥–µ–ª—å, –ø–æ—ç—Ç–æ–º—É —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è –¥–ª—è –Ω–∞—Å - –ø—Ä–µ–≤—Ä–∞—â–µ–Ω–∏–µ —Å—Ç—Ä–æ–∫–∏ –≤ –Ω–∞–±–æ—Ä —Å–∏–º–≤–æ–ª–æ–≤. –ü–æ–ø—Ä–æ—Å–∏–º —Ç–∞–∫–∂–µ –¥–æ–±–∞–≤–ª—è—Ç—å –≤ –Ω–∞—á–∞–ª–æ –∏ –∫–æ–Ω–µ—Ü —Å–ø–µ—Ü-—Å–∏–º–≤–æ–ª—ã `<s>` –∏ `</s>`."
      ]
    },
    {
      "metadata": {
        "id": "ilAMVxA8Xy4L",
        "colab_type": "code",
        "outputId": "9bb6ceea-8d75-49fb-bb7c-0eaf8b3ff3b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "from torchtext.data import Field\n",
        "\n",
        "text_field = Field(init_token='<s>', eos_token='</s>', lower=True, tokenize=lambda line: list(line))\n",
        "text_field"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torchtext.data.field.Field at 0x7f9fe1b25c88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "L_i0Z6JhF0rA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "–ü—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥ –±—É–¥–µ—Ç –≤—ã–≥–ª—è–¥–µ—Ç—å —Ç–∞–∫:"
      ]
    },
    {
      "metadata": {
        "id": "B-8IPlPHFyKa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# text_field.preprocess(data.text.iloc[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "19NFhTSNF1_1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "–°–∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤—Å—ë –∏ –ø–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–ª–∏–Ω:"
      ]
    },
    {
      "metadata": {
        "id": "wz1QnivMBmU3",
        "colab_type": "code",
        "outputId": "f8f3d015-74d4-4607-d218-f7400baf7c3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "data['text'] = data['text'].fillna('')\n",
        "lines = data.apply(lambda row: text_field.preprocess(row['text']), axis=1).tolist()\n",
        "\n",
        "lengths = [len(line) for line in lines]\n",
        "\n",
        "plt.hist(lengths, bins=30)[-1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<a list of 30 Patch objects>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD4CAYAAAAHHSreAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f9f85056b00>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "dE9rPW9UHE7d",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "–û—Ç—Å–µ—á–µ–º —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ —Å—Ç—Ä–æ–∫–∏ –∏ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –æ—Å—Ç–∞–≤—à–∏–µ—Å—è –≤ `Example`'—ã:"
      ]
    },
    {
      "metadata": {
        "id": "jfTlpBxODBg8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torchtext.data import Example\n",
        "\n",
        "lines = [line for line in lines if len(line) >= 50]\n",
        "\n",
        "fields = [('text', text_field)]\n",
        "examples = [Example.fromlist([line], fields) for line in lines]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7z1wPlz_HeEP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "–ü–æ `Example` –º–æ–∂–Ω–æ –ø–æ–ª—É—á–∏—Ç—å –æ–±—Ä–∞—Ç–Ω–æ –≤—Å–µ –ø–æ–ª—è, –∫–æ—Ç–æ—Ä—ã–µ –º—ã —Ç—É–¥–∞ –∑–∞–ø–∏—Ö–Ω—É–ª–∏. –ù–∞–ø—Ä–∏–º–µ—Ä, —Å–µ–π—á–∞—Å –º—ã —Å–æ–∑–¥–∞–ª–∏ –æ–¥–Ω–æ –ø–æ–ª–µ `text`:"
      ]
    },
    {
      "metadata": {
        "id": "iGMRSuk_HYCm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# examples[0].text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Yef1bv2MQcEA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "–ü–æ—Å—Ç—Ä–æ–∏–º, –Ω–∞–∫–æ–Ω–µ—Ü, –¥–∞—Ç–∞—Å–µ—Ç:"
      ]
    },
    {
      "metadata": {
        "id": "gSccEmVIHAaQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torchtext.data import Dataset\n",
        "\n",
        "dataset = Dataset(examples, fields)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vEe5YXIpRCYD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "–î–∞—Ç–∞—Å–µ—Ç –º–æ–∂–Ω–æ —Ä–∞–∑–±–∏—Ç—å –Ω–∞ —á–∞—Å—Ç–∏:"
      ]
    },
    {
      "metadata": {
        "id": "21whmJDFRBV1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_dataset, test_dataset = dataset.split(split_ratio=0.75)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "14CyhugSQsOf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "–ü–æ –Ω–µ–º—É –º–æ–∂–Ω–æ –ø–æ—Å—Ç—Ä–æ–∏—Ç—å —Å–ª–æ–≤–∞—Ä—å:"
      ]
    },
    {
      "metadata": {
        "id": "NQs3jbhyQkJD",
        "colab_type": "code",
        "outputId": "60197d3a-bd24-468d-9587-46dcc295be66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "cell_type": "code",
      "source": [
        "text_field.build_vocab(train_dataset, min_freq=30)\n",
        "\n",
        "print('Vocab size =', len(text_field.vocab))\n",
        "print(text_field.vocab.itos)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab size = 322\n",
            "['<unk>', '<pad>', '<s>', '</s>', ' ', 't', 'e', 'a', 'o', 'r', 'i', 's', 'n', 'l', 'h', 'c', 'p', 'd', 'm', 'u', '/', 'g', 'y', ':', 'w', 'b', 'f', '.', '@', 'k', 'v', '#', 'j', 'z', 'x', '\\n', \"'\", '‚Ä¶', '1', ',', '0', '2', 'q', '\\r', '!', '4', '6', '7', '3', '\"', '5', '-', '9', '8', '_', '?', ';', '‚Äô', '&', ')', '(', '‚Äò', '‚Äú', '$', 'üòÇ', '|', '‚Äù', '*', '%', '‚Äì', 'Ô∏è', 'üá∏', 'üá∫', '–æ', '–∞', '√º', '\\xa0', '–∏', '–µ', '‚ñ∂', '—Ç', '~', '–Ω', 'üî•', '—Ä', '+', '√§', 'üí•', '[', ']', '‚Äî', '–ª', '—Å', '=', '–≤', 'üö®', '√©', '–∫', '–ø', '–º', '‚ù§', '–¥', '√∂', 'ü§î', 'üëç', 'üëá', 'üëè', '‚Äº', '‚òÖ', 'ÿß', '—É', 'ÔøΩ', 'üèª', 'üò≠', '`', 'üèæ', 'üëâ', '–±', '–∑', 'üôè', 'üèº', '—ã', 'üò°', '—å', 'üòä', '–≥', '—è', 'ŸÑ', 'üòç', '√ü', 'üíØ', '¬ª', '‚Ä¢', 'üèΩ', 'üèø', 'üòé', '–π', '—á', 'üò≥', '‚úî', 'üíÄ', 'Ÿä', 'ŸÖ', '√†', 'üôÑ', '‚úä', '—Ö', 'üí©', '‚û°', 'üôå', '‚ú®', '‡§æ', 'üéâ', '¬´', '–∂', 'üëä', 'ÿ±', 'Ÿà', 'üí™', '√®', '‚ö°', 'üòò', 'ŸÜ', 'üòâ', 'üòè', 'üò©', '—à', 'üî¥', 'üí®', '—é', 'üëÄ', '‡•á', 'üí∞', 'ÿ™', 'ÿØ', '‚ñ∫', '‡§ï', '\\u200b', 'ÿ®', '‚úÖ', 'üöÇ', '‚û†', 'üåü', 'üò±', 'üëå', '‡§∞', 'üòÅ', 'Ÿá', 'üéÑ', 'üòÖ', '‚ùó', '‚ò∫', '„ÅÆ', 'üé∂', 'üëà', 'üòú', 'üòÜ', '¬¥', '‚ùå', 'ÿπ', '—Ü', 'üíô', '◊ô', '‚è≥', 'üòÑ', 'üö´', 'ÿ≥', '≈°', '\\x92', '‡§∏', 'üíï', 'üòí', '◊ï', 'üò†', '√°', '\\u200d', '„ÅÑ', '„ÄÇ', 'üåπ', 'üíû', '√ß', '√™', '‡§Æ', '‚≠ê', 'üêæ', '—Ñ', 'üÜò', 'üíú', '◊®', 'ÿ≠', '‡§π', '‚Äû', '‚¨á', '„Å™', 'üòî', 'üéà', 'üéØ', 'üíó', 'üî´', '‡•Ä', '‚úå', 'üÜì', 'üóΩ', 'üò¢', '‡•ã', '‚Ñ¢', '‚ô´', 'üëë', 'üíî', 'üí¶', 'ƒ±', '‡§ø', '‡•ç', '‚ô•', 'üòà', '^', '≈æ', 'ÿ©', '‡§§', '‚òÜ', 'üëé', 'ü§£', 'ŸÉ', '‡§®', 'üòÄ', '\\\\', '‚Åâ', '‚ö™', '‚ùì', '„ÄÅ', 'üèÜ', 'üí£', '—â', '◊™', '‚ùÑ', 'üòù', 'ƒá', '‡§Ç', '„ÅØ', 'ü§ò', '¬£', '‡§≤', '‚òÄ', '„Å®', '„Éª', 'ƒç', 'ŸÅ', '‚Üí', 'üò¥', '√±', 'ÿ¨', '‚ù£', 'üá∑', 'üîπ', 'üò∑', '√≠', '√≥', 'ŸÇ', '‡§™', '‚òï', 'üå¥', 'üçÄ', 'üòë', 'ü§ï', 'ü§ó', '‚§µ', '„Åå', '„Å´', 'üòÉ', 'üò¨', '‡§ó', '‡§¨', '„Å¶', '„Çã', 'üåå', 'üëÜ', 'üòá', '\\U000fe4e6', '◊î', '‚É£', '„Åó', 'üî∂']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-_EAdgsWRTzj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "–ù–∞–∫–æ–Ω–µ—Ü, –ø–æ –Ω–µ–º—É –º–æ–∂–Ω–æ –∏—Ç–µ—Ä–∏—Ä–æ–≤–∞—Ç—å—Å—è:"
      ]
    },
    {
      "metadata": {
        "id": "qaEMoxdVG98p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torchtext.data import BucketIterator\n",
        "\n",
        "train_iter, test_iter = BucketIterator.splits(datasets=(train_dataset, test_dataset), batch_sizes=(32, 128), \n",
        "                                              shuffle=True, device=DEVICE, sort=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RMG4L1-5RXnb",
        "colab_type": "code",
        "outputId": "fca61d44-4737-4e6c-dabf-104e8731b74f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "cell_type": "code",
      "source": [
        "batch = next(iter(train_iter))\n",
        "\n",
        "batch"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[torchtext.data.batch.Batch of size 32]\n",
              "\t[.text]:[torch.cuda.LongTensor of size 146x32 (GPU 0)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "oTrSUkqEhZzh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## –ü–µ—Ä–ø–ª–µ–∫—Å–∏—è"
      ]
    },
    {
      "metadata": {
        "id": "gqc9HpTM-FwD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "–ù–∞—à—É –∑–∞–¥–∞—á—É, –∫–∞–∫ –≤—Å–µ–≥–¥–∞, –Ω—É–∂–Ω–æ –Ω–∞—á–∏–Ω–∞—Ç—å —Å –¥–≤—É—Ö –≤–æ–ø—Ä–æ—Å–æ–≤ - –∫–∞–∫—É—é –º–µ—Ç—Ä–∏–∫—É –æ–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ–º –∏ –∫–∞–∫–æ–π –±–µ–π–∑–ª–∞–π–Ω.\n",
        "\n",
        "–° –º–µ—Ç—Ä–∏–∫–æ–π –≤—Å—ë –ø—Ä–æ—Å—Ç–æ - –º—ã —Ö–æ—Ç–∏–º, —á—Ç–æ–±—ã –º–æ–¥–µ–ª—å –∫–∞–∫ –º–æ–∂–Ω–æ –ª—É—á—à–µ —É–º–µ–ª–∞ –ø—Ä–∏–±–ª–∏–∂–∞—Ç—å —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–ª–æ–≤ —è–∑—ã–∫–∞. –í—Å–µ–≥–æ —è–∑—ã–∫–∞ —É –Ω–∞—Å –Ω–µ—Ç—É, –ø–æ—ç—Ç–æ–º—É –æ–±–æ–π–¥—ë–º—Å—è —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–æ–π.\n",
        "\n",
        "–ù–∞ –Ω–µ–π –º–æ–∂–Ω–æ –ø–æ—Å—á–∏—Ç–∞—Ç—å –∫—Ä–æ—Å—Å-—ç–Ω—Ç—Ä–æ–ø–∏–π–Ω—ã–µ –ø–æ—Ç–µ—Ä–∏: \n",
        "$$H(w_1, \\ldots, w_n) = - \\frac 1n \\sum_k \\log\\mathbf{P}(w_k | w_{k-1}, \\ldots, w_1).$$\n",
        "\n",
        "–ó–¥–µ—Å—å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å $\\mathbf{P}$ - —ç—Ç–æ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å, –æ—Ü–µ–Ω–µ–Ω–Ω–∞—è –Ω–∞—à–µ–π —è–∑—ã–∫–æ–≤–æ–π –º–æ–¥–µ–ª—å—é. –ò–¥–µ–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å –¥–∞–≤–∞–ª–∞ –±—ã –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Ä–∞–≤–Ω—É—é 1 –¥–ª—è —Å–ª–æ–≤ –≤ —Ç–µ–∫—Å—Ç–µ –∏ –ø–æ—Ç–µ—Ä–∏ –±—ã–ª–∏ –±—ã –Ω—É–ª–µ–≤—ã–º–∏ - —Ö–æ—Ç—è —ç—Ç–æ, –∫–æ–Ω–µ—á–Ω–æ, –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ, –¥–∞–∂–µ –≤—ã –∂–µ –Ω–µ –º–æ–∂–µ—Ç–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å —Å–ª–µ–¥—É—é—â–µ–µ —Å–ª–æ–≤–æ, —á—Ç–æ —É–∂ –ø—Ä–æ –±–µ–∑–¥—É—à–Ω—É—é –º–∞—à–∏–Ω—É –≥–æ–≤–æ—Ä–∏—Ç—å.\n",
        "\n",
        "–¢–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º, –≤—Å—ë –∫–∞–∫ –≤—Å–µ–≥–¥–∞ - –æ–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ–º –∫—Ä–æ—Å—Å-—ç–Ω—Ç—Ä–æ–ø–∏—é –∏ —Å—Ç—Ä–µ–º–∏–º—Å—è —Å–¥–µ–ª–∞—Ç—å –µ—ë –∫–∞–∫ –º–æ–∂–Ω–æ –Ω–∏–∂–µ.\n",
        "\n",
        "–ù—É, –ø–æ—á—Ç–∏ –≤—Å—ë. –ï—â—ë –µ—Å—Ç—å –æ—Ç–¥–µ–ª—å–Ω–∞—è –º–µ—Ç—Ä–∏–∫–∞ –¥–ª—è —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π - *–ø–µ—Ä–ø–ª–µ–∫—Å–∏—è*. –≠—Ç–æ –ø—Ä–æ—Å—Ç–æ –≤–æ–∑–≤–µ–¥–µ–Ω–Ω—ã–µ –≤ —ç–∫—Å–ø–æ–Ω–µ–Ω—Ç—É –∫—Ä–æ—Å—Å-—ç–Ω—Ç—Ä–æ–ø–∏–π–Ω—ã–µ –ø–æ—Ç–µ—Ä–∏:\n",
        "\n",
        "$$PP(w_1, \\ldots, w_n) = e^{H(w_1, \\ldots, w_n)} = e^{- \\frac 1n \\sum_k \\log\\mathbf{P}(w_k | w_{k-1}, \\ldots, w_1)} = \\left(\\mathbf{P}(w_1, \\ldots, w_n) \\right)^{-\\frac 1n}.$$\n",
        "\n",
        "–£ –µ—ë –∏–∑–º–µ—Ä–µ–Ω–∏—è –µ—Å—Ç—å –Ω–µ–∫–æ—Ç–æ—Ä—ã–π —Å–∞–∫—Ä–∞–ª—å–Ω—ã–π —Å–º—ã—Å–ª –∫—Ä–æ–º–µ –±–∞–Ω–∞–ª—å–Ω–æ–π –∏–Ω—Ç–µ–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ—Å—Ç–∏: –ø—Ä–µ–¥—Å—Ç–∞–≤–∏–º –º–æ–¥–µ–ª—å, –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—é—â—É—é —Å–ª–æ–≤–∞ –∏–∑ —Å–ª–æ–≤–∞—Ä—è —Ä–∞–≤–Ω–æ–≤–µ—Ä–æ—è—Ç–Ω–æ –≤–Ω–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞. –î–ª—è –Ω–µ—ë $\\mathbf{P}(w) = \\frac 1 N$, –≥–¥–µ $N$ ‚Äî —Ä–∞–∑–º–µ—Ä —Å–ª–æ–≤–∞—Ä—è, –∞ –ø–µ—Ä–ø–ª–µ–∫—Å–∏—è –±—É–¥–µ—Ç —Ä–∞–≤–Ω–∞ —Ä–∞–∑–º–µ—Ä—É —Å–ª–æ–≤–∞—Ä—è ‚Äî $N$. –ö–æ–Ω–µ—á–Ω–æ, —ç—Ç–æ —Å–æ–≤–µ—Ä—à–µ–Ω–Ω–æ –≥–ª—É–ø–∞—è –º–æ–¥–µ–ª—å, –Ω–æ –æ–≥–ª—è–¥—ã–≤–∞—è—Å—å –Ω–∞ –Ω–µ—ë, –º–æ–∂–Ω–æ —Ç—Ä–∞–∫—Ç–æ–≤–∞—Ç—å –ø–µ—Ä–ø–ª–µ–∫—Å–∏—é —Ä–µ–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –∫–∞–∫ —É—Ä–æ–≤–µ–Ω—å –Ω–µ–æ–¥–Ω–æ–∑–Ω–∞—á–Ω–æ—Å—Ç–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å–ª–æ–≤–∞.\n",
        "\n",
        "–°–∫–∞–∂–µ–º, –≤ –º–æ–¥–µ–ª–∏ —Å –ø–µ—Ä–ø–ª–µ–∫—Å–∏–µ–π 100 –≤—ã–±–æ—Ä —Å–ª–µ–¥—É—é—â–µ–≥–æ —Å–ª–æ–≤–∞ —Ç–∞–∫–∂–µ –Ω–µ–æ–¥–Ω–æ–∑–Ω–∞—á–µ–Ω, –∫–∞–∫ –≤—ã–±–æ—Ä –∏–∑ —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Å—Ä–µ–¥–∏ 100 —Å–ª–æ–≤. –ò –µ—Å–ª–∏ —Ç–∞–∫–æ–π –ø–µ—Ä–ø–ª–µ–∫—Å–∏–∏ —É–¥–∞–ª–æ—Å—å –¥–æ—Å—Ç–∏—á—å –Ω–∞ —Å–ª–æ–≤–∞—Ä–µ –≤ 100 000, –ø–æ–ª—É—á–∞–µ—Ç—Å—è, —á—Ç–æ —É–¥–∞–ª–æ—Å—å —Å–æ–∫—Ä–∞—Ç–∏—Ç—å —ç—Ç—É –Ω–µ–æ–¥–Ω–æ–∑–Ω–∞—á–Ω–æ—Å—Ç—å –Ω–∞ —Ç—Ä–∏ –ø–æ—Ä—è–¥–∫–∞ –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å —Ç—É–ø—ã–º —Ä–∞–Ω–¥–æ–º–æ–º."
      ]
    },
    {
      "metadata": {
        "id": "xW8I0lKv9y1H",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## –ë–µ–π–∑–ª–∞–π–Ω"
      ]
    },
    {
      "metadata": {
        "id": "7wInBuBn-DIf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "–í–æ–æ–±—â–µ, –±–µ–π–∑–ª–∞–π–Ω —Ç—É—Ç —Ç–æ–∂–µ –æ—á–µ–Ω—å –ø—Ä–æ—Å—Ç–æ–π. –ú—ã, –Ω–∞ —Å–∞–º–æ–º –¥–µ–ª–µ, –¥–∞–∂–µ —Å–º–æ—Ç—Ä–µ–ª–∏ –µ–≥–æ –Ω–∞ –∫—É—Ä—Å–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–π: [N-–≥—Ä–∞–º–º–Ω–∞—è —è–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å](https://colab.research.google.com/drive/1lz9vO6Ue5zOiowEx0-koXNiejBrrnbj0). –ú–æ–∂–Ω–æ –ø–æ–¥—Å—á–∏—Ç—ã–≤–∞—Ç—å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ N-–≥—Ä–∞–º–º —Å–ª–æ–≤ –ø–æ —á–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç—è–º –∏—Ö –ø–æ—è–≤–ª–µ–Ω–∏—è –≤ –æ–±—É—á–∞—é—â–µ–º –∫–æ—Ä–ø—É—Å–µ. –ê –¥–∞–ª—å—à–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∞–ø–ø—Ä–æ–∫—Å–∏–º–∞—Ü–∏—é $\\mathbf{P}(w_k|w_1, \\ldots, w_{k-1}) \\approx \\mathbf{P}(w_k|w_{k-1}, \\ldots, w_{k-N + 1})$.\n",
        "\n",
        "–ü—Ä–∏–º–µ–Ω–∏–º –ª—É—á—à–µ —Å–µ—Ç–æ—á–∫–∏ –¥–ª—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ —Ç–æ–≥–æ –∂–µ.\n",
        "\n",
        "![](https://image.ibb.co/buMnLf/2018-10-22-00-22-56.png =x450)  \n",
        "*From cs224n, Lecture 8 [pdf](http://web.stanford.edu/class/cs224n/lectures/lecture8.pdf)*\n",
        "\n",
        "–ù–∞ –≤—Ö–æ–¥ –ø—Ä–∏—Ö–æ–¥–∏—Ç –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–ª–æ–≤, –æ–Ω–∏ —ç–º–±–µ–¥–¥—è—Ç—Å—è, –∞ –¥–∞–ª—å—à–µ —Å –ø–æ–º–æ—â—å—é –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Å–ª–æ—è —Å—á–∏—Ç–∞–µ—Ç—Å—è –Ω–∞–∏–±–æ–ª–µ–µ –≤–µ—Ä–æ—è—Ç–Ω–æ–µ —Å–ª–µ–¥—É—é—â–µ–µ —Å–ª–æ–≤–æ.\n",
        "\n",
        "–°—Ç–æ–ø... –ù–æ –º—ã –∂–µ —É–∂–µ —Ä–µ–∞–ª–∏–∑–æ–≤—ã–≤–∞–ª–∏ —Ç–∞–∫–æ–µ! –í Word2vec CBoW –º–æ–¥–µ–ª–∏ –º—ã –ø–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–ª–∏ —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω–æ–µ —Å–ª–æ–≤–æ - –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω–æ–µ –æ—Ç–ª–∏—á–∏–µ –≤ —Ç–æ–º, —á—Ç–æ —Ç–µ–ø–µ—Ä—å –º—ã –∏–º–µ–µ–º —Ç–æ–ª—å–∫–æ –ª–µ–≤—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç. –ó–Ω–∞—á–∏—Ç, –≤—Å—ë, –∏–¥—ë–º –∫ —Å–ª–µ–¥—É—é—â–µ–π –º–æ–¥–µ–ª–∏?\n",
        "\n",
        "–ù–µ—Ç! –¢—É—Ç –µ—â—ë –µ—Å—Ç—å —Å —á–µ–º —Ä–∞–∑–≤–ª–µ—á—å—Å—è. –í Word2vec –º—ã —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–ª–∏ –±–∞—Ç—á–∏ —Ç–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º:\n",
        "![](https://image.ibb.co/bs3wgV/training-data.png =x350)  \n",
        "*From [Word2Vec Tutorial - The Skip-Gram Model, Chris McCormic](http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/)*\n",
        "\n",
        "–¢–æ –µ—Å—Ç—å –Ω–∞—Ä–µ–∑–∞–ª–∏ –∏–∑ —Ç–µ–∫—Å—Ç–∞ –Ω–∞–±–æ—Ä –ø–∞—Ä <–∫–æ–Ω—Ç–µ–∫—Å—Ç, —Å–ª–æ–≤–æ> (–∏ –∫–∞–∫-—Ç–æ –∏—Ö –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –º–µ—Ç–æ–¥–∞).\n",
        "\n",
        "–≠—Ç–æ –Ω–µ—Ä–∞—Ü–∏–æ–Ω–∞–ª—å–Ω–æ - –∫–∞–∂–¥–æ–µ —Å–ª–æ–≤–æ –ø–æ–≤—Ç–æ—Ä—è–µ—Ç—Å—è –º–Ω–æ–≥–æ —Ä–∞–∑. –ù–æ –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–≤–µ—Ä—Ç–æ—á–Ω—ã–µ —Å–µ—Ç–∏ - –æ–Ω–∏ –∑–∞ –Ω–∞—Å –ø—Ä–∏–º–µ–Ω—è—Ç –æ–ø–µ—Ä–∞—Ü–∏—é —É–º–Ω–æ–∂–µ–Ω–∏—è –Ω–∞ $W$ –∫ –∫–∞–∂–¥–æ–º—É –æ–∫–Ω—É. –í —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ —Ä–∞–∑–º–µ—Ä –≤—Ö–æ–¥–Ω–æ–≥–æ –±–∞—Ç—á–∞ –±—É–¥–µ—Ç —Å–∏–ª—å–Ω–æ –º–µ–Ω—å—à–µ.\n",
        "\n",
        "–ß—Ç–æ–±—ã –ø—Ä–∞–≤–∏–ª—å–Ω–æ –≤—Å—ë –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å, –Ω—É–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –ø–∞–¥–¥–∏–Ω–≥ –≤ –Ω–∞—á–∞–ª–æ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Ä–∞–∑–º–µ—Ä–æ–º `window_size - 1` - —Ç–æ–≥–¥–∞ –ø–µ—Ä–≤–æ–µ —Å–ª–æ–≤–æ –±—É–¥–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å—Å—è –ø–æ `<pad>...<pad><s>`.\n",
        "\n",
        "**–ó–∞–¥–∞–Ω–∏–µ** –†–µ–∞–ª–∏–∑—É–π—Ç–µ —è–∑—ã–∫–æ–≤—É—é –º–æ–¥–µ–ª—å —Å —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –æ–∫–Ω–æ–º."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "A-tn_Gmi3pU0",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class ConvLM(nn.Module):\n",
        "    def __init__(self, vocab_size, window_size=5, emb_dim=16, filters_count=128):\n",
        "        super().__init__()\n",
        "        \n",
        "        self._window_size = window_size\n",
        "        self._emb = nn.Embedding(vocab_size, emb_dim, padding_idx=1)\n",
        "        self._conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=filters_count, kernel_size=(window_size, emb_dim)),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm2d(filters_count)\n",
        "        )\n",
        "        self._out = nn.Linear(filters_count, vocab_size)\n",
        "        \n",
        "    def forward(self, inputs): \n",
        "        padding = inputs.new_ones(self._window_size - 1, inputs.shape[1])\n",
        "        outputs = torch.cat((inputs, padding), dim=0)\n",
        "        outputs = self._emb(outputs)  # (seq_len, batch_size, emb_dim)\n",
        "        outputs = outputs.permute((1, 0, 2))  # (batch_size, seq_len, emb_dim)\n",
        "        outputs = outputs.unsqueeze(1) \n",
        "        outputs = self._conv(outputs)  # (batch_size, filters_count, input_size, 1)   \n",
        "        outputs = outputs.squeeze(-1) # (batch_size, filters_count, input_size)\n",
        "        outputs = outputs.permute(2, 0, 1)\n",
        "#         outputs = outputs.max(dim=2)[0]  # (batch_size, filters_count)\n",
        "        outputs = self._out(outputs)  # (input_size, batch_size, vocab_size)\n",
        "#         outputs = F.softmax(outputs, dim=2)\n",
        "        return outputs, None  # hacky way to use training cycle for RNN and Conv simultaneously"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bjpOLKBH5yS5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "–ü—Ä–æ–≤–µ—Ä–∏–º, —á—Ç–æ –æ–Ω–æ —Ä–∞–±–æ—Ç–∞–µ—Ç:"
      ]
    },
    {
      "metadata": {
        "id": "ks_RTZ14nMRz",
        "colab_type": "code",
        "outputId": "a9633e33-5d2b-4b5d-dbed-56b4878b03fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "model = ConvLM(vocab_size=len(train_iter.dataset.fields['text'].vocab)).to(DEVICE)\n",
        "\n",
        "model(batch.text)[0].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([150, 32, 310])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "metadata": {
        "id": "Lb_2VTBW5v_7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**–ó–∞–¥–∞–Ω–∏–µ** –†–µ–∞–ª–∏–∑—É–π—Ç–µ —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è —Å—ç–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏–∑ —è–∑—ã–∫–æ–≤–æ–π –º–æ–¥–µ–ª–∏."
      ]
    },
    {
      "metadata": {
        "id": "0oUg0BjV2JjE",
        "colab_type": "code",
        "outputId": "5f7cff3c-800b-4d7e-8c47-10fc6b6cbbd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "def sample(probs, temp):\n",
        "    probs = F.log_softmax(probs.squeeze(), dim=0)\n",
        "    probs = (probs / temp).exp()\n",
        "    probs /= probs.sum()\n",
        "    probs = probs.cpu().numpy()\n",
        "\n",
        "    return np.random.choice(np.arange(len(probs)), p=probs)\n",
        "\n",
        "\n",
        "def generate(model, temp=0.7):\n",
        "    model.eval()\n",
        "    \n",
        "    history = [train_dataset.fields['text'].vocab.stoi['<s>']]\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for _ in range(150):\n",
        "            inputs = LongTensor([history])\n",
        "            inputs = inputs.permute(1, 0)\n",
        "            logits, _ = model(inputs)\n",
        "            index = sample(logits[-1, 0], temp)\n",
        "            history.append(index)\n",
        "            print(train_dataset.fields['text'].vocab.itos[history[-1]], end='')\n",
        "            \n",
        "generate(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ÿ®y0üëáw‚¨á„ÄÇ‚òÜüéÑ‚òï–∑tbüîπ„Å®m„ÄÅ5`‚Äûüò°üÜìÿπ◊ëüíØÿ±√°üååüèæ◊îüò¢‚ô•–Ω—Ñ¬ª–≥5]üëéüö´√ºüí¶üòë—áü§òüòÇpn≈°◊ô¬¥ƒáÿπ„ÉªüëÄ–æ2üíó–µ–µ¬£üîπŸÖüî∂?‚úî3üíÄüíîüëèüíÄ√±‚Äò◊ôŸÜÿ≠üòò‚ö°üòçüòú„ÅÆ—âüôÑ%–≥üéàÿπüòîüòÖüòî‚ú®#√®üíî.„ÄÇÿß@üí∞üíó‚û†ŸÑt√±*◊™—Ç‚úîl‡•áo„Éªüåπ#ÿØüÜìüíØ(‡§ø‚ÄùüëÄ‚ù§–≤?¬¥‡§≤</s>–º—âÿπ,üò°‡§Çüö´◊ïÿ±–∞k‚Äçl–º—Ä_—é‚ûñüéØ%füí¶‡§Æ"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CXuN871a852l",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**–ó–∞–¥–∞–Ω–∏–µ** –ú—ã –¥–æ —Å–∏—Ö –ø–æ—Ä –Ω–µ –∑–∞–¥–∞–ª–∏ –Ω–∏ –∫–∞–∫–æ–π target. –ê –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å –Ω–∞–º –±—É–¥–µ—Ç –Ω—É–∂–Ω–æ —Å–ª–µ–¥—É—é—â–∏–µ —Å–ª–æ–≤–∞ - —Ç–æ –µ—Å—Ç—å –ø—Ä–æ—Å—Ç–æ —Å–¥–≤–∏–Ω—É—Ç—ã–π –Ω–∞ 1 –≤—Ö–æ–¥–Ω–æ–π —Ç–µ–Ω–∑–æ—Ä. –†–µ–∞–ª–∏–∑—É–π—Ç–µ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ target'–∞ –∏ –ø–æ–¥—Å—á–µ—Ç –ø–æ—Ç–µ—Ä—å."
      ]
    },
    {
      "metadata": {
        "id": "7cmQFchzFMqn",
        "colab_type": "code",
        "outputId": "1a4eb6ec-8095-467d-80d5-15dcc8d872a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "logits = model(batch.text)[0]\n",
        "Y =  batch.text.view(-1)\n",
        "Y_hat = logits.view(-1, logits.shape[-1])\n",
        "\n",
        "Y_hat[range(Y_hat.shape[0]),  Y] # probs of corect values"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.1909, -0.0968, -0.0968,  ..., -0.0941, -0.0941, -0.0941],\n",
              "       device='cuda:0', grad_fn=<TakeBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "CGLkcXARjhTM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import math\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def do_epoch(model, criterion, data_iter, unk_idx, pad_idx, optimizer=None, name=None):\n",
        "    epoch_loss = 0\n",
        "    \n",
        "    is_train = not optimizer is None\n",
        "    name = name or ''\n",
        "    model.train(is_train)\n",
        "    \n",
        "    batches_count = len(data_iter)\n",
        "    \n",
        "    with torch.autograd.set_grad_enabled(is_train):\n",
        "        with tqdm(total=batches_count) as progress_bar:\n",
        "            for i, batch in enumerate(data_iter):\n",
        "                labels = batch.text[1:, :]\n",
        "                labels = labels.view(-1)\n",
        "                \n",
        "                logits, _ = model(batch.text)\n",
        "                logits = logits[:-1, :, :]\n",
        "                logits = logits.view(-1, logits.shape[-1])\n",
        "                \n",
        "                mask = ((labels != pad_idx) * (labels != unk_idx)).float()\n",
        "                \n",
        "                loss = torch.sum(criterion(logits, labels.view(-1)) * mask) / torch.sum(mask)\n",
        "                \n",
        "                epoch_loss += loss.item()\n",
        "\n",
        "                if optimizer:\n",
        "                    optimizer.zero_grad()\n",
        "                    loss.backward()\n",
        "                    nn.utils.clip_grad_norm_(model.parameters(), 1.)\n",
        "                    optimizer.step()\n",
        "\n",
        "#                 if i > 100:\n",
        "#                     break\n",
        "#                     generate(model)\n",
        "#                     print()\n",
        "#                     print('{:>5s} Loss = {:.5f}, PPX = {:.2f}'.format(name, loss.item(), math.exp(loss.item())))\n",
        "                progress_bar.update()\n",
        "                progress_bar.set_description('{:>5s} Loss = {:.5f}, PPX = {:.2f}'.format(name, loss.item(), \n",
        "                                                                                         math.exp(loss.item())))\n",
        "                \n",
        "            progress_bar.set_description('{:>5s} Loss = {:.5f}, PPX = {:.2f}'.format(\n",
        "                name, epoch_loss / batches_count, math.exp(epoch_loss / batches_count))\n",
        "            )\n",
        "\n",
        "    return epoch_loss / batches_count\n",
        "\n",
        "\n",
        "def fit(model, criterion, optimizer, train_iter, epochs_count=1, unk_idx=0, pad_idx=1, val_iter=None):\n",
        "    for epoch in range(epochs_count):\n",
        "        name_prefix = '[{} / {}] '.format(epoch + 1, epochs_count)\n",
        "        train_loss = do_epoch(model, criterion, train_iter, unk_idx, pad_idx, optimizer, name_prefix + 'Train:')\n",
        "        \n",
        "        if not val_iter is None:\n",
        "            val_loss = do_epoch(model, criterion, val_iter, unk_idx, pad_idx, None, name_prefix + '  Val:')\n",
        "\n",
        "        generate(model)\n",
        "        print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LIj0Lcdh9UJy",
        "colab_type": "code",
        "outputId": "eef7f752-cd20-45fa-aa1d-d1c258a36b91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        }
      },
      "cell_type": "code",
      "source": [
        "model = ConvLM(vocab_size=len(train_iter.dataset.fields['text'].vocab)).to(DEVICE)\n",
        "\n",
        "pad_idx = train_iter.dataset.fields['text'].vocab.stoi['<pad>']\n",
        "unk_idx = train_iter.dataset.fields['text'].vocab.stoi['<unk>']\n",
        "start_idx = train_iter.dataset.fields['text'].vocab.stoi['<s>']\n",
        "criterion = nn.CrossEntropyLoss(reduction='none').to(DEVICE) # \n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "fit(model, criterion, optimizer, train_iter, epochs_count=30, unk_idx=unk_idx, pad_idx=pad_idx, val_iter=test_iter)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 / 30] Train: Loss = 0.05979, PPX = 1.06: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4381/4381 [04:58<00:00, 15.03it/s]\n",
            "[1 / 30]   Val: Loss = 0.00007, PPX = 1.00: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 366/366 [01:19<00:00,  4.62it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Ÿá—àüëãüåπ‚û†¬ªƒá–æüéàü§ïüí£üá´◊ô√§üî´üçÄ—ãüëá‚òÜ◊î–¥√ü(üíïüëë[‚ô•üí®¬ª√ßüò±üòéüòÑ‡•ã√ßŸÑ—â≈°üôÑ◊ïküòÑ¬¥üò†‡§ïü§òÿßü§î¬ªüöÇ√ß‚Äôüá´–±u„Å™√©√ß\r◊ô–¥=0‡§®„Å™≈æ‡•á<unk>‚û°üö´üò≥–¥=ü§óüòä*üòÖüòÜüò©‚û†–¥üòú–¥üö´üòÜ—Å¬´√†0üÜì"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/4381 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "üÜìüò°–π–≥‡•Ä„ÄÇ–Ω</s>üóΩ‚ö°üò†üéØ‚ÜíŸÖ√§üí¶ŸÑ&ÿπ‚¨á¬†j%`‚Ä¢‚ô•‡§ïüéà–¥üêæ‚Äô≈æüí©‚òÜüòë—â–Ω‚Äç–∂ü§£–Ω</s>◊î◊î)üòë‚è≥üòÜüíûüÜìÔøΩ√≥üòù–≤üò†ü§£‡§Æ–∑—É„Å®\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[2 / 30] Train: Loss = 0.00004, PPX = 1.00: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4381/4381 [04:57<00:00, 14.73it/s]\n",
            "[2 / 30]   Val: Loss = 0.00000, PPX = 1.00: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 366/366 [01:19<00:00,  4.62it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "‡§≤–ªƒáüèºŸÉ‡§ø‚≠ê9‚Äô≈æüé∂◊îüò†üèΩüòäüá´—Äüí®‡•á‚ô•üòá◊ô-„Å®üò©‚úä—Öüò≥—Å‡§≤]‡§∞]füéâ–≤‚Ä¢—ãüí©„ÅÑ5%üëÄüëâüèÜ≈°‚≠ê„ÅÑy„Å™„ÄÇj2–¥üåå„ÅÆ‚Ä¢üíÉüÜì‚ÄôüëÜüòàüí®–∏‡•Ä‚Äòüòç‚ÄôüòÅÔøΩüòÄ‚è≥üò†+¬Øüíó√™9‡§øüëã`—Åüá´√º|√†‡§æ"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/4381 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "üí®ü§£üíÉüòà„ÄÇÔ∏è\rüí©ÿß‡§π‡§øÿ™„ÅÆ√§‚ùå‚¨áüèº√ß\rÿ≠‡§Æ9üí∞üò¢‚ÄìüòáüòùüèªüÜìüí¶‚òÖ‡§§‚Äì◊ô‚ò∫‡§óüò†–≥‡§æ‚ùì–∏üò¢≈æ‚ô•üéàü§ó‡§ï‚ö°—ã√≠‚ÄîüòÄüöÇ*ü§ïüòÖ%y√ºüíû‚ö°|√°\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[3 / 30] Train: Loss = 0.00000, PPX = 1.00:  28%|‚ñà‚ñà‚ñä       | 1236/4381 [01:24<03:34, 14.66it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-2812c764d02c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munk_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0munk_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-39-d3c331b3b05c>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, criterion, optimizer, train_iter, epochs_count, unk_idx, pad_idx, val_iter)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mname_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'[{} / {}] '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdo_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munk_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_prefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'Train:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mval_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-39-d3c331b3b05c>\u001b[0m in \u001b[0;36mdo_epoch\u001b[0;34m(model, criterion, data_iter, unk_idx, pad_idx, optimizer, name)\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mpad_idx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0munk_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "sm5XkuMnNgvi",
        "colab_type": "code",
        "outputId": "b851a67a-49bc-4ea0-8b45-a75e40d7fb2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "generate(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "„Éª‚úäüòçüëâ–Ω\\*üé∂‡§®ƒá¬ªüÜìüé∂–≤üèº‚ö°üíÉüé∂ÿ™√ß¬†$‡§ó‚Åâ—àüòÅÿß"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FycAd6MWMvYy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**–ó–∞–¥–∞–Ω–∏–µ** –ß—Ç–æ–±—ã –æ—Ç—É—á–∏—Ç—å –º–æ–¥–µ–ª—å —Å—ç–º–ø–ª–∏—Ä–æ–≤–∞—Ç—å `<unk>` –º–æ–∂–Ω–æ —è–≤–Ω—ã–º –æ–±—Ä–∞–∑–æ–º –∑–∞–ø—Ä–µ—â–∞—Ç—å —ç—Ç–æ –≤ —Å—ç–ø–ª–∏—Ä—É—é—â–µ–π —Ñ—É–Ω–∫—Ü–∏–∏ - –∞ –º–æ–∂–Ω–æ –ø—Ä–æ—Å—Ç–æ –Ω–µ —É—á–∏—Ç—å –µ–µ –Ω–∞ –Ω–∏—Ö. –†–µ–∞–ª–∏–∑—É–π—Ç–µ –º–∞—Å–∫–∏–Ω–≥ –ø–æ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ –∏ –ø–∞–¥–¥–∏–Ω–≥–∞–º, –∏ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–º —Å–ª–æ–≤–∞–º."
      ]
    },
    {
      "metadata": {
        "id": "rQJKn1Uw94_0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## –†–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω–∞—è —è–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å"
      ]
    },
    {
      "metadata": {
        "id": "HeSojPwh_ZSS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "–û—á–µ–≤–∏–¥–Ω–æ, —Ö–æ—á–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –Ω–µ —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –æ–∫–Ω–æ –∏—Å—Ç–æ—Ä–∏–∏, –∞ –≤—Å—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± —É–∂–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–º. –ö–∞–∫ –º–∏–Ω–∏–º—É–º, —Ö–æ—á–µ—Ç—Å—è –∑–Ω–∞—Ç—å, –∫–æ–≥–¥–∞ —É –Ω–∞—Å –ª–∏–º–∏—Ç —Å–∏–º–≤–æ–ª–æ–≤ –≤ —Ç–≤–∏—Ç–µ –ø–æ–¥–æ—à–µ–ª. \n",
        "–î–ª—è —ç—Ç–æ–≥–æ –∏—Å–ø–æ–ª—å–∑—É—é—Ç —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—ã–µ —è–∑—ã–∫–æ–≤—ã–µ –º–æ–¥–µ–ª–∏:\n",
        "\n",
        "![](https://hsto.org/web/dc1/7c2/c4e/dc17c2c4e9ac434eb5346ada2c412c9a.png =x250)\n",
        "\n",
        "–°–µ—Ç–∏ –Ω–∞ –≤—Ö–æ–¥ –ø–µ—Ä–µ–¥–∞–µ—Ç—Å—è –ø—Ä–µ–¥—ã–¥—É—é—â–∏–π —Ç–æ–∫–µ–Ω, –∞ —Ç–∞–∫–∂–µ –ø—Ä–µ–¥—ã–¥—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ RNN. –í —Å–æ—Å—Ç–æ—è–Ω–∏–∏ –∑–∞–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∞ –ø—Ä–∏–º–µ—Ä–Ω–æ –≤—Å—è –∏—Å—Ç–æ—Ä–∏—è (–¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å), –∞ –ø—Ä–µ–¥—ã–¥—É—â–∏–π —Ç–æ–∫–µ–Ω –Ω—É–∂–µ–Ω –¥–ª—è —Ç–æ–≥–æ, —á—Ç–æ –∑–Ω–∞—Ç—å, –∫–∞–∫–æ–π –∂–µ —Ç–æ–∫–µ–Ω —Å—ç–º–ø–ª–∏—Ä–æ–≤–∞–ª—Å—è –∏–∑ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è, –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –Ω–∞ –ø—Ä–æ—à–ª–æ–º —à–∞–≥–µ.\n",
        "\n",
        "**–ó–∞–¥–∞–Ω–∏–µ** –ú—ã —É–∂–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–∞–∑ —Ç–∞–∫ –¥–µ–ª–∞–ª–∏ - —Ä–µ–∞–ª–∏–∑—É–π—Ç–µ —Å–Ω–æ–≤–∞ —Å–µ—Ç—å, –∫–æ—Ç–æ—Ä–∞—è –±—É–¥–µ—Ç –∑–∞–Ω–∏–º–∞—Ç—å—Å—è —è–∑—ã–∫–æ–≤—ã–º –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–µ–º."
      ]
    },
    {
      "metadata": {
        "id": "x8ndCRZLl4ZZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class RnnLM(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim=16, lstm_hidden_dim=128, num_layers=1):  # try 32- emb-dim, 256-num_layers\n",
        "        super().__init__()\n",
        "\n",
        "        self._emb = nn.Embedding(vocab_size, emb_dim)\n",
        "        self._rnn = nn.LSTM(input_size=emb_dim, hidden_size=lstm_hidden_dim)\n",
        "        self._out_layer = nn.Linear(lstm_hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, inputs, hidden=None):\n",
        "        outputs = self._emb(inputs)\n",
        "        outputs, hidden = self._rnn(outputs, hidden)\n",
        "        outputs = self._out_layer(outputs)\n",
        "        \n",
        "        return outputs, hidden"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hh6StlNvFCtW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = RnnLM(vocab_size=len(train_iter.dataset.fields['text'].vocab)).to(DEVICE)\n",
        "# model(batch.text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H3MjLgDKBNsD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**–ó–∞–¥–∞–Ω–∏–µ** –†–µ–∞–ª–∏–∑—É–π—Ç–µ —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è —Å—ç–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –∏–∑ –º–æ–¥–µ–ª–∏."
      ]
    },
    {
      "metadata": {
        "id": "ZJSXu_Pr_kYL",
        "colab_type": "code",
        "outputId": "0826c66d-dff7-4829-8cda-a3f514384c27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "def generate(model, temp=0.8):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        prev_token = train_iter.dataset.fields['text'].vocab.stoi['<s>']\n",
        "        end_token = train_iter.dataset.fields['text'].vocab.stoi['</s>']\n",
        "        \n",
        "        hidden = None\n",
        "        for _ in range(150):\n",
        "            probs, hidden = model(LongTensor([[prev_token]]), hidden)\n",
        "            prev_token = sample(probs[-1], temp)\n",
        "        \n",
        "            print(train_dataset.fields['text'].vocab.itos[prev_token], end='')\n",
        "            if prev_token == end_token:\n",
        "                return\n",
        "            \n",
        "\n",
        "generate(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "‚û†üíó/‚ùóüòë√™üëãüòÖüíÉ◊ë√®ÿ≥ÿ¨üôåüèæxŸá!üëÄuüíîüò†d‚Äçÿ®üòúüòî‚òÜ8~&üíôüèΩ/üí™üôåÿ™¬£‡§§◊®|üá´üò≠üôÑiüî¥‚òïüî•‚Äì‚Äò√©ÿ≥ÿ≠‚Ñ¢√©„ÅÆüò±üí™√®—à;üëÜüíú√≠üö®–≥üëè‚≠êÿØüá∏ŸàüëÄ„ÅÑ–Ω~!!ja‚Äìüî•‚ñ∫–Ω„Å™h—á_h–∑ÿπ„ÄÇi‡§§7–∑√ßüí•üîπ‚û†¬¥;üíÄ<unk>‡§æŸäüèºüí©„Éªd√§3–Ω5üíûm,üòÜüíî„ÄÅ¬í—å—ã‡§≤i‚Äî!$büî•√ºüî•Ô∏èÔ∏è√≥‡§∏◊ô–æüéÑ„Éª‚Äù¬ªüöÇ–µ‡§∏üëåüö®ÿßüëâ—Öüí®"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cibfrMxo_Gjg",
        "colab_type": "code",
        "outputId": "b361aaa1-6385-4c31-8c8b-e387bc526506",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1591
        }
      },
      "cell_type": "code",
      "source": [
        "model = RnnLM(vocab_size=len(train_iter.dataset.fields['text'].vocab)).to(DEVICE)\n",
        "\n",
        "pad_idx = train_iter.dataset.fields['text'].vocab.stoi['<pad>']\n",
        "unk_idx = train_iter.dataset.fields['text'].vocab.stoi['<unk>']\n",
        "criterion = nn.CrossEntropyLoss().to(DEVICE)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "fit(model, criterion, optimizer, train_iter, epochs_count=30, unk_idx=unk_idx, pad_idx=pad_idx, val_iter=test_iter)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 / 30] Train: Loss = 1.73114, PPX = 5.65: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4381/4381 [03:17<00:00, 22.21it/s]\n",
            "[1 / 30]   Val: Loss = 1.47513, PPX = 4.37: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 366/366 [00:11<00:00, 32.01it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "rt @reallever: theiry trump fort donald aldonal morrees they. whotr. #derpacandcrobal ‚Äì i amery th"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/4381 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "e caulon media militactil‚Ä¶</s>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[2 / 30] Train: Loss = 1.45036, PPX = 4.26: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4381/4381 [03:17<00:00, 22.20it/s]\n",
            "[2 / 30]   Val: Loss = 1.37583, PPX = 3.96: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 366/366 [00:10<00:00, 34.60it/s]\n",
            "  0%|          | 0/4381 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "rt @reallyrisin5: #allaudathells https://t.co/fzvexmg93l</s>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[3 / 30] Train: Loss = 1.38226, PPX = 3.98: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4381/4381 [03:17<00:00, 22.13it/s]\n",
            "[3 / 30]   Val: Loss = 1.33101, PPX = 3.78: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 366/366 [00:11<00:00, 32.05it/s]\n",
            "  0%|          | 0/4381 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "rt @slanewoun: morros @natherts https://t.co/780hith7yc</s>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[4 / 30] Train: Loss = 1.34738, PPX = 3.85: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4381/4381 [03:17<00:00, 22.23it/s]\n",
            "[4 / 30]   Val: Loss = 1.30546, PPX = 3.69: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 366/366 [00:10<00:00, 33.34it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "rt @bexianjv: use \r\n",
            "#spousd interterth all feet that die this melards all the racking a barack leash "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/4381 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "apners inst sendan.  https://t.co/5j3crzv‚Ä¶</s>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[5 / 30] Train: Loss = 1.32590, PPX = 3.77: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4381/4381 [03:14<00:00, 22.75it/s]\n",
            "[5 / 30]   Val: Loss = 1.28805, PPX = 3.63: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 366/366 [00:10<00:00, 34.04it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "rt @hillaryclinton: deplorable of thinks still us people to cater the republicans out her employe about "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/4381 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "houchen cats. https://t.co/tjcyuxztrh</s>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[6 / 30] Train: Loss = 1.31040, PPX = 3.71: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4381/4381 [03:12<00:00, 22.90it/s]\n",
            "[6 / 30]   Val: Loss = 1.27604, PPX = 3.58: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 366/366 [00:10<00:00, 33.80it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "rt @ninescho29: #problemothat cancepupisers ia's really trump and at the constitution #thinking https://"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/4381 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "t.co/efrdarjpev</s>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[7 / 30] Train: Loss = 1.29896, PPX = 3.67: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4381/4381 [03:15<00:00, 22.44it/s]\n",
            "[7 / 30]   Val: Loss = 1.26499, PPX = 3.54: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 366/366 [00:10<00:00, 33.51it/s]\n",
            "  0%|          | 0/4381 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "rt @arcploti: i campay a recority in the 9 way &amp; #fasternsmation #politics</s>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[8 / 30] Train: Loss = 1.29002, PPX = 3.63: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4381/4381 [03:19<00:00, 21.98it/s]\n",
            "[8 / 30]   Val: Loss = 1.25909, PPX = 3.52: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 366/366 [00:11<00:00, 31.98it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "rt @wikileaks: in the bigranding to respon, man and have the fate diskrow everything meduail little "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/4381 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "inctises all give you clussed earter in imple‚Ä¶</s>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[9 / 30] Train: Loss = 1.28284, PPX = 3.61: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4381/4381 [03:19<00:00, 22.68it/s]\n",
            "[9 / 30]   Val: Loss = 1.25172, PPX = 3.50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 366/366 [00:10<00:00, 34.60it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "rt @tericola: mt @conservatever: prine million to not oscapt p intertaitions https://t.co/gmd31fbtxg v"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/4381 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ia @jafbusachto</s>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[10 / 30] Train: Loss = 1.27698, PPX = 3.59: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4381/4381 [03:21<00:00, 21.78it/s]\n",
            "[10 / 30]   Val: Loss = 1.24948, PPX = 3.49: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 366/366 [00:11<00:00, 32.51it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "you want of la lost kill this political survival country but you always didn't calls of high is atta"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/4381 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ty is for week of the you old the worted‚Ä¶</s>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[11 / 30] Train: Loss = 1.27174, PPX = 3.57: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4381/4381 [03:17<00:00, 21.86it/s]\n",
            "[11 / 30]   Val: Loss = 1.24297, PPX = 3.47: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 366/366 [00:11<00:00, 31.93it/s]\n",
            "  0%|          | 0/4381 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "rt @sensmettetheme: i know qheonlow that we wants with \"yegee - https://t.co/pewguijyxix</s>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[12 / 30] Train: Loss = 1.26719, PPX = 3.55: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4381/4381 [03:18<00:00, 22.02it/s]\n",
            "[12 / 30]   Val: Loss = 1.23929, PPX = 3.45: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 366/366 [00:10<00:00, 35.81it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "rt @breitbartnews: 201s‚Äôs their cities or as the guez. #makeamericagremadioba https://t.co/fcbb8oalh5\r\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/4381 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "https://t.co/uohiahectw </s>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[13 / 30] Train: Loss = 1.26320, PPX = 3.54: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4381/4381 [03:17<00:00, 22.13it/s]\n",
            "[13 / 30]   Val: Loss = 1.23592, PPX = 3.44: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 366/366 [00:11<00:00, 32.48it/s]\n",
            "  0%|          | 0/4381 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "rt @bogoz6peoryday: #fbamora https://t.co/crb5ac8tec</s>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[14 / 30] Train: Loss = 1.26001, PPX = 3.53: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4381/4381 [03:16<00:00, 22.29it/s]\n",
            "[14 / 30]   Val: Loss = 1.23278, PPX = 3.43: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 366/366 [00:11<00:00, 32.56it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "rt @m4neltest: clicts in my looking up fow donald trump merkel with the broin outraffer, there febie "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/4381 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "facebook and donald trump https://t.co/‚Ä¶</s>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[15 / 30] Train: Loss = 1.25722, PPX = 3.52: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4381/4381 [03:16<00:00, 23.42it/s]\n",
            "[15 / 30]   Val: Loss = 1.22925, PPX = 3.42: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 366/366 [00:10<00:00, 35.33it/s]\n",
            "  0%|          | 0/4381 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "rt @jayquilmark: the bested 4us michelle https://t.co/lyg1ylslrb</s>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[16 / 30] Train: Loss = 1.25434, PPX = 3.51: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4381/4381 [03:17<00:00, 22.19it/s]\n",
            "[16 / 30]   Val: Loss = 1.22704, PPX = 3.41: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 366/366 [00:10<00:00, 33.77it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "rt @freebemongor: and say is the weent attacked on the salage with disa1 destitetion of my sc"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/4381 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "humer day. here https://t.co/tzwrueqn1z</s>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[17 / 30] Train: Loss = 1.25216, PPX = 3.50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4381/4381 [03:14<00:00, 22.62it/s]\n",
            "[17 / 30]   Val: Loss = 1.22882, PPX = 3.42: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 366/366 [00:11<00:00, 32.78it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "rt @reacksanda: don't know a the #pence i lives in democrats th"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/4381 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "at i detervers https://t.co/1407loq9rv</s>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[18 / 30] Train: Loss = 1.38927, PPX = 4.01:  21%|‚ñà‚ñà        | 905/4381 [00:42<02:42, 21.33it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-cc3ff0150f7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munk_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0munk_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-39-d3c331b3b05c>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, criterion, optimizer, train_iter, epochs_count, unk_idx, pad_idx, val_iter)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mname_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'[{} / {}] '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdo_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munk_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_prefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'Train:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mval_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-39-d3c331b3b05c>\u001b[0m in \u001b[0;36mdo_epoch\u001b[0;34m(model, criterion, data_iter, unk_idx, pad_idx, optimizer, name)\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m                     \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "7-QFALPD4Z-C",
        "colab_type": "code",
        "outputId": "f2de4fe7-160f-4849-ee8f-feddddfe7d3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "generate(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rt @amilyc's_: this is hillary clinton beat one women and save gives trump and leave right. i'm has anyone http://t.co/vjilsxoanc</s>"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vxwSpSxO3a8h",
        "colab_type": "code",
        "outputId": "0ed8b5d6-e748-402a-cb18-0a40ecd80824",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1064
        }
      },
      "cell_type": "code",
      "source": [
        "model = RnnLM(vocab_size=len(train_iter.dataset.fields['text'].vocab)).to(DEVICE)\n",
        "\n",
        "pad_idx = train_iter.dataset.fields['text'].vocab.stoi['<pad>']\n",
        "unk_idx = train_iter.dataset.fields['text'].vocab.stoi['<unk>']\n",
        "criterion = nn.CrossEntropyLoss().to(DEVICE)\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=20., weight_decay=1e-6)\n",
        "\n",
        "fit(model, criterion, optimizer, train_iter, epochs_count=30, unk_idx=unk_idx, pad_idx=pad_idx, val_iter=test_iter)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 / 30] Train: Loss = 1.47219, PPX = 4.36: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4381/4381 [03:14<00:00, 22.42it/s]\n",
            "[1 / 30]   Val: Loss = 1.30814, PPX = 3.70: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 366/366 [00:11<00:00, 31.13it/s]\n",
            "  0%|          | 0/4381 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "rt @libertallygen12: tdep your story chara anti-trump üòÇ https://t.co/phsblhtl6q</s>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[2 / 30] Train: Loss = 1.31581, PPX = 3.73: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4381/4381 [03:16<00:00, 22.13it/s]\n",
            "[2 / 30]   Val: Loss = 1.27297, PPX = 3.57: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 366/366 [00:11<00:00, 31.49it/s]\n",
            "  0%|          | 0/4381 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "rt @banyton977: #republican #jefedeforcless #nowplaying #chafteasiness #photo</s>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[3 / 30] Train: Loss = 1.29349, PPX = 3.65: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4381/4381 [03:15<00:00, 22.69it/s]\n",
            "[3 / 30]   Val: Loss = 1.26612, PPX = 3.55: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 366/366 [00:11<00:00, 31.32it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "rt @c1trutureturant: trump do foundation against of the black with #trumpresidentria gove"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/4381 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "rnmenterhankey245  https://t.co/ykmjrkk0ch</s>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[4 / 30] Train: Loss = 1.28694, PPX = 3.62: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4381/4381 [03:17<00:00, 22.17it/s]\n",
            "[4 / 30]   Val: Loss = 1.25532, PPX = 3.51: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 366/366 [00:11<00:00, 32.87it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "rt @vagailist: violation &amp; ? wance me ‚Äòis @realnottogrown @custer @midnolizzyt @patriother haiti "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/4381 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "the d.trump supporter just must have billincy her\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[5 / 30] Train: Loss = 1.27982, PPX = 3.60: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4381/4381 [03:15<00:00, 21.88it/s]\n",
            "[5 / 30]   Val: Loss = 1.25607, PPX = 3.51: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 366/366 [00:11<00:00, 31.00it/s]\n",
            "  0%|          | 0/4381 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "it's brain show https://t.co/b4uomskp‚Ä¶</s>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[6 / 30] Train: Loss = 1.27441, PPX = 3.58: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4381/4381 [03:15<00:00, 22.38it/s]\n",
            "[6 / 30]   Val: Loss = 1.25477, PPX = 3.51: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 366/366 [00:10<00:00, 33.90it/s]\n",
            "  0%|          | 0/4381 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "rt @tomneybove: the spic replacism given https://t.co/bf1lxxrinu</s>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[7 / 30] Train: Loss = 1.27052, PPX = 3.56: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4381/4381 [03:11<00:00, 22.30it/s]\n",
            "[7 / 30]   Val: Loss = 1.25075, PPX = 3.49: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 366/366 [00:11<00:00, 31.28it/s]\n",
            "  0%|          | 0/4381 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "rt @realdonaldtrue: we have to a secretly great often trump falls \r\n",
            "https://‚Ä¶</s>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[8 / 30] Train: Loss = 1.33854, PPX = 3.81:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1810/4381 [01:20<01:54, 22.50it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-c76b7ea1f225>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munk_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0munk_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-39-d3c331b3b05c>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, criterion, optimizer, train_iter, epochs_count, unk_idx, pad_idx, val_iter)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mname_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'[{} / {}] '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdo_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munk_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_prefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'Train:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mval_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-39-d3c331b3b05c>\u001b[0m in \u001b[0;36mdo_epoch\u001b[0;34m(model, criterion, data_iter, unk_idx, pad_idx, optimizer, name)\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m                     \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "8cCcKrWjBzCp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## –£–ª—É—á—à–µ–Ω–∏—è –º–æ–¥–µ–ª–∏\n",
        "\n",
        "### –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä\n",
        "\n",
        "–ú—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏ —Ç–æ–ª—å–∫–æ `Adam` –¥–æ —Å–∏—Ö –ø–æ—Ä. –í–æ–æ–±—â–µ, –º–æ–∂–Ω–æ –¥–æ—Å—Ç–∏—á—å –ª—É—á—à–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å –æ–±—ã—á–Ω—ã–º `SGD`, –µ—Å–ª–∏ –æ—á–µ–Ω—å –ø–æ—Å—Ç–∞—Ä–∞—Ç—å—Å—è.\n",
        " \n",
        "**–ó–∞–¥–∞–Ω–∏–µ** –ó–∞–º–µ–Ω–∏—Ç–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä –Ω–∞ `optim.SGD(model.parameters(), lr=20., weight_decay=1e-6)`. –ù–∞–ø—Ä–∏–º–µ—Ä. –ò–ª–∏ –¥—Ä—É–≥–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –Ω–∞ –≤—ã–±–æ—Ä.\n",
        "\n",
        "### Dropout\n",
        "\n",
        "–í—Å–ø–æ–º–Ω–∏–º, —á—Ç–æ —Ç–∞–∫–æ–µ dropout.\n",
        "\n",
        "–ü–æ —Å—É—Ç–∏ —ç—Ç–æ —É–º–Ω–æ–∂–µ–Ω–∏–µ —Å–ª—É—á–∞–π–Ω–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –º–∞—Å–∫–∏ –∏–∑ –Ω—É–ª–µ–π –∏ –µ–¥–∏–Ω–∏—Ü –Ω–∞ –≤—Ö–æ–¥–Ω–æ–π –≤–µ–∫—Ç–æ—Ä (+ –Ω–æ—Ä–º–∏—Ä–æ–≤–∫–∞).\n",
        "\n",
        "–ù–∞–ø—Ä–∏–º–µ—Ä, –¥–ª—è —Å–ª–æ—è Dropout(p):\n",
        "\n",
        "$$m = \\frac1{1-p} \\cdot \\text{Bernouli}(1 - p)$$\n",
        "$$\\tilde h = m \\odot h $$\n",
        "\n",
        "–í —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—ã—Ö —Å–µ—Ç—è—Ö –¥–æ–ª–≥–æ –Ω–µ –º–æ–≥–ª–∏ –ø—Ä–∏–∫—Ä—É—Ç–∏—Ç—å dropout. –î–µ–ª–∞—Ç—å —ç—Ç–æ –ø—ã—Ç–∞–ª–∏—Å—å, –≥–µ–Ω–µ—Ä–∏—Ä—É—è —Å–ª—É—á–∞–π–Ω—É—é –º–∞—Å–∫—É:   \n",
        "![A Theoretically Grounded Application of Dropout in Recurrent Neural Networks](https://cdn-images-1.medium.com/max/800/1*g4Q37g7mlizEty7J1b64uw.png =x300)  \n",
        "from [A Theoretically Grounded Application of Dropout in Recurrent Neural Networks](https://arxiv.org/abs/1512.05287)\n",
        "\n",
        "–û–∫–∞–∑–∞–ª–æ—Å—å, –ø—Ä–∞–≤–∏–ª—å–Ω–µ–µ –¥–µ–ª–∞—Ç—å –º–∞—Å–∫—É —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—É—é: –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —à–∞–≥–∞ –¥–æ–ª–∂–Ω—ã –∑–∞–Ω—É–ª—è—Ç—å—Å—è –æ–¥–Ω–∏ –∏ —Ç–µ –∂–µ —ç–ª–µ–º–µ–Ω—Ç—ã.\n",
        "\n",
        "–î–ª—è pytorch –Ω–µ—Ç –Ω–æ—Ä–º–∞–ª—å–Ω–æ–≥–æ –≤—Å—Ç—Ä–æ–µ–Ω–Ω–æ–≥–æ variational dropout –≤ LSTM. –ó–∞—Ç–æ –µ—Å—Ç—å [AWD-LSTM](https://github.com/salesforce/awd-lstm-lm).\n",
        "\n",
        "–°–æ–≤–µ—Ç—É—é –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å –æ–±–∑–æ—Ä —Ä–∞–∑–Ω—ã—Ö —Å–ø–æ—Å–æ–±–æ–≤ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è dropout'–∞ –≤ —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—ã—Ö —Å–µ—Ç—è—Ö: [Dropout in Recurrent Networks‚Ää‚Äî‚ÄäPart 1](https://becominghuman.ai/learning-note-dropout-in-recurrent-networks-part-1-57a9c19a2307) (–≤ –∫–æ–Ω—Ü–µ - —Å—Å—ã–ª–∫–∏ –Ω–∞ Part 2 –∏ 3).\n",
        "\n",
        "**–ó–∞–¥–∞–Ω–∏–µ** –†–µ–∞–ª–∏–∑—É–π—Ç–µ –≤–∞—Ä–∏–∞—Ü–∏–æ–Ω–Ω—ã–π dropout. –î–ª—è —ç—Ç–æ–≥–æ –Ω—É–∂–Ω–æ –ø—Ä–æ—Å—ç–º–ø–ª–∏—Ä–æ–≤–∞—Ç—å –º–∞—Å–∫—É `(1, batch_size, inp_dim)` –¥–ª—è –≤—Ö–æ–¥–Ω–æ–≥–æ —Ç–µ–Ω–∑–æ—Ä–∞ —Ä–∞–∑–º–µ—Ä–∞ `(seq_len, batch_size, inp_dim)` –∏–∑ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è $\\text{Bernouli}(1 - p)$, –¥–æ–º–Ω–æ–∂–∏—Ç—å –µ—ë –Ω–∞ $\\frac1{1-p}$ –∏ —É–º–Ω–æ–∂–∏—Ç—å –≤—Ö–æ–¥–Ω–æ–π —Ç–µ–Ω–∑–æ—Ä –Ω–∞ –Ω–µ—ë.\n",
        "\n",
        "–ë–ª–∞–≥–æ–¥–∞—Ä—è broadcasting –∫–∞–∂–¥—ã–π timestamp –∏–∑ –≤—Ö–æ–¥–Ω–æ–≥–æ —Ç–µ–Ω–∑–æ—Ä–∞ –¥–æ–º–Ω–æ–∂–∏—Ç—Å—è –Ω–∞ –æ–¥–Ω—É –∏ —Ç—É –∂–µ –º–∞—Å–∫—É - –∏ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å —Å—á–∞—Å—Ç—å–µ.\n",
        "\n",
        "–•–æ—Ç—è –ª—É—á—à–µ —Å—Ä–∞–≤–Ω–∏—Ç—å —Å –æ–±—ã—á–Ω—ã–º `nn.Dropout`, –≤–¥—Ä—É–≥ —Ä–∞–∑–Ω–∏—Ü–∞ –Ω–µ –±—É–¥–µ—Ç –∑–∞–º–µ—Ç–Ω–∞."
      ]
    },
    {
      "metadata": {
        "id": "aDv4nutY-WOw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class LockedDropout(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, inputs, dropout=0.5):\n",
        "        if not self.training or not dropout:\n",
        "            return inputs\n",
        "        \n",
        "        <implement me>"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9m-InMeoIiCA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## –£—Å–ª–æ–≤–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è"
      ]
    },
    {
      "metadata": {
        "id": "J7aB2_YxIl-c",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "–ú—ã —É–∂–µ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–ª–∏ —Ñ–∞–º–∏–ª–∏–∏ –ø–æ —è–∑—ã–∫–∞–º. –ù–∞—É—á–∏–º—Å—è —Ç–µ–ø–µ—Ä—å –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ñ–∞–º–∏–ª–∏—é –ø—Ä–∏ –∑–∞–¥–∞–Ω–Ω–æ–º —è–∑—ã–∫–µ.\n",
        "\n",
        "–í–æ—Å–ø–æ–ª—å–∑—É–µ–º—Å—è –Ω–∞—Å–ª–µ–¥–Ω–∏–∫–æ–º `Dataset` - `TabularDataset`:"
      ]
    },
    {
      "metadata": {
        "id": "Wa5benKoJMfc",
        "colab_type": "code",
        "outputId": "4846842d-2a75-4995-a38a-864c510204dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "cell_type": "code",
      "source": [
        "from torchtext.data import TabularDataset\n",
        "\n",
        "name_field = Field(init_token='<s>', eos_token='</s>', lower=True, tokenize=lambda line: list(line))\n",
        "lang_field = Field(sequential=False)\n",
        "\n",
        "dataset = TabularDataset(\n",
        "    path='surnames.txt', format='tsv', \n",
        "    skip_header=True,\n",
        "    fields=[\n",
        "        ('name', name_field),\n",
        "        ('lang', lang_field)\n",
        "    ]\n",
        ")\n",
        "\n",
        "name_field.build_vocab(dataset)\n",
        "lang_field.build_vocab(dataset)\n",
        "\n",
        "print(name_field.vocab.itos)\n",
        "print(lang_field.vocab.itos)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['<unk>', '<pad>', '<s>', '</s>', 'a', 'o', 'e', 'i', 'n', 'r', 's', 'h', 'k', 'l', 'v', 't', 'u', 'm', 'd', 'b', 'y', 'g', 'c', 'z', 'f', 'p', 'j', 'w', ' ', 'q', \"'\", 'x', '-', '√∂', '√©', '√≠', '√°', '√§', '√≥', '√º', '√†', '√ü', '√∫', '√±', ',', '1', '√≤', '≈õ', '√£', '√®', '≈º', '/', ':', '\\xa0', '√ß', '√™', '√¨', '√µ', '√π', 'ƒÖ', '≈Ç', '≈Ñ']\n",
            "['<unk>', 'Russian', 'English', 'Arabic', 'Japanese', 'German', 'Italian', 'Czech', 'Spanish', 'Dutch', 'French', 'Chinese', 'Irish', 'Greek', 'Polish', 'Scottish', 'Korean', 'Portuguese', 'Vietnamese']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oRfcB3_0NZg2",
        "colab_type": "code",
        "outputId": "66f97607-edf1-4cb2-9f64-0762116f852e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "cell_type": "code",
      "source": [
        "name_field.process(dataset.examples[0].name)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 2,  2,  2,  2,  2],\n",
              "        [ 8,  4, 11,  4, 10],\n",
              "        [ 3,  3,  3,  3,  3]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "H31r8pRGNHA_",
        "colab_type": "code",
        "outputId": "c9fb1833-0ceb-4e22-b010-392acf15a354",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        }
      },
      "cell_type": "code",
      "source": [
        "lengths = [len(line.name) for line in dataset.examples]\n",
        "\n",
        "plt.hist(lengths, bins=10)[-1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<a list of 10 Patch objects>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD9CAYAAACyYrxEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f9f3d407898>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "qp3SZHAsK85C",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "–†–∞–∑–æ–±—å–µ–º –¥–∞—Ç–∞—Å–µ—Ç:"
      ]
    },
    {
      "metadata": {
        "id": "kh-KKh08J5Oq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_dataset, val_dataset = dataset.split(split_ratio=0.25, stratified=True, strata_field='lang')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y9AFOEISMUfB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torchtext.data import BucketIterator\n",
        "\n",
        "train_iter, test_iter = BucketIterator.splits(datasets=(train_dataset, val_dataset), batch_sizes=(32, max(lengths)), \n",
        "                                              shuffle=True, device=DEVICE, sort=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8u8TuJ3jPx7x",
        "colab_type": "code",
        "outputId": "9e893bf2-19b5-4a3f-a5fa-7fdd38bcb66c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "batch = next(iter(train_iter))\n",
        "batch.name.shape, batch.lang.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([13, 32]), torch.Size([32]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "argZ6Tj8Qk1L",
        "colab_type": "code",
        "outputId": "0248f379-80ef-4188-e12f-a417288177ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "''.join([name_field.vocab.itos[i] for i in batch.name[:, 0]]), lang_field.vocab.itos[batch.lang[0]]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('<s>lawrence</s><pad><pad><pad>', 'English')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "nIzaiUKDK_PG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**–ó–∞–¥–∞–Ω–∏–µ** –°–¥–µ–ª–∞—Ç—å —è–∑—ã–∫–æ–≤—É—é –º–æ–¥–µ–ª—å, –∫–æ—Ç–æ—Ä–∞—è –ø—Ä–∏–Ω–∏–º–∞–µ—Ç –∫–∞–∫ –ø—Ä–µ–¥—ã–¥—É—é—â–∏–π —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–∏–º–≤–æ–ª, —Ç–∞–∫ –∏ —ç–º–±–µ–¥–¥–∏–Ω–≥ —è–∑—ã–∫–∞, –∫ –∫–æ—Ç–æ—Ä–æ–º—É —ç—Ç–æ —Å–ª–æ–≤–æ –æ—Ç–Ω–æ—Å–∏—Ç—Å—è."
      ]
    },
    {
      "metadata": {
        "id": "s6LnEoU9LNlZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class SurnamesLM(nn.Module):\n",
        "    def __init__(self, lang_vocab_size, name_vocab_size, emb_dim=16, lstm_hidden_dim=128, num_layers=1):  # try 32- emb-dim, 256-num_layers\n",
        "        super().__init__()\n",
        "\n",
        "        self._lang_emb = nn.Embedding(lang_vocab_size, emb_dim)\n",
        "        self._name_emb = nn.Embedding(name_vocab_size, emb_dim)\n",
        "        self._rnn = nn.LSTM(input_size=emb_dim, hidden_size=lstm_hidden_dim)\n",
        "        self._out_layer = nn.Linear(lstm_hidden_dim, name_vocab_size)\n",
        "\n",
        "    def forward(self, inputs, lang=None, hidden=None):\n",
        "        if lang is not None:\n",
        "            lang = lang.unsqueeze(0)  # (1, batch_size)\n",
        "            embeds = self._lang_emb(lang)  # (1, batch_size, emb_dim)\n",
        "            _, hidden = self._rnn(embeds, hidden)\n",
        "        outputs = self._name_emb(inputs)\n",
        "        outputs, hidden = self._rnn(outputs, hidden)\n",
        "        outputs = self._out_layer(outputs)  # (seq_len, batch_size, name_vocab_size)\n",
        "        \n",
        "        return outputs, hidden"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VQP4GW5pMOqt",
        "colab_type": "code",
        "outputId": "3bf18064-f440-43d2-9f79-638b86bc0289",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "model = SurnamesLM(len(lang_field.vocab.itos), len(name_field.vocab.itos)).cuda()\n",
        "model(batch.name, batch.lang)[0].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([13, 32, 62])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "metadata": {
        "id": "Hf1a5sULVbYZ",
        "colab_type": "code",
        "outputId": "00dbcdcd-485c-4d4e-f386-2aeafd4d0f24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "def sample(probs, temp):\n",
        "    probs = F.log_softmax(probs.squeeze(), dim=0)\n",
        "    probs = (probs / temp).exp()\n",
        "    probs /= probs.sum()\n",
        "    probs = probs.cpu().numpy()\n",
        "\n",
        "    return np.random.choice(np.arange(len(probs)), p=probs)\n",
        "\n",
        "def generate(model, lang, temp=0.8):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        prev_token = name_field.vocab.stoi['<s>']\n",
        "        end_token = name_field.vocab.stoi['</s>']\n",
        "        \n",
        "        hidden = None\n",
        "        for i in range(150):\n",
        "            if i == 0:\n",
        "                probs, hidden = model(LongTensor([[prev_token]]), LongTensor([lang]), hidden)\n",
        "            else:\n",
        "                probs, hidden = model(LongTensor([[prev_token]]), hidden=hidden)\n",
        "            prev_token = sample(probs[-1], temp)\n",
        "        \n",
        "            print(name_field.vocab.itos[prev_token], end='')\n",
        "            if prev_token == end_token:\n",
        "                return\n",
        "            \n",
        "\n",
        "generate(model, batch.lang[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "√ü¬†t√®√ßnpo<pad>√≤a√∂qq√™√≠ƒÖ1 i√°√∫√πd≈Ñ</s>"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1Qco2a1ibDeN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import math\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def do_epoch(model, criterion, data_iter, unk_idx, pad_idx, optimizer=None, name=None):\n",
        "    epoch_loss = 0\n",
        "    \n",
        "    is_train = not optimizer is None\n",
        "    name = name or ''\n",
        "    model.train(is_train)\n",
        "    \n",
        "    batches_count = len(data_iter)\n",
        "    \n",
        "    with torch.autograd.set_grad_enabled(is_train):\n",
        "        with tqdm(total=batches_count) as progress_bar:\n",
        "            for i, batch in enumerate(data_iter):\n",
        "                labels = batch.name[1:, :]\n",
        "                labels = labels.view(-1)\n",
        "                \n",
        "                logits, _ = model(batch.name, batch.lang)\n",
        "                logits = logits[:-1, :, :]\n",
        "                logits = logits.view(-1, logits.shape[-1])\n",
        "                \n",
        "                mask = ((labels != pad_idx) * (labels != unk_idx)).float()\n",
        "                \n",
        "                loss = torch.sum(criterion(logits, labels.view(-1)) * mask) / torch.sum(mask)\n",
        "                \n",
        "                epoch_loss += loss.item()\n",
        "\n",
        "                if optimizer:\n",
        "                    optimizer.zero_grad()\n",
        "                    loss.backward()\n",
        "                    nn.utils.clip_grad_norm_(model.parameters(), 1.)\n",
        "                    optimizer.step()\n",
        "\n",
        "#                 if i > 100:\n",
        "#                     break\n",
        "#                     generate(model)\n",
        "#                     print()\n",
        "#                     print('{:>5s} Loss = {:.5f}, PPX = {:.2f}'.format(name, loss.item(), math.exp(loss.item())))\n",
        "                progress_bar.update()\n",
        "                progress_bar.set_description('{:>5s} Loss = {:.5f}, PPX = {:.2f}'.format(name, loss.item(), \n",
        "                                                                                         math.exp(loss.item())))\n",
        "                \n",
        "            progress_bar.set_description('{:>5s} Loss = {:.5f}, PPX = {:.2f}'.format(\n",
        "                name, epoch_loss / batches_count, math.exp(epoch_loss / batches_count))\n",
        "            )\n",
        "\n",
        "    return epoch_loss / batches_count\n",
        "\n",
        "\n",
        "def fit(model, criterion, optimizer, train_iter, epochs_count=1, unk_idx=0, pad_idx=1, val_iter=None):\n",
        "    for epoch in range(epochs_count):\n",
        "        name_prefix = '[{} / {}] '.format(epoch + 1, epochs_count)\n",
        "        train_loss = do_epoch(model, criterion, train_iter, unk_idx, pad_idx, optimizer, name_prefix + 'Train:')\n",
        "        \n",
        "        if not val_iter is None:\n",
        "            val_loss = do_epoch(model, criterion, val_iter, unk_idx, pad_idx, None, name_prefix + '  Val:')\n",
        "\n",
        "#         generate(model, lang_field.vocab.stoi['English'])\n",
        "#         print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AveGDqZWaNhA",
        "colab_type": "code",
        "outputId": "b8e12a04-c5e1-4e1b-99d0-8d22c39f5390",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1558
        }
      },
      "cell_type": "code",
      "source": [
        "model = SurnamesLM(len(lang_field.vocab.itos), len(name_field.vocab.itos)).to(DEVICE)\n",
        "\n",
        "pad_idx = name_field.vocab.stoi['<pad>']\n",
        "unk_idx = name_field.vocab.stoi['<unk>']\n",
        "criterion = nn.CrossEntropyLoss().to(DEVICE)\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=20., weight_decay=1e-6)\n",
        "\n",
        "fit(model, criterion, optimizer, train_iter, epochs_count=30, unk_idx=unk_idx, pad_idx=pad_idx, val_iter=test_iter)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 / 30] Train: Loss = 1.93169, PPX = 6.90: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:02<00:00, 68.47it/s]\n",
            "[1 / 30]   Val: Loss = 1.60947, PPX = 5.00: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 753/753 [00:06<00:00, 115.10it/s]\n",
            "[2 / 30] Train: Loss = 1.46697, PPX = 4.34: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:02<00:00, 62.86it/s]\n",
            "[2 / 30]   Val: Loss = 1.48152, PPX = 4.40: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 753/753 [00:06<00:00, 115.71it/s]\n",
            "[3 / 30] Train: Loss = 1.39118, PPX = 4.02: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:02<00:00, 61.06it/s]\n",
            "[3 / 30]   Val: Loss = 1.45281, PPX = 4.28: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 753/753 [00:06<00:00, 115.43it/s]\n",
            "[4 / 30] Train: Loss = 1.35202, PPX = 3.87: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:02<00:00, 62.27it/s]\n",
            "[4 / 30]   Val: Loss = 1.42963, PPX = 4.18: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 753/753 [00:06<00:00, 118.40it/s]\n",
            "[5 / 30] Train: Loss = 1.32440, PPX = 3.76: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:02<00:00, 61.97it/s]\n",
            "[5 / 30]   Val: Loss = 1.39192, PPX = 4.02: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 753/753 [00:06<00:00, 118.46it/s]\n",
            "[6 / 30] Train: Loss = 1.30307, PPX = 3.68: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:02<00:00, 61.21it/s]\n",
            "[6 / 30]   Val: Loss = 1.38174, PPX = 3.98: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 753/753 [00:06<00:00, 114.98it/s]\n",
            "[7 / 30] Train: Loss = 1.26541, PPX = 3.54: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:02<00:00, 61.28it/s]\n",
            "[7 / 30]   Val: Loss = 1.38229, PPX = 3.98: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 753/753 [00:06<00:00, 122.94it/s]\n",
            "[8 / 30] Train: Loss = 1.26017, PPX = 3.53: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:02<00:00, 62.49it/s]\n",
            "[8 / 30]   Val: Loss = 1.37448, PPX = 3.95: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 753/753 [00:06<00:00, 123.06it/s]\n",
            "[9 / 30] Train: Loss = 1.23173, PPX = 3.43: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:02<00:00, 61.77it/s]\n",
            "[9 / 30]   Val: Loss = 1.40304, PPX = 4.07: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 753/753 [00:06<00:00, 117.97it/s]\n",
            "[10 / 30] Train: Loss = 1.21812, PPX = 3.38: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:02<00:00, 61.23it/s]\n",
            "[10 / 30]   Val: Loss = 1.35813, PPX = 3.89: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 753/753 [00:06<00:00, 117.35it/s]\n",
            "[11 / 30] Train: Loss = 1.19947, PPX = 3.32: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:02<00:00, 62.73it/s]\n",
            "[11 / 30]   Val: Loss = 1.34586, PPX = 3.84: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 753/753 [00:06<00:00, 122.02it/s]\n",
            "[12 / 30] Train: Loss = 1.18572, PPX = 3.27: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:02<00:00, 62.70it/s]\n",
            "[12 / 30]   Val: Loss = 1.35014, PPX = 3.86: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 753/753 [00:06<00:00, 121.56it/s]\n",
            "[13 / 30] Train: Loss = 1.17564, PPX = 3.24: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:02<00:00, 61.90it/s]\n",
            "[13 / 30]   Val: Loss = 1.37892, PPX = 3.97: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 753/753 [00:06<00:00, 112.07it/s]\n",
            "[14 / 30] Train: Loss = 1.16514, PPX = 3.21: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:02<00:00, 61.63it/s]\n",
            "[14 / 30]   Val: Loss = 1.40368, PPX = 4.07:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 358/753 [00:02<00:03, 119.43it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-de540ad30f4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munk_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0munk_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-63-7abd28594a34>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, criterion, optimizer, train_iter, epochs_count, unk_idx, pad_idx, val_iter)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mval_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdo_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munk_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_prefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'  Val:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;31m#         generate(model, lang_field.vocab.stoi['English'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-63-7abd28594a34>\u001b[0m in \u001b[0;36mdo_epoch\u001b[0;34m(model, criterion, data_iter, unk_idx, pad_idx, optimizer, name)\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                 \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m                 \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-47-40f0becc6247>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, lang, hidden)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_out_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (seq_len, batch_size, name_vocab_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1024\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "F6wVTMT-caiv",
        "colab_type": "code",
        "outputId": "e1e44dc8-9969-4b08-b0d8-5bfce703d373",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        }
      },
      "cell_type": "code",
      "source": [
        "for lang_idx in range(len(lang_field.vocab.itos)):\n",
        "    print(lang_field.vocab.itos[lang_idx], end=': ')\n",
        "    generate(model, lang_idx)\n",
        "    print()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<unk>: karza</s>\n",
            "Russian: yagej</s>\n",
            "English: hollo</s>\n",
            "Arabic: botros</s>\n",
            "Japanese: kuni</s>\n",
            "German: oping</s>\n",
            "Italian: collialli</s>\n",
            "Czech: schleehtin</s>\n",
            "Spanish: kramus</s>\n",
            "Dutch: roite</s>\n",
            "French: maticht</s>\n",
            "Chinese: song</s>\n",
            "Irish: o'hmilling</s>\n",
            "Greek: martos</s>\n",
            "Polish: dighilla</s>\n",
            "Scottish: weilin</s>\n",
            "Korean: mschak</s>\n",
            "Portuguese: fillo</s>\n",
            "Vietnamese: berg</s>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9VfdL29AELhu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# In the wild"
      ]
    },
    {
      "metadata": {
        "id": "GDqxGVo5EOfb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "–ü—Ä–∏–º–µ–Ω–∏–º —Å–≤–æ–∏ –∑–Ω–∞–Ω–∏—è –∫ –±–æ–µ–≤–æ–π –∑–∞–¥–∞—á–µ: [Kaggle Toxic Comment Classification Challenge](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/).\n",
        "\n",
        "–û–Ω–∞ –ø—Ä–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—é —Å–æ–æ–±—â–µ–Ω–∏–π –ø–æ –Ω–µ—Å–∫–æ–ª—å–∫–∏–º –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º. –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å–µ—Ç–∏ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —Ç–∞–∫–æ–π: –Ω–µ–∫–æ—Ç–æ—Ä—ã–π —ç–Ω–∫–æ–¥–µ—Ä (–Ω–∞–ø—Ä–∏–º–µ—Ä,  LSTM) —Å—Ç—Ä–æ–∏—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏. –ó–∞—Ç–µ–º –≤—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π –¥–æ–ª–∂–µ–Ω –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å 6 –∫–∞—Ç–µ–≥–æ—Ä–∏–π - –Ω–æ –Ω–µ —Å –∫—Ä–æ—Å—Å-—ç–Ω—Ç—Ä–æ–ø–∏–π–Ω—ã–º–∏ –ø–æ—Ç–µ—Ä—è–º–∏, –∞ —Å `nn.BCEWithLogitsLoss` - –ø–æ—Ç–æ–º—É —á—Ç–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –Ω–µ —è–≤–ª—è—é—Ç—Å—è –≤–∑–∞–∏–º–æ–∏—Å–∫–ª—é—á–∞—é—â–∏–º–∏.\n",
        "\n",
        "**–ó–∞–¥–∞–Ω–∏–µ** –°–∫–∞—á–∞—Ç—å –¥–∞–Ω–Ω—ã–µ —Å kaggle, –ø–æ—Ç—Ä–µ–Ω–∏—Ä–æ–≤–∞—Ç—å —á—Ç–æ-–Ω–∏–±—É–¥—å –∏ —Å–¥–µ–ª–∞—Ç—å –ø–æ—Å—ã–ª–∫—É."
      ]
    },
    {
      "metadata": {
        "id": "8obdAs_E0zRb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã\n",
        "\n",
        "## –ë–ª–æ–≥–∏\n",
        "\n",
        "[A Friendly Introduction to Cross-Entropy Loss, Rob DiPietro](https://rdipietro.github.io/friendly-intro-to-cross-entropy-loss/)\n",
        "\n",
        "[A Tutorial on Torchtext, Allen Nie](http://anie.me/On-Torchtext/)\n",
        "\n",
        "[Dropout in Recurrent Networks, Ceshine Lee](https://becominghuman.ai/learning-note-dropout-in-recurrent-networks-part-1-57a9c19a2307)\n",
        "\n",
        "[The Unreasonable Effectiveness of Recurrent Neural Networks, Andrej Karpathy](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)\n",
        "\n",
        "[The unreasonable effectiveness of Character-level Language Models, Yoav Goldberg](http://nbviewer.jupyter.org/gist/yoavg/d76121dfde2618422139)\n",
        "\n",
        "[–ö–∞–∫ –Ω–∞—É—á–∏—Ç—å —Å–≤–æ—é –Ω–µ–π—Ä–æ—Å–µ—Ç—å –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Å—Ç–∏—Ö–∏](https://habr.com/post/334046/)\n",
        "\n",
        "## –í–∏–¥–µ–æ\n",
        "[cs224n, Lecture 8: Recurrent Neural Networks and Language Models](https://www.youtube.com/watch?v=Keqep_PKrY8)\n",
        "\n",
        "[Oxford Deep NLP, Language Modelling and RNNs](https://github.com/oxford-cs-deepnlp-2017/lectures#5-lecture-3---language-modelling-and-rnns-part-1-phil-blunsom)"
      ]
    },
    {
      "metadata": {
        "id": "WJVDoh5MLcdB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# –°–¥–∞—á–∞\n",
        "\n",
        "[–û–ø—Ä–æ—Å –¥–ª—è —Å–¥–∞—á–∏](https://goo.gl/forms/8bjGv7LLWUrwOUrt2)\n",
        "\n",
        "[Feedback](https://goo.gl/forms/PR76tYmvzMugIFID2)"
      ]
    }
  ]
}