{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Week 06 - RNNs, part 2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "P59NYU98GCb9",
        "colab_type": "code",
        "outputId": "76510c6e-221f-47d1-df96-c22d3e3025ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "!pip3 -qq install torch==0.4.1\n",
        "!pip install -qq bokeh==0.13.0\n",
        "!pip install -qq gensim==3.6.0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tcmalloc: large alloc 1073750016 bytes == 0x5a1e4000 @  0x7f05aeb612a4 0x594e17 0x626104 0x51190a 0x4f5277 0x510c78 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f6070 0x510c78 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f6070 0x4f3338 0x510fb0 0x5119bd 0x4f6070\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8sVtGHmA9aBM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    from torch.cuda import FloatTensor, LongTensor\n",
        "else:\n",
        "    from torch import FloatTensor, LongTensor\n",
        "\n",
        "np.random.seed(42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-6CNKM3b4hT1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Рекуррентные нейронные сети, часть 2"
      ]
    },
    {
      "metadata": {
        "id": "O_XkoGNQUeGm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## POS Tagging"
      ]
    },
    {
      "metadata": {
        "id": "QFEtWrS_4rUs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Мы уже посмотрели на применение рекуррентных сетей для классификации.\n",
        "\n",
        "![RNN types](http://karpathy.github.io/assets/rnn/diags.jpeg =x250)\n",
        "\n",
        "*From [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)*\n",
        "\n",
        "Перейдем к ещё одному варианту - sequence labeling (последняя картинка).\n",
        "\n",
        "Самые популярные примеры для такой постановки задачи - Part-of-Speech Tagging и Named Entity Recognition.\n",
        "\n",
        "Мы порешаем сейчас POS Tagging для английского.\n",
        "\n",
        "Будем работать с таким набором тегов:\n",
        "- ADJ - adjective (new, good, high, ...)\n",
        "- ADP - adposition (on, of, at, ...)\n",
        "- ADV - adverb (really, already, still, ...)\n",
        "- CONJ - conjunction (and, or, but, ...)\n",
        "- DET - determiner, article (the, a, some, ...)\n",
        "- NOUN - noun (year, home, costs, ...)\n",
        "- NUM - numeral (twenty-four, fourth, 1991, ...)\n",
        "- PRT - particle (at, on, out, ...)\n",
        "- PRON - pronoun (he, their, her, ...)\n",
        "- VERB - verb (is, say, told, ...)\n",
        "- . - punctuation marks (. , ;)\n",
        "- X - other (ersatz, esprit, dunno, ...)"
      ]
    },
    {
      "metadata": {
        "id": "EPIkKdFlHB-X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Скачаем данные:"
      ]
    },
    {
      "metadata": {
        "id": "TiA2dGmgF1rW",
        "colab_type": "code",
        "outputId": "b53e2584-c53c-47cf-c5b1-5fb37a5fe86a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from sklearn.cross_validation import train_test_split\n",
        "\n",
        "nltk.download('brown')\n",
        "nltk.download('universal_tagset')\n",
        "\n",
        "data = nltk.corpus.brown.tagged_sents(tagset='universal')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
            "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/universal_tagset.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "d93g_swyJA_V",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Пример размеченного предложения:"
      ]
    },
    {
      "metadata": {
        "id": "QstS4NO0L97c",
        "colab_type": "code",
        "outputId": "d4f25216-ab27-4c3b-a668-10f4fa2a608e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "cell_type": "code",
      "source": [
        "for word, tag in data[0]:\n",
        "    print('{:15}\\t{}'.format(word, tag))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The            \tDET\n",
            "Fulton         \tNOUN\n",
            "County         \tNOUN\n",
            "Grand          \tADJ\n",
            "Jury           \tNOUN\n",
            "said           \tVERB\n",
            "Friday         \tNOUN\n",
            "an             \tDET\n",
            "investigation  \tNOUN\n",
            "of             \tADP\n",
            "Atlanta's      \tNOUN\n",
            "recent         \tADJ\n",
            "primary        \tNOUN\n",
            "election       \tNOUN\n",
            "produced       \tVERB\n",
            "``             \t.\n",
            "no             \tDET\n",
            "evidence       \tNOUN\n",
            "''             \t.\n",
            "that           \tADP\n",
            "any            \tDET\n",
            "irregularities \tNOUN\n",
            "took           \tVERB\n",
            "place          \tNOUN\n",
            ".              \t.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "epdW8u_YXcAv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Построим разбиение на train/val/test - наконец-то, всё как у нормальных людей.\n",
        "\n",
        "На train будем учиться, по val - подбирать параметры и делать всякие early stopping, а на test - принимать модель по ее финальному качеству."
      ]
    },
    {
      "metadata": {
        "id": "xTai8Ta0lgwL",
        "colab_type": "code",
        "outputId": "60e0d7f3-d256-42c8-984a-2fcb9a7d9578",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "train_data, test_data = train_test_split(data, test_size=0.25, random_state=42)\n",
        "train_data, val_data = train_test_split(train_data, test_size=0.15, random_state=42)\n",
        "\n",
        "print('Words count in train set:', sum(len(sent) for sent in train_data))\n",
        "print('Words count in val set:', sum(len(sent) for sent in val_data))\n",
        "print('Words count in test set:', sum(len(sent) for sent in test_data))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Words count in train set: 739769\n",
            "Words count in val set: 130954\n",
            "Words count in test set: 290469\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eChdLNGtXyP0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Построим маппинги из слов в индекс и из тега в индекс:\n"
      ]
    },
    {
      "metadata": {
        "id": "pCjwwDs6Zq9x",
        "colab_type": "code",
        "outputId": "4d2325cb-c3bd-48a8-f905-eda8a8b6cce7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "words = {word for sample in train_data for word, tag in sample}\n",
        "word2ind = {word: ind + 1 for ind, word in enumerate(words)}\n",
        "word2ind['<pad>'] = 0\n",
        "\n",
        "tags = {tag for sample in train_data for word, tag in sample}\n",
        "tag2ind = {tag: ind + 1 for ind, tag in enumerate(tags)}\n",
        "tag2ind['<pad>'] = 0\n",
        "\n",
        "print('Unique words in train = {}. Tags = {}'.format(len(word2ind), tags))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique words in train = 45441. Tags = {'PRT', 'VERB', 'CONJ', '.', 'ADV', 'X', 'ADP', 'PRON', 'NOUN', 'ADJ', 'DET', 'NUM'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "URC1B2nvPGFt",
        "colab_type": "code",
        "outputId": "c02746e4-5244-440a-e01b-1a465cfaa1ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        }
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "tag_distribution = Counter(tag for sample in train_data for _, tag in sample)\n",
        "tag_distribution = [tag_distribution[tag] for tag in tags]\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "bar_width = 0.35\n",
        "plt.bar(np.arange(len(tags)), tag_distribution, bar_width, align='center', alpha=0.5)\n",
        "plt.xticks(np.arange(len(tags)), tags)\n",
        "    \n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmUAAAEvCAYAAAAEpLawAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhjJJkqQC/H83/mr9YwVFygAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fb4130d35f8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "gArQwbzWWkgi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Бейзлайн\n",
        "\n",
        "Какой самый простой теггер можно придумать? Давайте просто запоминать, какие теги самые вероятные для слова (или для последовательности):\n",
        "\n",
        "![tag-context](https://www.nltk.org/images/tag-context.png =x150)  \n",
        "*From [Categorizing and Tagging Words, nltk](https://www.nltk.org/book/ch05.html)*\n",
        "\n",
        "На картинке показано, что для предсказания $t_n$ используются два предыдущих предсказанных тега + текущее слово. По корпусу считаются вероятность для $P(t_n| w_n, t_{n-1}, t_{n-2})$, выбирается тег с максимальной вероятностью.\n",
        "\n",
        "Более аккуратно такая идея реализована в Hidden Markov Models: по тренировочному корпусу вычисляются вероятности $P(w_n| t_n), P(t_n|t_{n-1}, t_{n-2})$ и максимизируется их произведение.\n",
        "\n",
        "Простейший вариант - униграммная модель, учитывающая только слово:"
      ]
    },
    {
      "metadata": {
        "id": "5rWmSToIaeAo",
        "colab_type": "code",
        "outputId": "8d16b02b-2532-45e5-89b9-7e4fa9ff5dee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "default_tagger = nltk.DefaultTagger('NN')\n",
        "\n",
        "unigram_tagger = nltk.UnigramTagger(train_data, backoff=default_tagger)\n",
        "print('Accuracy of unigram tagger = {:.2%}'.format(unigram_tagger.evaluate(test_data)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of unigram tagger = 92.62%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "07Ymb_MkbWsF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Добавим вероятности переходов:"
      ]
    },
    {
      "metadata": {
        "id": "vjz_Rk0bbMyH",
        "colab_type": "code",
        "outputId": "4478f179-8033-4c24-cd06-1a7e6027220d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "bigram_tagger = nltk.BigramTagger(train_data, backoff=unigram_tagger)\n",
        "print('Accuracy of bigram tagger = {:.2%}'.format(bigram_tagger.evaluate(test_data)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of bigram tagger = 93.42%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uWMw6QHvbaDd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Обратите внимание, что `backoff` важен:"
      ]
    },
    {
      "metadata": {
        "id": "8XCuxEBVbOY_",
        "colab_type": "code",
        "outputId": "69cc0ec6-81d7-4d05-a54b-68a699f3889e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "trigram_tagger = nltk.TrigramTagger(train_data)\n",
        "print('Accuracy of trigram tagger = {:.2%}'.format(trigram_tagger.evaluate(test_data)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of trigram tagger = 23.33%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4t3xyYd__8d-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Делаемся рекуррентнее\n",
        "\n",
        "Униграмная модель работает на удивление хорошо, но мы же собрались учить сеточки.\n",
        "\n",
        "Омонимия - основная причина, почему униграмная модель плоха:\n",
        "*“he cashed a check at the **bank**”*  \n",
        "vs  \n",
        "*“he sat on the **bank** of the river”*\n",
        "\n",
        "Поэтому нам очень полезно учитывать контекст при предсказании тега.\n",
        "\n",
        "Воспользуемся LSTM - он умеет работать с контекстом очень даже хорошо:\n",
        "\n",
        "![](https://image.ibb.co/kgmoff/Baseline-Tagger.png =x400)\n",
        "\n",
        "Синим показано выделение фичей из слова, LSTM оранжевенький - он строит эмбеддинги слов с учетом контекста, а дальше зелененькая логистическая регрессия делает предсказания тегов."
      ]
    },
    {
      "metadata": {
        "id": "RtRbz1SwgEqc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def convert_data(data, word2ind, tag2ind):\n",
        "    X = [[word2ind.get(word, 0) for word, _ in sample] for sample in data]\n",
        "    y = [[tag2ind.get(tag, 0) for _, tag in sample] for sample in data]\n",
        "    \n",
        "    return X, y\n",
        "\n",
        "X_train, y_train = convert_data(train_data, word2ind, tag2ind)\n",
        "X_val, y_val = convert_data(val_data, word2ind, tag2ind)\n",
        "X_test, y_test = convert_data(test_data, word2ind, tag2ind)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DhsTKZalfih6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def iterate_batches(data, batch_size):\n",
        "    X, y = data\n",
        "    n_samples = len(X)\n",
        "\n",
        "    indices = np.arange(n_samples)\n",
        "    np.random.shuffle(indices)\n",
        "    \n",
        "    for start in range(0, n_samples, batch_size):\n",
        "        end = min(start + batch_size, n_samples)\n",
        "        \n",
        "        batch_indices = indices[start:end]\n",
        "        \n",
        "        max_sent_len = max(len(X[ind]) for ind in batch_indices)\n",
        "        X_batch = np.zeros((max_sent_len, len(batch_indices)))\n",
        "        y_batch = np.zeros((max_sent_len, len(batch_indices)))\n",
        "        \n",
        "        for batch_ind, sample_ind in enumerate(batch_indices):\n",
        "            X_batch[:len(X[sample_ind]), batch_ind] = X[sample_ind]\n",
        "            y_batch[:len(y[sample_ind]), batch_ind] = y[sample_ind]\n",
        "            \n",
        "        yield X_batch, y_batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Gixp3BZ4_-s9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def iterate_test_batches(data, batch_size):\n",
        "    X = [[word for word, _ in sample] for sample in data]\n",
        "    y = [[tag for _, tag in sample] for sample in data]\n",
        "    n_samples = len(X)\n",
        "\n",
        "    indices = np.arange(n_samples)\n",
        "    np.random.shuffle(indices)\n",
        "    \n",
        "    for start in range(0, n_samples, batch_size):\n",
        "        end = min(start + batch_size, n_samples)\n",
        "        \n",
        "        batch_indices = indices[start:end]\n",
        "        \n",
        "        max_sent_len = max(len(X[ind]) for ind in batch_indices)\n",
        "        X_batch = []\n",
        "        y_batch = np.zeros((max_sent_len, len(batch_indices)))\n",
        "        \n",
        "        for batch_ind, sample_ind in enumerate(batch_indices):\n",
        "            X_batch.append(X[sample_ind])\n",
        "            y_batch[:len(y[sample_ind]), batch_ind] = [tag2ind.get(tag, 0) for tag in y[sample_ind]]\n",
        "            \n",
        "        yield X_batch, y_batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l4XsRII5kW5x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_batch, y_batch = next(iterate_batches((X_train, y_train), 4))  # (max_sent_len, batch_size)\n",
        "\n",
        "# X_batch, y_batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C5I9E9P6eFYv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Задание** Реализуйте `LSTMTagger`:"
      ]
    },
    {
      "metadata": {
        "id": "WVEHju54d68T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class LSTMTagger(nn.Module):\n",
        "    def __init__(self, vocab_size, tagset_size, word_emb_dim=100, lstm_hidden_dim=128, lstm_layers_count=1):\n",
        "        super().__init__()\n",
        "        \n",
        "        self._embed = nn.Embedding(vocab_size, word_emb_dim)\n",
        "        self._dropout = nn.Dropout(0.3)\n",
        "        self._lstm = nn.LSTM(word_emb_dim, lstm_hidden_dim, num_layers=lstm_layers_count, bidirectional=True)\n",
        "        self._out_layer = nn.Linear(lstm_hidden_dim * 2, tagset_size)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        outputs = self._embed(inputs)\n",
        "        outputs = self._dropout(outputs)\n",
        "        outputs, _ = self._lstm(outputs)\n",
        "        outputs = self._out_layer(outputs)\n",
        "        return outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q_HA8zyheYGH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Задание** Научитесь считать accuracy (а заодно проверьте, что модель работает)"
      ]
    },
    {
      "metadata": {
        "id": "jbrxsZ2mehWB",
        "colab_type": "code",
        "outputId": "6dbd2221-6938-4546-eb02-e18ba5981c8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "model = LSTMTagger(\n",
        "    vocab_size=len(word2ind),\n",
        "    tagset_size=len(tag2ind)\n",
        ")\n",
        "\n",
        "X_batch, y_batch = torch.LongTensor(X_batch), torch.LongTensor(y_batch)\n",
        "\n",
        "logits = model(X_batch)\n",
        "\n",
        "preds = torch.argmax(logits, dim=2)\n",
        "mask = 1 - preds.eq(0)\n",
        "acc = torch.sum((preds == y_batch) * mask).item() / (y_batch.shape[0] * y_batch.shape[1])\n",
        "acc"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.046875"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "nSgV3NPUpcjH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Задание** Вставьте эти вычисление в функцию:"
      ]
    },
    {
      "metadata": {
        "id": "FprPQ0gllo7b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import math\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def do_epoch(model, criterion, data, batch_size, optimizer=None, name=None, pass_val_as_words=False):\n",
        "    epoch_loss = 0\n",
        "    correct_count = 0\n",
        "    sum_count = 0\n",
        "    \n",
        "    is_train = not optimizer is None\n",
        "    name = name or ''\n",
        "    model.train(is_train)\n",
        "    \n",
        "    batches_count = math.ceil(len(data[0]) / batch_size)\n",
        "    \n",
        "    batch_iterator = iterate_batches\n",
        "    if not is_train and pass_val_as_words:\n",
        "        batch_iterator = iterate_test_batches\n",
        "    \n",
        "    with torch.autograd.set_grad_enabled(is_train):\n",
        "#         with tqdm(total=batches_count) as progress_bar:\n",
        "            for i, (X_batch, y_batch) in enumerate(batch_iterator(data, batch_size)):\n",
        "                if is_train or not pass_val_as_words:\n",
        "                    X_batch = LongTensor(X_batch)\n",
        "                y_batch = LongTensor(y_batch)\n",
        "                logits = model(X_batch)\n",
        "                loss = criterion(logits.view(-1, logits.shape[-1]), y_batch.view(-1))\n",
        "\n",
        "                epoch_loss += loss.item()\n",
        "\n",
        "                if optimizer:\n",
        "                    optimizer.zero_grad()\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "                logits = logits.view(-1, logits.shape[-1])\n",
        "                preds = torch.argmax(logits, dim=1)\n",
        "                mask = 1 - preds.eq(0) # to exclude padding\n",
        "#                 print(preds.shape, y_batch.shape)\n",
        "                y_batch = y_batch.view(-1)\n",
        "                cur_correct_count, cur_sum_count = torch.sum((preds == y_batch) * mask).item(), len(preds)\n",
        " \n",
        "                correct_count += cur_correct_count\n",
        "                sum_count += cur_sum_count\n",
        "               \n",
        "#                 progress_bar.update()\n",
        "#                 progress_bar.set_description('{:>5s} Loss = {:.5f}, Accuracy = {:.2%}'.format(\n",
        "#                     name, loss.item(), cur_correct_count / cur_sum_count)\n",
        "#                 )\n",
        "                \n",
        "#             progress_bar.set_description('{:>5s} Loss = {:.5f}, Accuracy = {:.2%}'.format(\n",
        "#                 name, epoch_loss / batches_count, correct_count / sum_count)\n",
        "#             )\n",
        "\n",
        "    return epoch_loss / batches_count, correct_count / sum_count\n",
        "\n",
        "\n",
        "def fit(model, criterion, optimizer, train_data, epochs_count=1, batch_size=32,\n",
        "        val_data=None, val_batch_size=None, pass_val_as_words=False):\n",
        "        \n",
        "    if not val_data is None and val_batch_size is None:\n",
        "        val_batch_size = batch_size\n",
        "        \n",
        "    for epoch in range(epochs_count):\n",
        "        name_prefix = '[{} / {}] '.format(epoch + 1, epochs_count)\n",
        "        train_loss, train_acc = do_epoch(model, criterion, train_data, batch_size, optimizer, name_prefix + 'Train:')\n",
        "        \n",
        "        print(name_prefix + 'Train: Loss = {:.5f}, Accuracy = {:.2%}'.format(train_loss, train_acc))\n",
        "        if not val_data is None:\n",
        "            val_loss, val_acc = do_epoch(model, criterion, val_data, val_batch_size, None, name_prefix + '  Val:', pass_val_as_words=pass_val_as_words)\n",
        "            print(name_prefix + 'Val: Loss = {:.5f}, Accuracy = {:.2%}'.format(val_loss, val_acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Pqfbeh1ltEYa",
        "colab_type": "code",
        "outputId": "69479d15-26bb-49ff-829d-5e6880112d51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1717
        }
      },
      "cell_type": "code",
      "source": [
        "model = LSTMTagger(\n",
        "    vocab_size=len(word2ind),\n",
        "    tagset_size=len(tag2ind)\n",
        ").cuda()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0).cuda()\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "fit(model, criterion, optimizer, train_data=(X_train, y_train), epochs_count=50,\n",
        "    batch_size=64, val_data=(X_val, y_val), val_batch_size=64)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 / 50] Train: Loss = 0.65300, Accuracy = 24.70%\n",
            "[1 / 50] Val: Loss = 0.32309, Accuracy = 28.10%\n",
            "[2 / 50] Train: Loss = 0.30187, Accuracy = 28.39%\n",
            "[2 / 50] Val: Loss = 0.22306, Accuracy = 28.31%\n",
            "[3 / 50] Train: Loss = 0.22344, Accuracy = 28.99%\n",
            "[3 / 50] Val: Loss = 0.17951, Accuracy = 29.56%\n",
            "[4 / 50] Train: Loss = 0.18032, Accuracy = 29.48%\n",
            "[4 / 50] Val: Loss = 0.15328, Accuracy = 29.29%\n",
            "[5 / 50] Train: Loss = 0.15172, Accuracy = 29.64%\n",
            "[5 / 50] Val: Loss = 0.14095, Accuracy = 29.69%\n",
            "[6 / 50] Train: Loss = 0.13032, Accuracy = 30.10%\n",
            "[6 / 50] Val: Loss = 0.12926, Accuracy = 29.72%\n",
            "[7 / 50] Train: Loss = 0.11464, Accuracy = 30.24%\n",
            "[7 / 50] Val: Loss = 0.12879, Accuracy = 30.32%\n",
            "[8 / 50] Train: Loss = 0.10196, Accuracy = 30.30%\n",
            "[8 / 50] Val: Loss = 0.12061, Accuracy = 29.26%\n",
            "[9 / 50] Train: Loss = 0.09152, Accuracy = 30.35%\n",
            "[9 / 50] Val: Loss = 0.11648, Accuracy = 30.15%\n",
            "[10 / 50] Train: Loss = 0.08308, Accuracy = 30.55%\n",
            "[10 / 50] Val: Loss = 0.11290, Accuracy = 29.85%\n",
            "[11 / 50] Train: Loss = 0.07549, Accuracy = 30.59%\n",
            "[11 / 50] Val: Loss = 0.11129, Accuracy = 30.18%\n",
            "[12 / 50] Train: Loss = 0.06870, Accuracy = 30.81%\n",
            "[12 / 50] Val: Loss = 0.11118, Accuracy = 29.50%\n",
            "[13 / 50] Train: Loss = 0.06397, Accuracy = 30.56%\n",
            "[13 / 50] Val: Loss = 0.11528, Accuracy = 29.77%\n",
            "[14 / 50] Train: Loss = 0.05916, Accuracy = 30.64%\n",
            "[14 / 50] Val: Loss = 0.11685, Accuracy = 30.38%\n",
            "[15 / 50] Train: Loss = 0.05453, Accuracy = 30.77%\n",
            "[15 / 50] Val: Loss = 0.10855, Accuracy = 30.21%\n",
            "[16 / 50] Train: Loss = 0.05082, Accuracy = 30.91%\n",
            "[16 / 50] Val: Loss = 0.11207, Accuracy = 30.25%\n",
            "[17 / 50] Train: Loss = 0.04703, Accuracy = 30.80%\n",
            "[17 / 50] Val: Loss = 0.11187, Accuracy = 30.51%\n",
            "[18 / 50] Train: Loss = 0.04452, Accuracy = 30.78%\n",
            "[18 / 50] Val: Loss = 0.10588, Accuracy = 30.08%\n",
            "[19 / 50] Train: Loss = 0.04190, Accuracy = 30.67%\n",
            "[19 / 50] Val: Loss = 0.11439, Accuracy = 29.97%\n",
            "[20 / 50] Train: Loss = 0.03938, Accuracy = 30.98%\n",
            "[20 / 50] Val: Loss = 0.11211, Accuracy = 29.82%\n",
            "[21 / 50] Train: Loss = 0.03701, Accuracy = 30.69%\n",
            "[21 / 50] Val: Loss = 0.12380, Accuracy = 30.00%\n",
            "[22 / 50] Train: Loss = 0.03432, Accuracy = 30.99%\n",
            "[22 / 50] Val: Loss = 0.11816, Accuracy = 30.36%\n",
            "[23 / 50] Train: Loss = 0.03254, Accuracy = 31.01%\n",
            "[23 / 50] Val: Loss = 0.12734, Accuracy = 30.34%\n",
            "[24 / 50] Train: Loss = 0.03112, Accuracy = 30.97%\n",
            "[24 / 50] Val: Loss = 0.12007, Accuracy = 30.10%\n",
            "[25 / 50] Train: Loss = 0.02954, Accuracy = 31.03%\n",
            "[25 / 50] Val: Loss = 0.12581, Accuracy = 30.03%\n",
            "[26 / 50] Train: Loss = 0.02752, Accuracy = 31.29%\n",
            "[26 / 50] Val: Loss = 0.12100, Accuracy = 30.24%\n",
            "[27 / 50] Train: Loss = 0.02709, Accuracy = 31.25%\n",
            "[27 / 50] Val: Loss = 0.12632, Accuracy = 30.11%\n",
            "[28 / 50] Train: Loss = 0.02562, Accuracy = 31.03%\n",
            "[28 / 50] Val: Loss = 0.13546, Accuracy = 30.11%\n",
            "[29 / 50] Train: Loss = 0.02449, Accuracy = 31.04%\n",
            "[29 / 50] Val: Loss = 0.12662, Accuracy = 29.55%\n",
            "[30 / 50] Train: Loss = 0.02336, Accuracy = 30.94%\n",
            "[30 / 50] Val: Loss = 0.11807, Accuracy = 30.09%\n",
            "[31 / 50] Train: Loss = 0.02239, Accuracy = 31.25%\n",
            "[31 / 50] Val: Loss = 0.12533, Accuracy = 29.97%\n",
            "[32 / 50] Train: Loss = 0.02125, Accuracy = 31.32%\n",
            "[32 / 50] Val: Loss = 0.13412, Accuracy = 30.41%\n",
            "[33 / 50] Train: Loss = 0.02027, Accuracy = 31.20%\n",
            "[33 / 50] Val: Loss = 0.12652, Accuracy = 29.89%\n",
            "[34 / 50] Train: Loss = 0.01967, Accuracy = 31.36%\n",
            "[34 / 50] Val: Loss = 0.12077, Accuracy = 30.26%\n",
            "[35 / 50] Train: Loss = 0.01908, Accuracy = 31.17%\n",
            "[35 / 50] Val: Loss = 0.12479, Accuracy = 30.19%\n",
            "[36 / 50] Train: Loss = 0.01815, Accuracy = 30.99%\n",
            "[36 / 50] Val: Loss = 0.13068, Accuracy = 29.91%\n",
            "[37 / 50] Train: Loss = 0.01779, Accuracy = 31.15%\n",
            "[37 / 50] Val: Loss = 0.11865, Accuracy = 30.39%\n",
            "[38 / 50] Train: Loss = 0.01689, Accuracy = 31.27%\n",
            "[38 / 50] Val: Loss = 0.12146, Accuracy = 30.14%\n",
            "[39 / 50] Train: Loss = 0.01618, Accuracy = 31.26%\n",
            "[39 / 50] Val: Loss = 0.13673, Accuracy = 29.97%\n",
            "[40 / 50] Train: Loss = 0.01591, Accuracy = 31.44%\n",
            "[40 / 50] Val: Loss = 0.13168, Accuracy = 29.98%\n",
            "[41 / 50] Train: Loss = 0.01539, Accuracy = 31.01%\n",
            "[41 / 50] Val: Loss = 0.13389, Accuracy = 29.80%\n",
            "[42 / 50] Train: Loss = 0.01469, Accuracy = 31.11%\n",
            "[42 / 50] Val: Loss = 0.14207, Accuracy = 30.20%\n",
            "[43 / 50] Train: Loss = 0.01437, Accuracy = 31.35%\n",
            "[43 / 50] Val: Loss = 0.14296, Accuracy = 30.37%\n",
            "[44 / 50] Train: Loss = 0.01402, Accuracy = 31.15%\n",
            "[44 / 50] Val: Loss = 0.13498, Accuracy = 30.15%\n",
            "[45 / 50] Train: Loss = 0.01376, Accuracy = 31.30%\n",
            "[45 / 50] Val: Loss = 0.14378, Accuracy = 30.16%\n",
            "[46 / 50] Train: Loss = 0.01305, Accuracy = 31.45%\n",
            "[46 / 50] Val: Loss = 0.14734, Accuracy = 30.07%\n",
            "[47 / 50] Train: Loss = 0.01253, Accuracy = 31.21%\n",
            "[47 / 50] Val: Loss = 0.15376, Accuracy = 30.12%\n",
            "[48 / 50] Train: Loss = 0.01238, Accuracy = 31.27%\n",
            "[48 / 50] Val: Loss = 0.13628, Accuracy = 30.17%\n",
            "[49 / 50] Train: Loss = 0.01183, Accuracy = 31.23%\n",
            "[49 / 50] Val: Loss = 0.15103, Accuracy = 30.07%\n",
            "[50 / 50] Train: Loss = 0.01157, Accuracy = 31.34%\n",
            "[50 / 50] Val: Loss = 0.15289, Accuracy = 30.08%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "m0qGetIhfUE5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Masking\n",
        "\n",
        "**Задание** Проверьте себя - не считаете ли вы потери и accuracy на паддингах - очень легко получить высокое качество за счет этого.\n",
        "\n",
        "У функции потерь есть параметр `ignore_index`, для таких целей. Для accuracy нужно использовать маскинг - умножение на маску из нулей и единиц, где нули на позициях паддингов (а потом усреднение по ненулевым позициям в маске)."
      ]
    },
    {
      "metadata": {
        "id": "nAfV2dEOfHo5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Задание** Посчитайте качество модели на тесте"
      ]
    },
    {
      "metadata": {
        "id": "98wr38_rw55D",
        "colab_type": "code",
        "outputId": "e959cdbf-ae98-499f-b555-711df7f4c0da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "correct_count = 0\n",
        "sum_count = 0\n",
        "for X_batch_test, y_batch_test in iterate_batches((X_test, y_test), 64):\n",
        "    X_batch_test, y_batch_test = torch.cuda.LongTensor(X_batch_test), torch.cuda.LongTensor(y_batch_test)\n",
        "    logits = model(X_batch_test)\n",
        "    preds = torch.argmax(logits, dim=2)\n",
        "    mask = 1 - preds.eq(0)\n",
        "    correct_count += torch.sum((preds == y_batch_test) * mask).item()\n",
        "    sum_count += len(preds.view(-1))\n",
        "print(\"Accuracy of LSTMT tagger: {:.2%}\".format( correct_count / sum_count ) )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of LSTMT tagger: 30.78%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PXUTSFaEHbDG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Bidirectional LSTM\n",
        "\n",
        "Благодаря BiLSTM можно использовать сразу оба контеста при предсказании тега слова. Т.е. для каждого токена $w_i$ forward LSTM будет выдавать представление $\\mathbf{f_i} \\sim (w_1, \\ldots, w_i)$ - построенное по всему левому контексту - и $\\mathbf{b_i} \\sim (w_n, \\ldots, w_i)$ - представление правого контекста. Их конкатенация автоматически захватит весь доступный контекст слова: $\\mathbf{h_i} = [\\mathbf{f_i}, \\mathbf{b_i}] \\sim (w_1, \\ldots, w_n)$.\n",
        "\n",
        "![BiLSTM](https://www.researchgate.net/profile/Wang_Ling/publication/280912217/figure/fig2/AS:391505383575555@1470353565299/Illustration-of-our-neural-network-for-POS-tagging.png =x450)  \n",
        "from [Finding Function in Form: Compositional Character Models for Open Vocabulary Word Representation](https://arxiv.org/abs/1508.02096)\n",
        "\n",
        "**Задание** Добавьте Bidirectional LSTM."
      ]
    },
    {
      "metadata": {
        "id": "ZlBEVI-_8LGM",
        "colab_type": "code",
        "outputId": "24d9e191-d063-469d-a848-75411ccd9d69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "correct_count = 0\n",
        "sum_count = 0\n",
        "for X_batch_test, y_batch_test in iterate_batches((X_test, y_test), 64):\n",
        "    X_batch_test, y_batch_test = torch.cuda.LongTensor(X_batch_test), torch.cuda.LongTensor(y_batch_test)\n",
        "    logits = model(X_batch_test)\n",
        "    preds = torch.argmax(logits, dim=2)\n",
        "    mask = 1 - preds.eq(0)\n",
        "    correct_count += torch.sum((preds == y_batch_test) * mask).item()\n",
        "    sum_count += len(preds.view(-1))\n",
        "print(\"Accuracy of BiLSTMT tagger: {:.2%}\".format( correct_count / sum_count ) )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of BiLSTMT tagger: 31.02%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UpAIjkLYcPv4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "(И это только благодаря дропауту( )"
      ]
    },
    {
      "metadata": {
        "id": "ZTXmYGD_ANhm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Предобученные эмбеддинги\n",
        "\n",
        "Мы знаем, какая клёвая вещь - предобученные эмбеддинги. При текущем размере обучающей выборки еще можно было учить их и с нуля - с меньшей было бы совсем плохо.\n",
        "\n",
        "Поэтому стандартный пайплайн - скачать эмбеддинги, засунуть их в сеточку. Запустим его:"
      ]
    },
    {
      "metadata": {
        "id": "uZpY_Q1xZ18h",
        "colab_type": "code",
        "outputId": "80a77de6-6ad0-4e58-92aa-cc0477de47bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "w2v_model = api.load('glove-wiki-gigaword-100')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[==================================================] 100.0% 128.1/128.1MB downloaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KYogOoKlgtcf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Построим подматрицу для слов из нашей тренировочной выборки:"
      ]
    },
    {
      "metadata": {
        "id": "VsCstxiO03oT",
        "colab_type": "code",
        "outputId": "0bb4a43f-ae27-4743-a24a-41849a40f34c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "known_count = 0\n",
        "embeddings = np.zeros((len(word2ind), w2v_model.vectors.shape[1]))\n",
        "for word, ind in word2ind.items():\n",
        "    word = word.lower()\n",
        "    if word in w2v_model.vocab:\n",
        "        embeddings[ind] = w2v_model.get_vector(word)\n",
        "        known_count += 1\n",
        "        \n",
        "print('Know {} out of {} word embeddings'.format(known_count, len(word2ind)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Know 38736 out of 45441 word embeddings\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HcG7i-R8hbY3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Задание** Сделайте модель с предобученной матрицей. Используйте `nn.Embedding.from_pretrained`."
      ]
    },
    {
      "metadata": {
        "id": "LxaRBpQd0pat",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class LSTMTaggerWithPretrainedEmbs(nn.Module):\n",
        "    def __init__(self, embeddings, tagset_size, lstm_hidden_dim=64, lstm_layers_count=1):\n",
        "        super().__init__()\n",
        "        \n",
        "        self._emb = nn.Embedding.from_pretrained(torch.FloatTensor(embeddings))\n",
        "        self._emb_dim = self._emb.weight.shape[-1]\n",
        "        self._dropout = nn.Dropout(0.3)\n",
        "        self._lstm = nn.LSTM(self._emb_dim, lstm_hidden_dim, num_layers=lstm_layers_count, bidirectional=True)\n",
        "        self._out_layer = nn.Linear(lstm_hidden_dim * 2, tagset_size)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        if self.training:\n",
        "            outputs = self._emb(inputs)\n",
        "        else:\n",
        "            batch_size = len(inputs)\n",
        "            max_sent_len = max(len(sent) for sent in inputs)\n",
        "            outputs = self._emb.weight.new_zeros((max_sent_len, batch_size, self._emb_dim))\n",
        "            for i, sent in enumerate(inputs):\n",
        "                for j, word in enumerate(sent):\n",
        "                    if word in w2v_model.vocab:\n",
        "                        outputs[j, i] = torch.from_numpy(w2v_model.get_vector(word))\n",
        "        outputs = self._dropout(outputs)\n",
        "        outputs, _ = self._lstm(outputs)\n",
        "        outputs = self._out_layer(outputs)\n",
        "        return outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EBtI6BDE-Fc7",
        "colab_type": "code",
        "outputId": "dafe9d4b-67f0-4f65-fbbf-4cd5490d5ccf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1285
        }
      },
      "cell_type": "code",
      "source": [
        "model = LSTMTaggerWithPretrainedEmbs(\n",
        "    embeddings=embeddings,\n",
        "    tagset_size=len(tag2ind)\n",
        ").cuda()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "fit(model, criterion, optimizer, train_data=(X_train, y_train), epochs_count=50,\n",
        "    batch_size=64, val_data=val_data, val_batch_size=64, pass_val_as_words=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 / 50] Train: Loss = 0.70392, Accuracy = 24.39%\n",
            "[1 / 50] Val: Loss = 51.40134, Accuracy = 26.93%\n",
            "[2 / 50] Train: Loss = 0.32310, Accuracy = 28.26%\n",
            "[2 / 50] Val: Loss = 42.13447, Accuracy = 27.70%\n",
            "[3 / 50] Train: Loss = 0.24809, Accuracy = 29.01%\n",
            "[3 / 50] Val: Loss = 39.17144, Accuracy = 27.93%\n",
            "[4 / 50] Train: Loss = 0.20956, Accuracy = 29.26%\n",
            "[4 / 50] Val: Loss = 38.50707, Accuracy = 28.48%\n",
            "[5 / 50] Train: Loss = 0.18703, Accuracy = 29.29%\n",
            "[5 / 50] Val: Loss = 38.56161, Accuracy = 28.11%\n",
            "[6 / 50] Train: Loss = 0.17251, Accuracy = 29.48%\n",
            "[6 / 50] Val: Loss = 37.84654, Accuracy = 28.59%\n",
            "[7 / 50] Train: Loss = 0.16135, Accuracy = 29.65%\n",
            "[7 / 50] Val: Loss = 37.73847, Accuracy = 28.96%\n",
            "[8 / 50] Train: Loss = 0.15208, Accuracy = 29.68%\n",
            "[8 / 50] Val: Loss = 38.19388, Accuracy = 28.44%\n",
            "[9 / 50] Train: Loss = 0.14586, Accuracy = 29.99%\n",
            "[9 / 50] Val: Loss = 38.26041, Accuracy = 28.91%\n",
            "[10 / 50] Train: Loss = 0.13977, Accuracy = 29.89%\n",
            "[10 / 50] Val: Loss = 37.69886, Accuracy = 28.71%\n",
            "[11 / 50] Train: Loss = 0.13581, Accuracy = 29.83%\n",
            "[11 / 50] Val: Loss = 37.94828, Accuracy = 28.43%\n",
            "[12 / 50] Train: Loss = 0.13232, Accuracy = 30.01%\n",
            "[12 / 50] Val: Loss = 37.66794, Accuracy = 29.07%\n",
            "[13 / 50] Train: Loss = 0.12900, Accuracy = 29.94%\n",
            "[13 / 50] Val: Loss = 37.08463, Accuracy = 28.25%\n",
            "[14 / 50] Train: Loss = 0.12634, Accuracy = 30.03%\n",
            "[14 / 50] Val: Loss = 37.60359, Accuracy = 28.39%\n",
            "[15 / 50] Train: Loss = 0.12416, Accuracy = 30.10%\n",
            "[15 / 50] Val: Loss = 38.04314, Accuracy = 28.36%\n",
            "[16 / 50] Train: Loss = 0.12190, Accuracy = 30.01%\n",
            "[16 / 50] Val: Loss = 37.51624, Accuracy = 28.97%\n",
            "[17 / 50] Train: Loss = 0.11990, Accuracy = 30.26%\n",
            "[17 / 50] Val: Loss = 37.58128, Accuracy = 28.36%\n",
            "[18 / 50] Train: Loss = 0.11836, Accuracy = 30.16%\n",
            "[18 / 50] Val: Loss = 37.75514, Accuracy = 28.86%\n",
            "[19 / 50] Train: Loss = 0.11654, Accuracy = 30.19%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-26ae3adc8acf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m fit(model, criterion, optimizer, train_data=(X_train, y_train), epochs_count=50,\n\u001b[0;32m---> 10\u001b[0;31m     batch_size=64, val_data=val_data, val_batch_size=64, pass_val_as_words=True)\n\u001b[0m",
            "\u001b[0;32m<ipython-input-13-2994c150aec6>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, criterion, optimizer, train_data, epochs_count, batch_size, val_data, val_batch_size, pass_val_as_words)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_prefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'Train: Loss = {:.5f}, Accuracy = {:.2%}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mval_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdo_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_prefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'  Val:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpass_val_as_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpass_val_as_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_prefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'Val: Loss = {:.5f}, Accuracy = {:.2%}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-2994c150aec6>\u001b[0m in \u001b[0;36mdo_epoch\u001b[0;34m(model, criterion, data, batch_size, optimizer, name, pass_val_as_words)\u001b[0m\n\u001b[1;32m     24\u001b[0m                     \u001b[0mX_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-3768fddc49c4>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mw2v_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                         \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw2v_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "2Ne_8f24h8kg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Задание** Оцените качество модели на тестовой выборке. Обратите внимание, вовсе не обязательно ограничиваться векторами из урезанной матрицы - вполне могут найтись слова в тесте, которых не было в трейне и для которых есть эмбеддинги."
      ]
    },
    {
      "metadata": {
        "id": "HPUuAPGhEGVR",
        "colab_type": "code",
        "outputId": "5ca8951b-3634-4d37-b011-b5407c38b48b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "correct_count = 0\n",
        "sum_count = 0\n",
        "for X_batch_test, y_batch_test in iterate_test_batches(test_data, 64):\n",
        "    y_batch_test = torch.cuda.LongTensor(y_batch_test)\n",
        "    logits = model(X_batch_test)\n",
        "    preds = torch.argmax(logits, dim=2)\n",
        "    mask = 1 - preds.eq(0)\n",
        "    correct_count += torch.sum((preds == y_batch_test) * mask).item()\n",
        "    sum_count += len(preds.view(-1))\n",
        "print(\"Accuracy of LSTMTaggerWithPretrainedEmbs: {:.2%}\".format( correct_count / sum_count ) )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of LSTMTaggerWithPretrainedEmbs: 29.27%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "enF9GAPAN3RB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Дообучение предобученных векторов\n",
        "\n",
        "**Задание** Почему бы не попробовать дообучать вектора? Для этого нужно просто заменить флаг `freeze=False` в методе `from_pretrained`. Попробуйте."
      ]
    },
    {
      "metadata": {
        "id": "J1qVLMf5MLLZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class LSTMTaggerWithPretrainedEmbs(nn.Module):\n",
        "    def __init__(self, embeddings, tagset_size, lstm_hidden_dim=64, lstm_layers_count=1):\n",
        "        super().__init__()\n",
        "        \n",
        "        self._emb = nn.Embedding.from_pretrained(torch.FloatTensor(embeddings), freeze=False )\n",
        "        self._emb_dim = self._emb.weight.shape[-1]\n",
        "        self._dropout = nn.Dropout(0.3)\n",
        "        self._lstm = nn.LSTM(self._emb_dim, lstm_hidden_dim, num_layers=lstm_layers_count, bidirectional=True)\n",
        "        self._out_layer = nn.Linear(lstm_hidden_dim * 2, tagset_size)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        if self.training:\n",
        "            outputs = self._emb(inputs)\n",
        "        else:\n",
        "            batch_size = len(inputs)\n",
        "            max_sent_len = max(len(sent) for sent in inputs)\n",
        "            outputs = self._emb.weight.new_zeros((max_sent_len, batch_size, self._emb_dim))\n",
        "            for i, sent in enumerate(inputs):\n",
        "                for j, word in enumerate(sent):\n",
        "                    if word in w2v_model.vocab:\n",
        "                        outputs[j, i] = torch.from_numpy(w2v_model.get_vector(word))\n",
        "        outputs = self._dropout(outputs)\n",
        "        outputs, _ = self._lstm(outputs)\n",
        "        outputs = self._out_layer(outputs)\n",
        "        return outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5AdB6olUiyf7",
        "colab_type": "code",
        "outputId": "9138f162-4025-4508-eb22-eab9c5bb024e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1329
        }
      },
      "cell_type": "code",
      "source": [
        "model = LSTMTaggerWithPretrainedEmbs(\n",
        "    embeddings=embeddings,\n",
        "    tagset_size=len(tag2ind)\n",
        ").cuda()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "fit(model, criterion, optimizer, train_data=(X_train, y_train), epochs_count=50,\n",
        "    batch_size=64, val_data=val_data, val_batch_size=512, pass_val_as_words=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 / 50] Train: Loss = 0.47417, Accuracy = 26.74%\n",
            "[1 / 50] Val: Loss = 8.60263, Accuracy = 15.67%\n",
            "[2 / 50] Train: Loss = 0.12094, Accuracy = 30.05%\n",
            "[2 / 50] Val: Loss = 8.79219, Accuracy = 16.46%\n",
            "[3 / 50] Train: Loss = 0.08494, Accuracy = 30.49%\n",
            "[3 / 50] Val: Loss = 9.03400, Accuracy = 16.04%\n",
            "[4 / 50] Train: Loss = 0.06644, Accuracy = 30.64%\n",
            "[4 / 50] Val: Loss = 8.82678, Accuracy = 17.63%\n",
            "[5 / 50] Train: Loss = 0.05491, Accuracy = 30.78%\n",
            "[5 / 50] Val: Loss = 8.84642, Accuracy = 16.50%\n",
            "[6 / 50] Train: Loss = 0.04703, Accuracy = 30.72%\n",
            "[6 / 50] Val: Loss = 9.47900, Accuracy = 16.29%\n",
            "[7 / 50] Train: Loss = 0.04077, Accuracy = 31.09%\n",
            "[7 / 50] Val: Loss = 9.93246, Accuracy = 16.78%\n",
            "[8 / 50] Train: Loss = 0.03686, Accuracy = 31.01%\n",
            "[8 / 50] Val: Loss = 10.25840, Accuracy = 15.67%\n",
            "[9 / 50] Train: Loss = 0.03309, Accuracy = 30.76%\n",
            "[9 / 50] Val: Loss = 10.72721, Accuracy = 15.70%\n",
            "[10 / 50] Train: Loss = 0.02986, Accuracy = 30.97%\n",
            "[10 / 50] Val: Loss = 10.66701, Accuracy = 15.72%\n",
            "[11 / 50] Train: Loss = 0.02730, Accuracy = 31.20%\n",
            "[11 / 50] Val: Loss = 11.09199, Accuracy = 15.60%\n",
            "[12 / 50] Train: Loss = 0.02522, Accuracy = 31.23%\n",
            "[12 / 50] Val: Loss = 10.89299, Accuracy = 16.73%\n",
            "[13 / 50] Train: Loss = 0.02357, Accuracy = 31.26%\n",
            "[13 / 50] Val: Loss = 11.46670, Accuracy = 16.31%\n",
            "[14 / 50] Train: Loss = 0.02143, Accuracy = 31.03%\n",
            "[14 / 50] Val: Loss = 11.81803, Accuracy = 15.44%\n",
            "[15 / 50] Train: Loss = 0.01988, Accuracy = 31.19%\n",
            "[15 / 50] Val: Loss = 12.26543, Accuracy = 16.09%\n",
            "[16 / 50] Train: Loss = 0.01846, Accuracy = 31.30%\n",
            "[16 / 50] Val: Loss = 12.23772, Accuracy = 15.69%\n",
            "[17 / 50] Train: Loss = 0.01732, Accuracy = 30.98%\n",
            "[17 / 50] Val: Loss = 12.13992, Accuracy = 15.80%\n",
            "[18 / 50] Train: Loss = 0.01562, Accuracy = 31.32%\n",
            "[18 / 50] Val: Loss = 13.96693, Accuracy = 15.50%\n",
            "[19 / 50] Train: Loss = 0.01481, Accuracy = 31.23%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-157-4ac0599479aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m fit(model, criterion, optimizer, train_data=(X_train, y_train), epochs_count=50,\n\u001b[0;32m---> 10\u001b[0;31m     batch_size=64, val_data=val_data, val_batch_size=512, pass_val_as_words=True)\n\u001b[0m",
            "\u001b[0;32m<ipython-input-152-98cea656d299>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, criterion, optimizer, train_data, epochs_count, batch_size, val_data, val_batch_size, pass_val_as_words)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_prefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'Train: Loss = {:.5f}, Accuracy = {:.2%}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mval_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdo_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_prefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'  Val:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpass_val_as_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpass_val_as_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_prefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'Val: Loss = {:.5f}, Accuracy = {:.2%}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-152-98cea656d299>\u001b[0m in \u001b[0;36mdo_epoch\u001b[0;34m(model, criterion, data, batch_size, optimizer, name, pass_val_as_words)\u001b[0m\n\u001b[1;32m     24\u001b[0m                     \u001b[0mX_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-155-3c88fa59b4e3>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mw2v_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                         \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw2v_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "R3ck_XJxLkYU",
        "colab_type": "code",
        "outputId": "75a1d9bb-46f8-49ec-e388-c34dbd88530b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "correct_count = 0\n",
        "sum_count = 0\n",
        "for X_batch_test, y_batch_test in iterate_test_batches(test_data, 64):\n",
        "    y_batch_test = torch.cuda.LongTensor(y_batch_test)\n",
        "    logits = model(X_batch_test)\n",
        "    preds = torch.argmax(logits, dim=2)\n",
        "    mask = 1 - preds.eq(0)\n",
        "    correct_count += torch.sum((preds == y_batch_test) * mask).item()\n",
        "    sum_count += len(preds.view(-1))\n",
        "print(\"Accuracy of LSTMTaggerWithPretrainedEmbs: {:.2%}\".format( correct_count / sum_count ) )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of LSTMT tagger: 24.82%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZVJet3RQix98",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Задание** На самом деле, понятно, почему это плохо - после этого нельзя использовать старые предобученные вектора (которые не попали в трейн). Проверьте, какое качество получается на тесте со старыми векторами.\n",
        "\n",
        "Чтобы бороться с этим, можно использовать такой прием: на предобученные вектора накладывать $l_2$-регуляризацию, чтобы они не удалялись от исходных векторов, а для слов, эмбеддинги которых мы не знаем, строить случайные вектора и учить их как обычно.\n",
        "\n",
        "**Задание** Попробуйте реализовать это."
      ]
    },
    {
      "metadata": {
        "id": "EfN1olf6RZne",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## We need to go deeper\n",
        "\n",
        "Напомню, на прошлом занятии мы строили LSTM сеть, которая обрабатывала последовательности символов, и предсказывала, к какому языку относится слово. \n",
        "\n",
        "LSTM выступал в роли feature extractor'а, работающего с произвольного размера последовательностью символов (ну, почти произвольного - мы ограничивались максимальной длиной слова). Батч для сети имел размерность `(max_word_len, batch_size)`.\n",
        "\n",
        "Теперь мы опять хотим использовать такую же идею для извлечения признаков из последовательности символов - потому что последовательность символов же должна быть полезной для предсказания части речи, правда?\n",
        "\n",
        "Сеть должна будет запомнить, например, что `-ly` - это часто про наречие, а `-tion` - про существительное.\n",
        "\n",
        "![](https://image.ibb.co/kzbh6L/Char-Bi-LSTM.png =x400)\n",
        "\n",
        "Остальная часть сети при этом будет такой же.\n",
        "\n",
        "Найдем границу для длины слов:"
      ]
    },
    {
      "metadata": {
        "id": "SczGwL8Cy0Ws",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from collections import Counter \n",
        "    \n",
        "def find_max_len(counter, threshold):\n",
        "    sum_count = sum(counter.values())\n",
        "    cum_count = 0\n",
        "    for i in range(max(counter)):\n",
        "        cum_count += counter[i]\n",
        "        if cum_count > sum_count * threshold:\n",
        "            return i\n",
        "    return max(counter)\n",
        "\n",
        "word_len_counter = Counter()\n",
        "for sent in data:\n",
        "    for word, _ in sent:\n",
        "        word_len_counter[len(word)] += 1\n",
        "    \n",
        "threshold = 0.99\n",
        "MAX_WORD_LEN = find_max_len(word_len_counter, threshold)\n",
        "\n",
        "print('Max word len for {:.0%} of words is {}'.format(threshold, MAX_WORD_LEN))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YlArjEvqkMGk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Построим алфавит:"
      ]
    },
    {
      "metadata": {
        "id": "-LWXHmXGcotd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from string import punctuation\n",
        "\n",
        "def get_range(first_symb, last_symb):\n",
        "    return set(chr(c) for c in range(ord(first_symb), ord(last_symb) + 1))\n",
        "\n",
        "chars = get_range('a', 'z') | get_range('A', 'Z') | get_range('0', '9') | set(punctuation)\n",
        "char2ind = {c : i + 1 for i, c in enumerate(chars)}\n",
        "char2ind['<pad>'] = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v0OS9WQjkO9b",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Задание** Сконвертируйте данные, как в функции выше - только теперь слова должны отобразиться не в один индекс, а в последовательность.\n",
        "\n",
        "Обрезайте слова по `MAX_WORD_LEN`."
      ]
    },
    {
      "metadata": {
        "id": "k3Q3arGCmgi-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def convert_data(data, char2ind, tag2ind):\n",
        "    X = [[[char2ind.get(ch, 0) for ch in word[:MAX_WORD_LEN]] for word, _ in sample] for sample in data]\n",
        "    y = [[tag2ind[tag] for _, tag in sample] for sample in data]\n",
        "    return X, y\n",
        "  \n",
        "X_train, y_train = convert_data(train_data, char2ind, tag2ind)\n",
        "X_val, y_val = convert_data(val_data, char2ind, tag2ind)\n",
        "X_test, y_test = convert_data(test_data, char2ind, tag2ind)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1SMmXMx5Rr5z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Напишем генератор батчей:"
      ]
    },
    {
      "metadata": {
        "id": "c835LEVERXzl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def iterate_batches(data, batch_size):\n",
        "    X, y = data\n",
        "    n_samples = len(X)\n",
        "\n",
        "    indices = np.arange(n_samples)\n",
        "    np.random.shuffle(indices)\n",
        "    \n",
        "    for start in range(0, n_samples, batch_size):\n",
        "        end = min(start + batch_size, n_samples)\n",
        "        \n",
        "        batch_indices = indices[start: end]\n",
        "        \n",
        "        sent_len = max(len(X[ind]) for ind in batch_indices)\n",
        "        word_len = max(len(word) for ind in batch_indices for word in X[ind])\n",
        "            \n",
        "        X_batch = np.zeros((sent_len, len(batch_indices), word_len))\n",
        "        y_batch = np.zeros((sent_len, len(batch_indices)))\n",
        "        \n",
        "        for batch_ind, sample_ind in enumerate(batch_indices):\n",
        "            for word_ind, word in enumerate(X[sample_ind]):\n",
        "                X_batch[word_ind, batch_ind, :len(word)] = word\n",
        "            y_batch[:len(y[sample_ind]), batch_ind] = y[sample_ind]\n",
        "            \n",
        "        yield X_batch, y_batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zWcRRe11jFI8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_batch, y_batch = next(iterate_batches((X_train, y_train), 4))\n",
        "\n",
        "X_batch.shape, y_batch.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yfY7FcXCknzX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Задание** Реализуйте сеть, которая принимает батч размера `(seq_len, batch_size, word_len)` и возвращает `(seq_len, batch_size, word_emb_dim)`. Это может быть любая функция, которая умеет в последовательности произвольной длины. Мы уже смотрели на сверточные и рекуррентные сети для такой задачи - попробуйте обе."
      ]
    },
    {
      "metadata": {
        "id": "f1qs96uAY3Wd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CharsEmbedding(nn.Module):\n",
        "    def __init__(self, vocab_size, char_emb_dim=24, word_emb_dim=100):\n",
        "        super().__init__()\n",
        "        self._embs = nn.Embedding(vocab_size, char_emb_dim)\n",
        "        self._conv = nn.Conv2d(in_channels=1, out_channels=word_emb_dim, kernel_size=(2, char_emb_dim))\n",
        "#         <create Conv or LSTM encoder>\n",
        "        \n",
        "    def forward(self, inputs):\n",
        "        outputs = self._embs(inputs)\n",
        "        print(outputs.shape)\n",
        "        seq_len, batch_size = outputs.shape[:2]\n",
        "        outputs = outputs.view(seq_len*batch_size, 1, outputs.shape[2], outputs.shape[3])\n",
        "        print(outputs.shape)\n",
        "        outputs = self._conv(ouputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bLf7MGBtENUH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = CharsEmbedding(len(char2ind))\n",
        "X_batch = torch.LongTensor(X_batch)\n",
        "model(X_batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ag2R5sIglLhh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Задание** Реализуйте теггер с эмбеддингами символьного уровня."
      ]
    },
    {
      "metadata": {
        "id": "TRB8tAOAa_YW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class LSTMTagger(nn.Module):\n",
        "    def __init__(self, char_vocab_size, tagset_size, char_emb_dim=24, \n",
        "                 word_emb_dim=128, lstm_hidden_dim=128, lstm_layers_count=1):\n",
        "        super().__init__()\n",
        "        \n",
        "        <create it>\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        <apply>"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cEaWjN0qjFfe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = LSTMTagger(char_vocab_size=len(char2ind), tagset_size=len(tag2ind)).cuda()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0).cuda()\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "fit(model, criterion, optimizer, train_data=(X_train, y_train), epochs_count=20, \n",
        "    batch_size=24, val_data=(X_val, y_val), val_batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OGDJqyG9lTxV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Задание** Оцените его качество."
      ]
    },
    {
      "metadata": {
        "id": "OCUj9_nqjgrL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "_, test_accuracy = do_epoch(model, criterion, (X_test, y_test), batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "12HYYmSzlZtm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Визуализации\n",
        "\n",
        "**Задание** Посчитайте эмбеддинги символьного уровня (обученные внутри модели перед этим) для 1000 случайных слов из `word2ind`."
      ]
    },
    {
      "metadata": {
        "id": "qyXEJ6MUG8PE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "embeddings, index2word = <calc me>"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K2klT31GSWlR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import bokeh.models as bm, bokeh.plotting as pl\n",
        "from bokeh.io import output_notebook\n",
        "\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.preprocessing import scale\n",
        "\n",
        "\n",
        "def draw_vectors(x, y, radius=10, alpha=0.25, color='blue',\n",
        "                 width=600, height=400, show=True, **kwargs):\n",
        "    \"\"\" draws an interactive plot for data points with auxilirary info on hover \"\"\"\n",
        "    output_notebook()\n",
        "    \n",
        "    if isinstance(color, str): \n",
        "        color = [color] * len(x)\n",
        "    data_source = bm.ColumnDataSource({ 'x' : x, 'y' : y, 'color': color, **kwargs })\n",
        "\n",
        "    fig = pl.figure(active_scroll='wheel_zoom', width=width, height=height)\n",
        "    fig.scatter('x', 'y', size=radius, color='color', alpha=alpha, source=data_source)\n",
        "\n",
        "    fig.add_tools(bm.HoverTool(tooltips=[(key, \"@\" + key) for key in kwargs.keys()]))\n",
        "    if show: \n",
        "        pl.show(fig)\n",
        "    return fig\n",
        "\n",
        "\n",
        "def get_tsne_projection(word_vectors):\n",
        "    tsne = TSNE(n_components=2, verbose=100)\n",
        "    return scale(tsne.fit_transform(word_vectors))\n",
        "    \n",
        "    \n",
        "def visualize_embeddings(embeddings, token):\n",
        "    tsne = get_tsne_projection(embeddings)\n",
        "    draw_vectors(tsne[:, 0], tsne[:, 1], token=token)\n",
        "    \n",
        "\n",
        "visualize_embeddings(embeddings, index2word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TgmDHM9Dl7W7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Задание** Посчитайте эмбеддинги для всех слов из трейна и для нескольких случайных слов из теста, которые не встречаются в трейне, найдите их ближайших соседей по их эмбеддигам символьного уровня."
      ]
    },
    {
      "metadata": {
        "id": "1bctty__mOOz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WzAozOANpnT1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Словные эмбеддинги\n",
        "\n",
        "**Задание** Только символьных эмбеддингов может быть недостаточно. Верните ещё словные эмбеддинги. Слова стоит приводить к нижнему регистру - признаки, связанные с регистром должны ухватываться символьный LSTM.\n",
        "\n",
        "Эти эмбеддинги можно просто сконкатенировать, можно складывать, а можно использовать гейт (как в LSTM). Например, по эмбеддингу слова предсказывать $o = \\sigma(w)$ - насколько он хорош и сочетать в такой пропорции с символьным эмбеддингом: $o \\odot w + (1 - o) \\odot \\tilde w$, где $\\tilde w$ - эмбеддинг слова, полученный по символьному уровню. Проверьте разные варианты.\n",
        "\n",
        "### Связь словных эмбеддингов и эмбеддингов символьного уровня\n",
        "В словных эмбеддингах мы строим отображение из слова в индекс. В итоге входной батч достаточно небольшой - это хорошо для обучения (быстрее передача на видеокарту). С символьными эмбеддингами беда - но это можно исправить.\n",
        "\n",
        "Давайте предпосчитаем для каждого слова в `word2ind` его последовательность индексов символов. Получится матрица. Эту матрицу можно вместе с моделью перенести на видеокарту. Тогда нужен будет батч из индексов слов - по нему можно сделать лукап (с помощью `F.embedding`) в матрице и получить трехмерную матрицу с символами.\n",
        "\n",
        "Преимущество - по одному батчу можно получить сразу и эмбеддинги слов, и эмбеддинги символьного уровня. Это удобно и энергоэффективно.\n",
        "\n",
        "Другая идея - после того, как мы обучили модель, можно предпосчитать эмбеддинги слов символьного уровня - лукап в таблице эмбеддингов гораздо проще, чем сверточная или рекуррентная сеть над символами. Таким образом, например, получаются эмбеддинги в [FastText](https://github.com/facebookresearch/fastText/blob/master/pretrained-vectors.md) - они также исходно считаются на символьном (N-граммном) уровне."
      ]
    },
    {
      "metadata": {
        "id": "9gzxhGe6okls",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Encoder-decoder\n",
        "\n",
        "Можно усложнить модель - добавить еще один рекуррентный слой. Первый слой будет служить энкодером последовательности, второй, более легкий - декодировать последовательность. Декодировать - значит, на вход он должен принимать как состояние для данного токена из энкодера, так и предыдущий предсказанный тег.\n",
        "\n",
        "**Задание** Рискните реализовать это."
      ]
    },
    {
      "metadata": {
        "id": "s8WVAmMWqsrS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Сдача\n",
        "\n",
        "[Опрос](https://goo.gl/forms/R6UqcESWIjtVSA6J3)"
      ]
    }
  ]
}